{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowpal Wabbit в NLP\n",
    "Автоматическая обработка текстов - 2017, семинар 4.\n",
    "\n",
    "В этом семинаре мы познакомимся с библиотекой Vowpal Wabbit и решим с его помощью задачу многоклассовой классификации на больших данных. \n",
    "Данные скачайте [здесь](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data) или запустите следующие две ячейки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget https://www.dropbox.com/s/r0q0p0uprhcp8bb/train-sample.zip\n",
    "! unzip train-sample.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget https://www.dropbox.com/s/50vw2gsglc91f6o/train.zip\n",
    "! unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы на семинаре не тратить время на обработку и обучение моделей на всех данных, предлагается использовать только небольшую подвыборку (`train-sample.csv`). Но сдавать ноутбук все равно необходимо с результатами на **всех** данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BodyMarkdown': 'I am building a corpus of indexed sentences in different languages. I have a collection of Languages which have both an ObjectId and the ISO code as a key. Is it better to use a reference to the Language collection or store a key like \"en\" or \"fr\"?\\r\\n\\r\\nI suppose it\\'s a compromise between:\\r\\n\\r\\n - ease of referencing the Language\\r\\n - object in that collection\\r\\n - speed in doing queries where the sentence has a certain language\\r\\n - the size of the data on disk\\r\\n\\r\\nAny best practices that I should know of?',\n",
       " 'OpenStatus': 'open',\n",
       " 'OwnerCreationDate': '09/17/2010 10:15:06',\n",
       " 'OwnerUndeletedAnswerCountAtPostTime': '2',\n",
       " 'OwnerUserId': '543315',\n",
       " 'PostClosedDate': '',\n",
       " 'PostCreationDate': '05/18/2011 14:14:05',\n",
       " 'PostId': '6046168',\n",
       " 'ReputationAtPostCreation': '1',\n",
       " 'Tag1': 'mongodb',\n",
       " 'Tag2': '',\n",
       " 'Tag3': '',\n",
       " 'Tag4': '',\n",
       " 'Tag5': '',\n",
       " 'Title': 'For Mongodb is it better to reference an object or use a natural String key?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#INPUT_DATA = 'train.csv'\n",
    "INPUT_DATA = 'train-sample.csv'\n",
    "\n",
    "reader = csv.DictReader(open(INPUT_DATA))\n",
    "dict(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект выборки соответствует некоторому посту на Stack Overflow. Требуется построить модель, определяющую статус поста. Подробнее про задачу и формат данных можно прочитать на [странице соревнования](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow).\n",
    "\n",
    "Перед обучением модели из Vowpal Wabbit данные следует сохранить в специальный формат: <br>\n",
    "`label |namespace1 feature1:value1 feature2 feature3:value3 |namespace2 ...` <br>\n",
    "Записи `feature` и `feature:1.0` эквивалентны. Выделение признаков в смысловые подгруппы (namespaces) позволяет создавать взаимодействия между ними. Подробнее про формат входных данных можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format).\n",
    "\n",
    "Ниже реализована функция, которая извлекает признаки с помощью подаваемого на вход экстрактора, разбивает данные на трейн и тест и записывает их на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATUSES = ['not a real question', 'not constructive', 'off topic', 'open', 'too localized']\n",
    "STATUS_DICT = {status: i+1 for i, status in enumerate(STATUSES)}\n",
    "\n",
    "def data2vw(features_extractor, train_output='train', test_output='test', ytest_output='ytest'):\n",
    "    reader = csv.DictReader(open(INPUT_DATA))\n",
    "    writer_train = open(train_output, 'w')\n",
    "    writer_test = open(test_output, 'w')\n",
    "    writer_ytest = open(ytest_output, 'w')\n",
    "    \n",
    "    for row in reader:\n",
    "        label = STATUS_DICT[row['OpenStatus']]\n",
    "        features = features_extractor(row)\n",
    "        output_line = '%s %s\\n' % (label, features)\n",
    "        if int(row['PostId']) % 2 == 0:\n",
    "            writer_train.write(output_line)\n",
    "        else:\n",
    "            writer_test.write(output_line)\n",
    "            writer_ytest.write('%s\\n' % label)\n",
    "            \n",
    "    writer_train.close()\n",
    "    writer_test.close()\n",
    "    writer_ytest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с простейшей модели. В качестве признаков возьмите заголовки и очистите их: приведите символы к нижнему регистру, удалите пунктуацию. Также приветствуется использование стеммеров/лемматизаторов, однако учтите, что они могут сильно замедлить скорость обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_title(row):\n",
    "    title = row['Title']\n",
    "    # YOUR CODE HERE\n",
    "    return ''.join([character for character in title.lower() if (character.isalpha() or character == ' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2vw(lambda row: '| %s' % extract_title(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | for mongodb is it better to reference an object or use a natural string key\r\n",
      "4 | springdata mongodb querying multiple classes stored in the same collection\r\n",
      "4 | stop ajax function in midway when other element is clicked\r\n",
      "1 | list of all txt file\r\n",
      "5 | i want to design an invitation card for my wedding in silverlight \r\n"
     ]
    }
   ],
   "source": [
    "! head -n 5 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим `vw` модель. Параметр `-d` отвечает за путь к обучающей выборке, `-f` – за путь к модели, `--oaa` – за режим мультиклассовой классификации `one-against-all`. Подробное описание всех параметров можно найти [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments) или вызвав `vw --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4        1       16\n",
      "0.500000 0.000000            2            2.0        4        4       11\n",
      "0.500000 0.500000            4            4.0        1        4        6\n",
      "0.750000 1.000000            8            8.0        3        4        8\n",
      "0.625000 0.500000           16           16.0        2        4        7\n",
      "0.500000 0.375000           32           32.0        2        4       10\n",
      "0.468750 0.437500           64           64.0        1        4       11\n",
      "0.476562 0.484375          128          128.0        3        4        9\n",
      "0.511719 0.546875          256          256.0        1        4       10\n",
      "0.500000 0.488281          512          512.0        4        4        9\n",
      "0.522461 0.544922         1024         1024.0        2        4       12\n",
      "0.497559 0.472656         2048         2048.0        1        1        9\n",
      "0.478760 0.459961         4096         4096.0        4        4        8\n",
      "0.464600 0.450439         8192         8192.0        4        4        9\n",
      "0.450134 0.435669        16384        16384.0        4        4       11\n",
      "0.434967 0.419800        32768        32768.0        3        3       10\n",
      "0.425644 0.416321        65536        65536.0        4        4       12\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 70398\n",
      "passes used = 1\n",
      "weighted example sum = 70398.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.423549\n",
      "total feature number = 622027\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим модель к тестовой выборке и сохраним предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "raw predictions = pred\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        4        4       11\n",
      "0.000000 0.000000            2            2.0        4        4        5\n",
      "0.250000 0.500000            4            4.0        4        4        8\n",
      "0.375000 0.500000            8            8.0        3        1        9\n",
      "0.375000 0.375000           16           16.0        4        4        9\n",
      "0.406250 0.437500           32           32.0        4        4       13\n",
      "0.453125 0.500000           64           64.0        3        1       11\n",
      "0.414062 0.375000          128          128.0        1        4       10\n",
      "0.406250 0.398438          256          256.0        4        4        9\n",
      "0.412109 0.417969          512          512.0        3        3        5\n",
      "0.400391 0.388672         1024         1024.0        4        4        8\n",
      "0.396484 0.392578         2048         2048.0        4        1        6\n",
      "0.412598 0.428711         4096         4096.0        4        4        3\n",
      "0.411621 0.410645         8192         8192.0        4        4        9\n",
      "0.412231 0.412842        16384        16384.0        1        1        7\n",
      "0.408630 0.405029        32768        32768.0        4        4        9\n",
      "0.406998 0.405365        65536        65536.0        4        4       12\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 69874\n",
      "passes used = 1\n",
      "weighted example sum = 69874.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.407333\n",
      "total feature number = 618970\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t test -r pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:-1.33599 2:-4.18829 3:-5.10424 4:1.28751 5:-4.24916\r\n",
      "1:-1.33252 2:-2.2637 3:-1.84231 4:0.320449 5:-3.03934\r\n",
      "1:0.1727 2:-1.91199 3:-3.26753 4:-1.68744 5:-0.847286\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 3 pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, которая вычисляет `logloss` и `accuracy`, не загружая вектора в память. Используйте `softmax`, чтобы получить вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(ytest_input='ytest', pred_input='pred'):\n",
    "    n, error, loss = 0, 0, 0\n",
    "    reader_ytest = open(ytest_input, 'r')\n",
    "    reader_pred = open(pred_input, 'r')\n",
    "    \n",
    "    for label, pred in zip(reader_ytest, reader_pred):\n",
    "        # YOUR CODE HERE\n",
    "        def sigmoid(x):\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "\n",
    "        def dict_max(dictionary):  \n",
    "            values = list(dictionary.values())\n",
    "            keys = list(dictionary.keys())\n",
    "            return keys[values.index(max(values))]\n",
    "\n",
    "        label = int(label)\n",
    "        probabilities = {\n",
    "            int(item[:item.find(':')]): sigmoid(float(item[item.find(':') + 1:]))\n",
    "            for item in pred.split(' ')\n",
    "        }\n",
    "        loss += np.log(probabilities[label])\n",
    "        if (dict_max(probabilities) != label):\n",
    "            error += 1\n",
    "        n += 1\n",
    "\n",
    "    reader_ytest.close()\n",
    "    reader_pred.close()\n",
    "    return - loss / n, 1 - float(error) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 1.06088\n",
      "accuracy = 0.59267\n"
     ]
    }
   ],
   "source": [
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На оригинальных данных `logloss` должен быть меньше `0.20`, `accuracy` больше `0.95`. Если это не так, то скорее всего у вас ошибка.\n",
    "\n",
    "Теперь попробуем улучшить модель, добавив новые признаки, порождаемые словами. В `vowpal wabbit` есть возможность делать это прямо на лету. Воспользуйтесь параметрами `affix`, `ngram`, `skips`.\n",
    "\n",
    "Далее везде при подборе параметров ориентируйтесь на улучшение `logloss`. Используйте `--quiet` или `-P`, чтобы избавиться от длинных выводов при обучении и применении моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 1.16406\n",
      "accuracy = 0.56745\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --ngram 1 --ngram 2 --ngram 3 --ngram 4 --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто качество `vw` модели получается учушить увеличением числа проходов по обучающей выборке (параметр `--passes`) и увеличением числа бит хэш-функции для уменьшения числа коллизий признаков (параметр `-b`). Подробнее про то, где в `vowpal wabbit` используется хэш-функция, можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction). Как меняется качество при изменении этих параметров? Верно ли, что при увеличении значений параметров `--passes` и `-b` качество всегда не убывает и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 2.29411\n",
      "accuracy = 0.50724\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --ngram 1 --ngram 2 --ngram 3 --ngram 4 --quiet --passes 5 --cache_file cache_file -b 16\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь интерес представляет то, какие признаки оказались наиболее важными для модели. Для этого сначала переведем модель в читаемый формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 8.4.0\r\n",
      "Id \r\n",
      "Min label:-50\r\n",
      "Max label:50\r\n",
      "bits:16\r\n",
      "lda:0\r\n",
      "4 ngram:1 2 3 4 \r\n",
      "0 skip:\r\n",
      "options: --oaa 5\r\n",
      "Checksum: 3546572062\r\n",
      ":0\r\n",
      "Constant:10976:-2.67334\r\n",
      "Constant[1]:10977:-3.63295\r\n",
      "Constant[2]:10978:-3.00891\r\n",
      "Constant[3]:10979:2.62512\r\n",
      "Constant[4]:10980:-2.82301\r\n",
      "a:19856:0.772795\r\n",
      "a[1]:19857:0.661652\r\n",
      "a[2]:19858:0.65739\r\n",
      "a[3]:19859:-0.316702\r\n",
      "a[4]:19860:1.12167\r\n",
      "a^a:46304:-0.28654\r\n",
      "a^a[1]:46305:-0.183126\r\n",
      "a^a[2]:46306:-0.335523\r\n",
      "a^a[3]:46307:0.0683122\r\n",
      "a^a[4]:46308:-0.481479\r\n",
      "a^a^directory:14304:-0.134231\r\n",
      "a^a^directory[1]:14305:-0.24279\r\n",
      "a^a^directory[2]:14306:-0.00054518\r\n",
      "a^a^directory[3]:14307:0.174285\r\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t --invert_hash model.readable train --quiet\n",
    "! head -n 30 model.readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые несколько строк соответствуют информации о модели. Далее следуют строчки вида `feature[label]:hash:weight`. Выделите для каждого класса 10 признаков с наибольшими по модулю весами. Постарайтесь сделать ваш алгоритм прохода по файлу константным по памяти. Например, можно воспользоваться [кучей](https://docs.python.org/2/library/heapq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import re\n",
    "from heapq import heappop, heappush\n",
    "\n",
    "with open('model.readable') as file:\n",
    "    counter = 0\n",
    "    label_regular = re.compile(r'\\[\\d\\]')\n",
    "    feature_regular = re.compile(r'^(.+):\\d+:')\n",
    "    weight_reqular = re.compile(r':\\d+:(.+)$')\n",
    "    heaps = {i: [] for i in STATUS_DICT.values()}\n",
    "    for line in file:\n",
    "        if counter > 10:\n",
    "            label = label_regular.findall(line)\n",
    "            if len(label) != 0:\n",
    "                label = int(label[0][1:-1])\n",
    "            else:\n",
    "                label = None\n",
    "            feature = feature_regular.findall(line)[0]\n",
    "            if feature[-1] == ']':\n",
    "                feature = feature[:-3]\n",
    "            weight = float(weight_reqular.findall(line)[0])\n",
    "\n",
    "            if label is not None:\n",
    "                if ((weight, feature) not in heaps[label]):\n",
    "                    heappush(heaps[label], (weight, feature))\n",
    "                    if len(heaps[label]) > 10:\n",
    "                        heappop(heaps[label])\n",
    "                else:\n",
    "                    print('!!!')\n",
    "            if counter == 5000:\n",
    "                break\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.584254, 'a^break^of^over'),\n",
       " (0.636991, 'a^appengine^datastore^element'),\n",
       " (0.651453, 'a^basic^bashrc^file'),\n",
       " (0.636991, 'a^bar^like'),\n",
       " (0.647641, 'a^bit^int^to'),\n",
       " (1.5843, 'a^background^location'),\n",
       " (0.788221, 'a^ball^so^when'),\n",
       " (0.661652, 'a'),\n",
       " (0.944992, 'a^bot^script'),\n",
       " (0.802438, 'a^badge^precognitive')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heaps[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Добавим признаки, извлеченные из текста поста (поле `BodyMarkdown`). В этом поле находится более подробная информация о вопросе, и часто туда помещают код, формулы и т.д. При удалении пунктуации мы потеряем много полезной информации, однако модель \"мешка слов\" на сырых данных может сильно раздуть признаковое пространство. В таких случаях работают с n-граммами на символах. <br>\n",
    "Будьте осторожны: символы \"`:`\" и \"`|`\" нельзя использовать в названиях признаков, поскольку они являются служебными для `vw`-формата. Замените эти символы на два других редко встречающихся в выборке (или вообще не встречающихся). Также не забудьте про \"`\\n`\". <br>\n",
    "Поскольку для каждого документа одна n-грамма может встретиться далеко не один раз, то будет экономнее записывать признаки в формате `[n-грамма]:[число вхождений]`.\n",
    "\n",
    "Также добавьте тэги (поля вид `TagN`). Приветствуется добавление информации о пользователе из других полей. Только не используйте `PostClosedDate` – в нем содержится информация о таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_ngram_body(row, ngram=3):\n",
    "    # YOUR CODE HERE\n",
    "    body_text = re.sub('[\\|\\:]', '', row['BodyMarkdown'])\n",
    "    body_text = re.sub('\\n', ' ', body_text)\n",
    "    def ngram_from_word(counter, word, ngram=2):\n",
    "        for index in range(1, len(word) - ngram + 1):\n",
    "            counter[word[index:(index + ngram)]] += 1\n",
    "    ngrams_dict = Counter()\n",
    "    for word in body_text.split(' '):\n",
    "        ngram_from_word(ngrams_dict, word, ngram)\n",
    "    return ' '.join([key + ':' + str(ngrams_dict[key]) for key in ngrams_dict])\n",
    "\n",
    "\n",
    "def extract_tags(row):\n",
    "    # YOUR CODE HERE\n",
    "    return ' '.join(row['Tag' + str(i)] for i in range(1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все вместе. Реализуйте экстрактор признаков, который выделяет каждую подгруппу в отдельный namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractors_list = [\n",
    "    ('t', extract_title),\n",
    "    ('b', extract_ngram_body),\n",
    "    ('a', extract_tags)\n",
    "] # (namespace, extractor)\n",
    "\n",
    "\n",
    "def make_feature_extractor(extractors_list):\n",
    "    def feature_extractor(row):\n",
    "        # YOUR CODE HERE\n",
    "        return ' '.join(['|' + name + ' ' + extractor(row) for name, extractor in extractors_list])\n",
    "    return feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2vw(make_feature_extractor(extractors_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 |t for mongodb is it better to reference an object or use a natural string key |b Iam:1 xed:1 eda:1 rta:1 rom:1 Oco:1 ldk:1 ldi:1 edi:1 itb:1 zeo:1 bes:1 \r",
      "\r",
      "-:1 eds:1 tin:1 -ob:1 ffe:1 ose:1 lle:3 y.I:1 ybe:1 now:1 nga:1 han:1 sho:1 gth:1 ies:1 Isu:1 ngt:1 ngu:5 hou:1 veb:1 ngq:1 vea:1 tai:1 eth:1 owo:1 has:1 fin:1 rto:1 hav:2 ges:2 ert:2 spe:1 it':1 nof:1 amb:1 din:2 ceh:1 gec:1 nyb:1 hic:1 ces:2 cer:1 fth:1 sk\r",
      ":1 ace:1 tIs:1 tbe:1 nor:1 nla:1 gua:5 rea:1 tco:1 dif:1 efe:2 iff:1 een:1 \r",
      "\r",
      "I:1 eed:1 tic:1 \r",
      "\r",
      "A:1 upp:1 dis:1 ebe:1 int:1 -ea:1 ten:2 oin:1 ebo:1 oll:3 ke\":1 tId:1 eto:1 are:1 sea:1 wof:1 ous:1 sen:2 ter:1 or\":1 ode:1 sei:1 uer:1 esw:2 ich:1 ize:1 whe:1 \"or:1 ret:1 s.I:1 'sa:1 ese:1 ren:3 tte:1 sup:1 pee:1 dse:1 ref:2 esi:2 doi:1 lec:3 Obj:1 eco:1 omi:1 eLa:2 use:1 orp:1 ors:1 nth:1 asa:2 ect:5 que:1 ntl:1 key:2 \r",
      "-s:1 pra:1 ore:1 nte:2 ctI:1 pus:1 ndi:2 ild:1 cor:1 obj:1 etw:1 ett:1 ata:1 hes:2 nde:1 Any:1 isk:1 chh:1 tla:1 omp:1 cod:1 act:1 dkn:1 es.:1 \r",
      "Is:1 Iha:1 com:1 cti:5 ake:2 yli:1 sak:1 bje:2 her:1 rpu:1 ono:2 sof:1 e\r",
      "-:2 ppo:1 pos:1 ond:1 ndt:1 ISO:1 uld:1 fLa:1 mbu:1 en\r",
      ":1 n\r",
      "\r",
      ":1 heI:1 swh:2 eIS:1 \"en:1 fre:1 twe:1 uso:1 oul:1 eyl:1 tot:1 tou:1 hed:1 jec:2 -th:1 fer:3 atI:1 eha:1 n\r",
      "-:1 oth:2 eak:1 kno:1 eac:1 \"fr:1 .Ih:1 heL:2 nci:1 bui:1 ice:1 rst:1 eas:2 ear:1 gac:1 nce:3 Ish:1 atc:1 dex:1 fr\":1 dth:1 eit:1 on\r",
      ":1 hat:2 sto:1 sth:1 cin:1 ey.:1 \r",
      "An:1 ere:4 ain:1 stp:1 ge\r",
      ":2 dea:1 gqu:1 eri:1 bet:2 seb:1 and:1 SOc:1 ang:5 dan:1 rac:1 t's:1 sac:2 bot:1 pro:1 uil:1 inl:1 seo:1 hha:1 ndo:1 ind:3 ave:2 ing:3 ase:1 uag:5 wee:1 Lan:3 enc:4 sit:1 \r",
      "-t:1 k\r",
      "\r",
      ":1 anO:1 nOb:1 lik:1 \r",
      "-o:1 tio:3 ent:3 \r",
      "-e:1 r\"f:1 mis:1 sin:1 tpr:1 ike:1 e\"e:1 lan:2 \"?\r",
      ":1 aon:1 whi:1 ofL:1 tor:1 ion:3 Isi:1 est:2 n\"o:1 -sp:1 .Is:1 rie:1 aco:3 ?\r",
      "\r",
      ":1 Ida:1 r\"?:1 dat:1 en\":1 exe:1 eof:2 age:5 ofi:1 col:3 ofr:1 cet:1 ise:1 oft:1 siz:1 mpr:1 the:6 tao:1 tha:3 |a mongodb    \r\n"
     ]
    }
   ],
   "source": [
    "! head -n 1 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 1.07433\n",
      "accuracy = 0.59500\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с другими параметрами модели. Добавьте квадратичные взаимодействия между различными блоками признаков, измените параметры оптимизатора, добавьте регуляризацию и т.д. Совсем необязательно перебирать все параметры по сетке и добиваться оптимального качества. Для нас важнее то, насколько хорошо вы разобрались с возможностями библиотеки и продемонстрировали это.\n",
    "\n",
    "Выберите не менее трех параметров. Для каждого из них объясните, почему по вашему мнению его изменение может улучшить качество модели, подберите оптимальное значение. Можете перебрать несколько значений \"руками\", а можете воспользоваться [vw-hypersearch](https://github.com/JohnLangford/vowpal_wabbit/wiki/Using-vw-hypersearch) или [vw-hyperopt](https://github.com/JohnLangford/vowpal_wabbit/blob/master/utl/vw-hyperopt.py) ([статья на хабре](https://habrahabr.ru/company/dca/blog/272697/)). Какие параметры повлияли на улучшение качества сильнее всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
