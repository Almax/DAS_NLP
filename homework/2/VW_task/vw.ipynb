{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowpal Wabbit в NLP\n",
    "Автоматическая обработка текстов - 2017, семинар 4.\n",
    "\n",
    "В этом семинаре мы познакомимся с библиотекой Vowpal Wabbit и решим с его помощью задачу многоклассовой классификации на больших данных. \n",
    "Данные скачайте [здесь](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data) или запустите следующие две ячейки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget https://www.dropbox.com/s/r0q0p0uprhcp8bb/train-sample.zip\n",
    "! unzip train-sample.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget https://www.dropbox.com/s/50vw2gsglc91f6o/train.zip\n",
    "! unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы на семинаре не тратить время на обработку и обучение моделей на всех данных, предлагается использовать только небольшую подвыборку (`train-sample.csv`). Но сдавать ноутбук все равно необходимо с результатами на **всех** данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BodyMarkdown': \"I'm new to C#, and I want to use a trackbar for the forms opacity\\r\\nThis is my code\\r\\n\\r\\n    decimal trans = trackBar1.Value / 5000\\r\\n    this.Opacity = trans\\r\\n\\r\\nWhen I try to build it, I get this error\\r\\n\\r\\n**Cannot implicitly convert type 'decimal' to 'double**\\r\\n\\r\\nI tried making trans a double, but then the control doesn't work. This code worked fine for me in VB.NET. Any suggestions?\",\n",
       " 'OpenStatus': 'open',\n",
       " 'OwnerCreationDate': '07/31/2008 21:33:24',\n",
       " 'OwnerUndeletedAnswerCountAtPostTime': '0',\n",
       " 'OwnerUserId': '8',\n",
       " 'PostClosedDate': '',\n",
       " 'PostCreationDate': '07/31/2008 21:42:52',\n",
       " 'PostId': '4',\n",
       " 'ReputationAtPostCreation': '1',\n",
       " 'Tag1': 'c#',\n",
       " 'Tag2': '',\n",
       " 'Tag3': '',\n",
       " 'Tag4': '',\n",
       " 'Tag5': '',\n",
       " 'Title': 'Decimal vs Double?'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "INPUT_DATA = 'train.csv'\n",
    "#INPUT_DATA = 'train-sample.csv'\n",
    "\n",
    "reader = csv.DictReader(open(INPUT_DATA))\n",
    "dict(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект выборки соответствует некоторому посту на Stack Overflow. Требуется построить модель, определяющую статус поста. Подробнее про задачу и формат данных можно прочитать на [странице соревнования](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow).\n",
    "\n",
    "Перед обучением модели из Vowpal Wabbit данные следует сохранить в специальный формат: <br>\n",
    "`label |namespace1 feature1:value1 feature2 feature3:value3 |namespace2 ...` <br>\n",
    "Записи `feature` и `feature:1.0` эквивалентны. Выделение признаков в смысловые подгруппы (namespaces) позволяет создавать взаимодействия между ними. Подробнее про формат входных данных можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format).\n",
    "\n",
    "Ниже реализована функция, которая извлекает признаки с помощью подаваемого на вход экстрактора, разбивает данные на трейн и тест и записывает их на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATUSES = ['not a real question', 'not constructive', 'off topic', 'open', 'too localized']\n",
    "STATUS_DICT = {status: i+1 for i, status in enumerate(STATUSES)}\n",
    "\n",
    "def data2vw(features_extractor, train_output='train', test_output='test', ytest_output='ytest'):\n",
    "    reader = csv.DictReader(open(INPUT_DATA))\n",
    "    writer_train = open(train_output, 'w')\n",
    "    writer_test = open(test_output, 'w')\n",
    "    writer_ytest = open(ytest_output, 'w')\n",
    "    \n",
    "    for row in reader:\n",
    "        label = STATUS_DICT[row['OpenStatus']]\n",
    "        features = features_extractor(row)\n",
    "        output_line = '%s %s\\n' % (label, features)\n",
    "        if int(row['PostId']) % 2 == 0:\n",
    "            writer_train.write(output_line)\n",
    "        else:\n",
    "            writer_test.write(output_line)\n",
    "            writer_ytest.write('%s\\n' % label)\n",
    "            \n",
    "    writer_train.close()\n",
    "    writer_test.close()\n",
    "    writer_ytest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с простейшей модели. В качестве признаков возьмите заголовки и очистите их: приведите символы к нижнему регистру, удалите пунктуацию. Также приветствуется использование стеммеров/лемматизаторов, однако учтите, что они могут сильно замедлить скорость обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_title(row):\n",
    "    title = row['Title']\n",
    "    # YOUR CODE HERE\n",
    "    return ''.join([character for character in title.lower() if (character.isalpha() or character == ' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2vw(lambda row: '| %s' % extract_title(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | decimal vs double\r\n",
      "4 | percentage width child in absolutely positioned parent doesnt work in ie\r\n",
      "4 | tools for porting j code to c\r\n",
      "4 | throw error in mysql trigger\r\n",
      "4 | whats the difference between mathfloor and mathtruncate\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 5 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим `vw` модель. Параметр `-d` отвечает за путь к обучающей выборке, `-f` – за путь к модели, `--oaa` – за режим мультиклассовой классификации `one-against-all`. Подробное описание всех параметров можно найти [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments) или вызвав `vw --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = model\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = train\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        4        1        4\n",
      "0.500000 0.000000            2            2.0        4        4       12\n",
      "0.250000 0.000000            4            4.0        4        4        6\n",
      "0.125000 0.000000            8            8.0        4        4        7\n",
      "0.062500 0.000000           16           16.0        4        4        4\n",
      "0.062500 0.062500           32           32.0        4        4        9\n",
      "0.046875 0.031250           64           64.0        4        4        5\n",
      "0.062500 0.078125          128          128.0        4        4       11\n",
      "0.089844 0.117188          256          256.0        4        4        8\n",
      "0.070312 0.050781          512          512.0        4        4        5\n",
      "0.066406 0.062500         1024         1024.0        4        4        8\n",
      "0.063965 0.061523         2048         2048.0        4        4        6\n",
      "0.056641 0.049316         4096         4096.0        4        4       11\n",
      "0.053101 0.049561         8192         8192.0        4        4        6\n",
      "0.043518 0.033936        16384        16384.0        4        4       14\n",
      "0.033569 0.023621        32768        32768.0        4        4       15\n",
      "0.023666 0.013763        65536        65536.0        4        4        7\n",
      "0.016594 0.009521       131072       131072.0        4        4       12\n",
      "0.011841 0.007088       262144       262144.0        4        4       14\n",
      "0.011797 0.011753       524288       524288.0        4        4       11\n",
      "0.016258 0.020720      1048576      1048576.0        4        4       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685253\n",
      "passes used = 1\n",
      "weighted example sum = 1685253.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.020987\n",
      "total feature number = 15261066\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим модель к тестовой выборке и сохраним предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "raw predictions = pred\n",
      "Num weight bits = 18\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = test\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        4        4        9\n",
      "0.000000 0.000000            2            2.0        4        4        7\n",
      "0.000000 0.000000            4            4.0        4        4        8\n",
      "0.125000 0.250000            8            8.0        4        4        6\n",
      "0.125000 0.125000           16           16.0        4        4        7\n",
      "0.156250 0.187500           32           32.0        4        4       10\n",
      "0.093750 0.031250           64           64.0        4        4        8\n",
      "0.117188 0.140625          128          128.0        4        4        8\n",
      "0.125000 0.132812          256          256.0        4        4       15\n",
      "0.109375 0.093750          512          512.0        4        4       11\n",
      "0.095703 0.082031         1024         1024.0        4        4       10\n",
      "0.084473 0.073242         2048         2048.0        4        4       14\n",
      "0.065430 0.046387         4096         4096.0        4        4        7\n",
      "0.060791 0.056152         8192         8192.0        4        4        4\n",
      "0.050110 0.039429        16384        16384.0        4        4        6\n",
      "0.039825 0.029541        32768        32768.0        4        4       14\n",
      "0.029327 0.018829        65536        65536.0        4        4        8\n",
      "0.021118 0.012909       131072       131072.0        4        4       10\n",
      "0.015690 0.010262       262144       262144.0        4        4        6\n",
      "0.014833 0.013977       524288       524288.0        4        4        5\n",
      "0.018147 0.021460      1048576      1048576.0        4        4       11\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1685275\n",
      "passes used = 1\n",
      "weighted example sum = 1685275.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.022069\n",
      "total feature number = 15264873\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t test -r pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:-4.35195 2:-5.91848 3:-4.50574 4:2.55012 5:-6.68008\r\n",
      "1:-7.03339 2:-7.67415 3:-6.85027 4:4.34536 5:-6.29331\r\n",
      "1:-4.26178 2:-5.55279 3:-5.30194 4:2.89059 5:-7.50815\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 3 pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, которая вычисляет `logloss` и `accuracy`, не загружая вектора в память. Используйте `softmax`, чтобы получить вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(ytest_input='ytest', pred_input='pred'):\n",
    "    import numpy as np\n",
    "    n, error, loss = 0, 0, 0\n",
    "    reader_ytest = open(ytest_input, 'r')\n",
    "    reader_pred = open(pred_input, 'r')\n",
    "    \n",
    "    for label, pred in zip(reader_ytest, reader_pred):\n",
    "        # YOUR CODE HERE\n",
    "        scores = np.array([\n",
    "            float(item[item.find(':') + 1:])\n",
    "            for item in pred.split(' ')\n",
    "        ])\n",
    "        label = int(label)\n",
    "        probabilities = np.exp(scores) / np.sum(np.exp(scores))\n",
    "        loss += np.log(probabilities[label - 1])\n",
    "        if ((np.argmax(probabilities) + 1) != label):\n",
    "            error += 1\n",
    "        n += 1\n",
    "\n",
    "    reader_ytest.close()\n",
    "    reader_pred.close()\n",
    "    return - loss / n, 1 - float(error) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14684\n",
      "accuracy = 0.97793\n"
     ]
    }
   ],
   "source": [
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На оригинальных данных `logloss` должен быть меньше `0.20`, `accuracy` больше `0.95`. Если это не так, то скорее всего у вас ошибка.\n",
    "\n",
    "Теперь попробуем улучшить модель, добавив новые признаки, порождаемые словами. В `vowpal wabbit` есть возможность делать это прямо на лету. Воспользуйтесь параметрами `affix`, `ngram`, `skips`.\n",
    "\n",
    "Далее везде при подборе параметров ориентируйтесь на улучшение `logloss`. Используйте `--quiet` или `-P`, чтобы избавиться от длинных выводов при обучении и применении моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.18119\n",
      "accuracy = 0.97577\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Добавляем n-граммы разных длин\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --ngram 2 --ngram 3 --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.16338\n",
      "accuracy = 0.97785\n"
     ]
    }
   ],
   "source": [
    "# Добавляем n-граммы и n-skips разных длин\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --skips 3 --ngram 4 --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.13970\n",
      "accuracy = 0.97818\n"
     ]
    }
   ],
   "source": [
    "# Добавляем суффиксы\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --affix +2 --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто качество `vw` модели получается учушить увеличением числа проходов по обучающей выборке (параметр `--passes`) и увеличением числа бит хэш-функции для уменьшения числа коллизий признаков (параметр `-b`). Подробнее про то, где в `vowpal wabbit` используется хэш-функция, можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction). Как меняется качество при изменении этих параметров? Верно ли, что при увеличении значений параметров `--passes` и `-b` качество всегда не убывает и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.54994\n",
      "accuracy = 0.97112\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "#  Теперь запустим больше проходов по выборке и увеличим размер хеша.\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --skips 3 --ngram 4 --quiet --passes 5 --cache_file cache_file -b 20\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление фичей в основном только ухудшает качество. Лишь добавление суффиксов небольшой длины увеличило его. Увеличение числапроходов и размера хеша уменьшает качество еще сильнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь интерес представляет то, какие признаки оказались наиболее важными для модели. Для этого сначала переведем модель в читаемый формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Вернем лучшую модель, которая была\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --affix +2 --quiet\n",
    "! vw -i model -t test -r pred --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 8.4.0\r\n",
      "Id \r\n",
      "Min label:-50\r\n",
      "Max label:50\r\n",
      "bits:18\r\n",
      "lda:0\r\n",
      "0 ngram:\r\n",
      "0 skip:\r\n",
      "options: --affix +2 --oaa 5\r\n",
      "Checksum: 32408175\r\n",
      ":0\r\n",
      "Constant:142048:-1.88053\r\n",
      "Constant[1]:142049:-2.94652\r\n",
      "Constant[2]:142050:-2.42378\r\n",
      "Constant[3]:142051:1.91574\r\n",
      "Constant[4]:142052:-2.59536\r\n",
      "a:216464:-0.0159857\r\n",
      "a[1]:216465:0.129169\r\n",
      "a[2]:216466:-0.0123258\r\n",
      "a[3]:216467:0.00122789\r\n",
      "a[4]:216468:0.0639045\r\n",
      "aa:36168:-1.56558\r\n",
      "aa[1]:36169:-1.64298\r\n",
      "aa[2]:36170:-2.50951\r\n",
      "aa[3]:36171:0.887328\r\n",
      "aa[4]:36172:-1.23849\r\n",
      "aaa:196024:-1.24977\r\n",
      "aaa[1]:196025:-0.972496\r\n",
      "aaa[2]:196026:-0.842369\r\n",
      "aaa[3]:196027:0.945228\r\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t --invert_hash model.readable train --quiet\n",
    "! head -n 30 model.readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые несколько строк соответствуют информации о модели. Далее следуют строчки вида `feature[label]:hash:weight`. Выделите для каждого класса 10 признаков с наибольшими по модулю весами. Постарайтесь сделать ваш алгоритм прохода по файлу константным по памяти. Например, можно воспользоваться [кучей](https://docs.python.org/2/library/heapq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import re\n",
    "from heapq import heappop, heappush\n",
    "\n",
    "with open('model.readable') as file:\n",
    "    counter = 0\n",
    "    label_regular = re.compile(r'\\[\\d\\]')\n",
    "    feature_regular = re.compile(r'^(.+):\\d+:')\n",
    "    weight_reqular = re.compile(r':\\d+:(.+)$')\n",
    "    heaps = {i: [] for i in STATUS_DICT.values()}\n",
    "    heap_size = 10\n",
    "    for line in file:\n",
    "        if counter > 10:\n",
    "            label = label_regular.findall(line)\n",
    "            if len(label) != 0:\n",
    "                label = int(label[0][1:-1])\n",
    "            else:\n",
    "                label = None\n",
    "            feature = feature_regular.findall(line)[0]\n",
    "            if feature[-1] == ']':\n",
    "                feature = feature[:-3]\n",
    "            weight = float(weight_reqular.findall(line)[0])\n",
    "\n",
    "            if label is not None:\n",
    "                if ((weight, feature) not in heaps[label]):\n",
    "                    heappush(heaps[label], (weight, feature))\n",
    "                    if len(heaps[label]) > heap_size:\n",
    "                        heappop(heaps[label])\n",
    "                else:\n",
    "                    print('!!!')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на кучи для некоторых статусов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.46947, 'interview'),\n",
       " (1.46947, 'javajse'),\n",
       " (1.46947, 'petri'),\n",
       " (1.46947, 'xdebugfilelinkformat'),\n",
       " (1.46947, 'javalangruntime'),\n",
       " (1.46947, 'tun'),\n",
       " (1.78573, 'iphoneobjectivecc'),\n",
       " (1.78573, 'destroyed'),\n",
       " (1.78573, 'appendstring'),\n",
       " (1.78573, 'books')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heaps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.05868, 'ubuntu'),\n",
       " (1.05868, 'usermetadata'),\n",
       " (1.09357, 'affix^+2=ub'),\n",
       " (1.09357, 'checknot'),\n",
       " (1.05868, 'webxm'),\n",
       " (1.09357, 'hashmapunorderd'),\n",
       " (1.09357, 'skbuffs'),\n",
       " (1.09357, 'sqlsrvfetchobject'),\n",
       " (1.09357, 'resolutiontiming'),\n",
       " (1.09357, 'integrityerror')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heaps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.525523, 'sshconnent'),\n",
       " (0.525523, 'statsd'),\n",
       " (0.540231, 'remarks'),\n",
       " (0.540231, 'affix^+2=ch'),\n",
       " (0.525523, 'surfacegame'),\n",
       " (0.540231, 'splicelike'),\n",
       " (0.540231, 'servergo'),\n",
       " (0.540231, 'chackunchack'),\n",
       " (0.540231, 'popuphtml'),\n",
       " (0.540231, 'mapthread')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heaps[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что кое-где суффиксы являются сильно значимыми признаками. Таким образом и следует выбирать, какие фичи добавлять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Добавим признаки, извлеченные из текста поста (поле `BodyMarkdown`). В этом поле находится более подробная информация о вопросе, и часто туда помещают код, формулы и т.д. При удалении пунктуации мы потеряем много полезной информации, однако модель \"мешка слов\" на сырых данных может сильно раздуть признаковое пространство. В таких случаях работают с n-граммами на символах. <br>\n",
    "Будьте осторожны: символы \"`:`\" и \"`|`\" нельзя использовать в названиях признаков, поскольку они являются служебными для `vw`-формата. Замените эти символы на два других редко встречающихся в выборке (или вообще не встречающихся). Также не забудьте про \"`\\n`\". <br>\n",
    "Поскольку для каждого документа одна n-грамма может встретиться далеко не один раз, то будет экономнее записывать признаки в формате `[n-грамма]:[число вхождений]`.\n",
    "\n",
    "Также добавьте тэги (поля вид `TagN`). Приветствуется добавление информации о пользователе из других полей. Только не используйте `PostClosedDate` – в нем содержится информация о таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_ngram_body(row, ngram=3):\n",
    "    # YOUR CODE HERE\n",
    "    body_text = re.sub('\\|', 'ы', row['BodyMarkdown'])\n",
    "    body_text = re.sub('\\:', 'я', body_text)\n",
    "    body_text = re.sub('\\n+', '. ', body_text)\n",
    "    def ngram_from_word(counter, word, ngram=2):\n",
    "        for index in range(1, len(word) - ngram + 1):\n",
    "            counter[word[index:(index + ngram)]] += 1\n",
    "    ngrams_dict = Counter()\n",
    "    for word in body_text.split(' '):\n",
    "        ngram_from_word(ngrams_dict, word, ngram)\n",
    "    return ' '.join([key + ':' + str(ngrams_dict[key]) for key in ngrams_dict])\n",
    "\n",
    "\n",
    "def extract_tags(row):\n",
    "    # YOUR CODE HERE\n",
    "    return ' '.join(row['Tag' + str(i)] for i in range(1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все вместе. Реализуйте экстрактор признаков, который выделяет каждую подгруппу в отдельный namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractors_list = [\n",
    "    ('t', extract_title),\n",
    "    ('b', extract_ngram_body),\n",
    "    ('a', extract_tags)\n",
    "] # (namespace, extractor)\n",
    "\n",
    "\n",
    "def make_feature_extractor(extractors_list):\n",
    "    def feature_extractor(row):\n",
    "        # YOUR CODE HERE\n",
    "        return ' '.join(['|' + name + ' ' + extractor(row) for name, extractor in extractors_list])\n",
    "    return feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 |t decimal vs double |b itl:1 rol:1 Val:1 kba:1 ugg:1 r1.:1 *Ca:1 ity:2 ror:1 alu:1 ima:2 ver:1 tio:1 Opa:1 ied:1 is.:1 ges:1 his:4 Bar:1 al':1 mpl:1 nve:1 Can:1 not:1 bar:1 tro:1 kBa:1 **\r",
      ":1 rro:1 rms:1 oub:2 le*:1 le,:1 ode:2 ici:1 est:1 s.O:1 or\r",
      ":1 *\r",
      ".:1 lue:1 ble:2 esn:1 ar1:1 ked:1 oes:1 ntr:1 eci:2 gge:1 orm:1 ork:2 pli:1 ild:1 ack:2 .Op:1 aci:2 aki:1 e\r",
      ".:1 rke:1 de\r",
      ":1 ons:1 NET:1 onv:1 ont:1 0\r",
      ".:1 .NE:1 ns?:1 rk.:1 hen:2 ert:1 ns\r",
      ":1 sti:1 cim:2 n't:1 B.N:1 .Va:1 cit:3 dec:1 r\r",
      ".:1 tly:1 nno:1 sn':1 rac:2 ran:3 ann:1 uil:1 ant:1 s\r",
      ".:1 ans:3 ine:1 rie:1 ty\r",
      ":1 ing:1 e**:1 lic:1 pac:2 ype:1 ET.:1 ckB:1 ion:1 000:1 kin:1 ubl:2 mal:2 y\r",
      ".:1 1.V:1 ckb:1 00\r",
      ":1 dou:1 |a c#    \r\n"
     ]
    }
   ],
   "source": [
    "data2vw(make_feature_extractor(extractors_list))\n",
    "! head -n 1 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14086\n",
      "accuracy = 0.97858\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с другими параметрами модели. Добавьте квадратичные взаимодействия между различными блоками признаков, измените параметры оптимизатора, добавьте регуляризацию и т.д. Совсем необязательно перебирать все параметры по сетке и добиваться оптимального качества. Для нас важнее то, насколько хорошо вы разобрались с возможностями библиотеки и продемонстрировали это.\n",
    "\n",
    "Выберите не менее трех параметров. Для каждого из них объясните, почему по вашему мнению его изменение может улучшить качество модели, подберите оптимальное значение. Можете перебрать несколько значений \"руками\", а можете воспользоваться [vw-hypersearch](https://github.com/JohnLangford/vowpal_wabbit/wiki/Using-vw-hypersearch) или [vw-hyperopt](https://github.com/JohnLangford/vowpal_wabbit/blob/master/utl/vw-hyperopt.py) ([статья на хабре](https://habrahabr.ru/company/dca/blog/272697/)). Какие параметры повлияли на улучшение качества сильнее всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в фичи n-граммы разных длин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Добавим n-граммы разной длины\n",
    "extractors_list = [\n",
    "    ('t', extract_title),\n",
    "    ('b', lambda row: extract_ngram_body(row, 2)),\n",
    "    ('c', lambda row: extract_ngram_body(row, 3)),\n",
    "    ('d', lambda row: extract_ngram_body(row, 4)),\n",
    "    ('a', extract_tags)\n",
    "] # (namespace, extractor)\n",
    "\n",
    "data2vw(make_feature_extractor(extractors_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14563\n",
      "accuracy = 0.97764\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавлене таких фичей существенно качество не улучшило. Но небольшой прирост все же дало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Попробуем l1 и l2 регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.12954\n",
      "accuracy = 0.97925\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l2 0.000001\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.15668\n",
      "accuracy = 0.97927\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l1 0.000001\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, l2 регуляризация дала значителное улучшение, а l1 оказалась бесполезной. Лучше брать l2 регуляризацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь попробуем улучшить качество, поменяв различный параметры оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 12.72904\n",
      "accuracy = 0.50755\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --sgd --quiet --passes 1 --cache_file cache_file\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 11.29637\n",
      "accuracy = 0.53042\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --sgd --quiet --passes 5 --cache_file cache_file\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 11.92278\n",
      "accuracy = 0.48418\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --sgd --quiet --passes 10 --cache_file cache_file\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что для sgd увеличение числа проходов все же положительно складывается на качестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 2.00079\n",
      "accuracy = 0.95444\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --adaptive --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в целом изменение режима оптимизации приводит к значительно худшим результатам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем уменьшаять learning rate между проходами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.43511\n",
      "accuracy = 0.94437\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l2 0.000001 --passes 3 --cache_file cache_file --decay_learning_rate 0.05\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прироста достигнуть не получилось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом все ясно, самая главная команда: vw -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
