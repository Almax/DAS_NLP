{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vowpal Wabbit в NLP\n",
    "Автоматическая обработка текстов - 2017, семинар 4.\n",
    "\n",
    "В этом семинаре мы познакомимся с библиотекой Vowpal Wabbit и решим с его помощью задачу многоклассовой классификации на больших данных. \n",
    "Данные скачайте [здесь](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow/data) или запустите следующие две ячейки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget https://www.dropbox.com/s/r0q0p0uprhcp8bb/train-sample.zip\n",
    "! unzip train-sample.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! wget https://www.dropbox.com/s/50vw2gsglc91f6o/train.zip\n",
    "! unzip train.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы на семинаре не тратить время на обработку и обучение моделей на всех данных, предлагается использовать только небольшую подвыборку (`train-sample.csv`). Но сдавать ноутбук все равно необходимо с результатами на **всех** данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BodyMarkdown': \"I'm new to C#, and I want to use a trackbar for the forms opacity\\r\\nThis is my code\\r\\n\\r\\n    decimal trans = trackBar1.Value / 5000\\r\\n    this.Opacity = trans\\r\\n\\r\\nWhen I try to build it, I get this error\\r\\n\\r\\n**Cannot implicitly convert type 'decimal' to 'double**\\r\\n\\r\\nI tried making trans a double, but then the control doesn't work. This code worked fine for me in VB.NET. Any suggestions?\",\n",
       " 'OpenStatus': 'open',\n",
       " 'OwnerCreationDate': '07/31/2008 21:33:24',\n",
       " 'OwnerUndeletedAnswerCountAtPostTime': '0',\n",
       " 'OwnerUserId': '8',\n",
       " 'PostClosedDate': '',\n",
       " 'PostCreationDate': '07/31/2008 21:42:52',\n",
       " 'PostId': '4',\n",
       " 'ReputationAtPostCreation': '1',\n",
       " 'Tag1': 'c#',\n",
       " 'Tag2': '',\n",
       " 'Tag3': '',\n",
       " 'Tag4': '',\n",
       " 'Tag5': '',\n",
       " 'Title': 'Decimal vs Double?'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "INPUT_DATA = 'train.csv'\n",
    "#INPUT_DATA = 'train-sample.csv'\n",
    "\n",
    "reader = csv.DictReader(open(INPUT_DATA))\n",
    "dict(next(reader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждый объект выборки соответствует некоторому посту на Stack Overflow. Требуется построить модель, определяющую статус поста. Подробнее про задачу и формат данных можно прочитать на [странице соревнования](https://www.kaggle.com/c/predict-closed-questions-on-stack-overflow).\n",
    "\n",
    "Перед обучением модели из Vowpal Wabbit данные следует сохранить в специальный формат: <br>\n",
    "`label |namespace1 feature1:value1 feature2 feature3:value3 |namespace2 ...` <br>\n",
    "Записи `feature` и `feature:1.0` эквивалентны. Выделение признаков в смысловые подгруппы (namespaces) позволяет создавать взаимодействия между ними. Подробнее про формат входных данных можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Input-format).\n",
    "\n",
    "Ниже реализована функция, которая извлекает признаки с помощью подаваемого на вход экстрактора, разбивает данные на трейн и тест и записывает их на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATUSES = ['not a real question', 'not constructive', 'off topic', 'open', 'too localized']\n",
    "STATUS_DICT = {status: i+1 for i, status in enumerate(STATUSES)}\n",
    "\n",
    "def data2vw(features_extractor, train_output='train', test_output='test', ytest_output='ytest'):\n",
    "    reader = csv.DictReader(open(INPUT_DATA))\n",
    "    writer_train = open(train_output, 'w')\n",
    "    writer_test = open(test_output, 'w')\n",
    "    writer_ytest = open(ytest_output, 'w')\n",
    "    \n",
    "    for row in reader:\n",
    "        label = STATUS_DICT[row['OpenStatus']]\n",
    "        features = features_extractor(row)\n",
    "        output_line = '%s %s\\n' % (label, features)\n",
    "        if int(row['PostId']) % 2 == 0:\n",
    "            writer_train.write(output_line)\n",
    "        else:\n",
    "            writer_test.write(output_line)\n",
    "            writer_ytest.write('%s\\n' % label)\n",
    "            \n",
    "    writer_train.close()\n",
    "    writer_test.close()\n",
    "    writer_ytest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с простейшей модели. В качестве признаков возьмите заголовки и очистите их: приведите символы к нижнему регистру, удалите пунктуацию. Также приветствуется использование стеммеров/лемматизаторов, однако учтите, что они могут сильно замедлить скорость обработки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_title(row):\n",
    "    title = row['Title']\n",
    "    # YOUR CODE HERE\n",
    "    return ''.join([character for character in title.lower() if (character.isalpha() or character == ' ')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data2vw(lambda row: '| %s' % extract_title(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 5 train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим `vw` модель. Параметр `-d` отвечает за путь к обучающей выборке, `-f` – за путь к модели, `--oaa` – за режим мультиклассовой классификации `one-against-all`. Подробное описание всех параметров можно найти [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Command-line-arguments) или вызвав `vw --help`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим модель к тестовой выборке и сохраним предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! vw -i model -t test -r pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -n 3 pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию, которая вычисляет `logloss` и `accuracy`, не загружая вектора в память. Используйте `softmax`, чтобы получить вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scores(ytest_input='ytest', pred_input='pred'):\n",
    "    import numpy as np\n",
    "    n, error, loss = 0, 0, 0\n",
    "    reader_ytest = open(ytest_input, 'r')\n",
    "    reader_pred = open(pred_input, 'r')\n",
    "    \n",
    "    for label, pred in zip(reader_ytest, reader_pred):\n",
    "        # YOUR CODE HERE\n",
    "        scores = np.array([\n",
    "            float(item[item.find(':') + 1:])\n",
    "            for item in pred.split(' ')\n",
    "        ])\n",
    "        label = int(label)\n",
    "        probabilities = np.exp(scores) / np.sum(np.exp(scores))\n",
    "        loss += np.log(probabilities[label - 1])\n",
    "        if ((np.argmax(probabilities) + 1) != label):\n",
    "            error += 1\n",
    "        n += 1\n",
    "\n",
    "    reader_ytest.close()\n",
    "    reader_pred.close()\n",
    "    return - loss / n, 1 - float(error) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На оригинальных данных `logloss` должен быть меньше `0.20`, `accuracy` больше `0.95`. Если это не так, то скорее всего у вас ошибка.\n",
    "\n",
    "Теперь попробуем улучшить модель, добавив новые признаки, порождаемые словами. В `vowpal wabbit` есть возможность делать это прямо на лету. Воспользуйтесь параметрами `affix`, `ngram`, `skips`.\n",
    "\n",
    "Далее везде при подборе параметров ориентируйтесь на улучшение `logloss`. Используйте `--quiet` или `-P`, чтобы избавиться от длинных выводов при обучении и применении моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Добавляем n-граммы разных длин\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --ngram 2 --ngram 3 --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем n-граммы и n-skips разных длин\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --skips 3 --ngram 4 --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавляем суффиксы\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --affix +2 --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Часто качество `vw` модели получается учушить увеличением числа проходов по обучающей выборке (параметр `--passes`) и увеличением числа бит хэш-функции для уменьшения числа коллизий признаков (параметр `-b`). Подробнее про то, где в `vowpal wabbit` используется хэш-функция, можно прочитать [здесь](https://github.com/JohnLangford/vowpal_wabbit/wiki/Feature-Hashing-and-Extraction). Как меняется качество при изменении этих параметров? Верно ли, что при увеличении значений параметров `--passes` и `-b` качество всегда не убывает и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#  Теперь запустим больше проходов по выборке и увеличим размер хеша.\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --skips 3 --ngram 4 --quiet --passes 5 --cache_file cache_file -b 20\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление фичей в основном только ухудшает качество. Лишь добавление суффиксов небольшой длины увеличило его. Увеличение числапроходов и размера хеша уменьшает качество еще сильнее."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь интерес представляет то, какие признаки оказались наиболее важными для модели. Для этого сначала переведем модель в читаемый формат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Вернем лучшую модель, которая была\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --affix +2 --quiet\n",
    "! vw -i model -t test -r pred --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 8.4.0\r\n",
      "Id \r\n",
      "Min label:-50\r\n",
      "Max label:50\r\n",
      "bits:18\r\n",
      "lda:0\r\n",
      "0 ngram:\r\n",
      "0 skip:\r\n",
      "options: --affix +2 --oaa 5\r\n",
      "Checksum: 32408175\r\n",
      ":0\r\n",
      "Constant:142048:-2.02494\r\n",
      "Constant[1]:142049:-1.40876\r\n",
      "Constant[2]:142050:-1.60224\r\n",
      "Constant[3]:142051:1.32718\r\n",
      "Constant[4]:142052:-2.2639\r\n",
      "a^#visualstudio:174888:-0.0938351\r\n",
      "a^#visualstudio[1]:174889:-0.0834189\r\n",
      "a^#visualstudio[2]:174890:-0.0914689\r\n",
      "a^#visualstudio[3]:174891:0.0811847\r\n",
      "a^#visualstudio[4]:174892:-0.0951813\r\n",
      "a^--call:206552:-0.023634\r\n",
      "a^--call[1]:206553:-0.0270316\r\n",
      "a^--call[2]:206554:-0.0274786\r\n",
      "a^--call[3]:206555:0.0262607\r\n",
      "a^--call[4]:206556:-0.0200461\r\n",
      "a^.a:39888:-0.0719136\r\n",
      "a^.a[1]:39889:-0.0498216\r\n",
      "a^.a[2]:39890:-0.069618\r\n",
      "a^.a[3]:39891:0.0475522\r\n"
     ]
    }
   ],
   "source": [
    "! vw -i model -t --invert_hash model.readable train --quiet\n",
    "! head -n 30 model.readable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первые несколько строк соответствуют информации о модели. Далее следуют строчки вида `feature[label]:hash:weight`. Выделите для каждого класса 10 признаков с наибольшими по модулю весами. Постарайтесь сделать ваш алгоритм прохода по файлу константным по памяти. Например, можно воспользоваться [кучей](https://docs.python.org/2/library/heapq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import re\n",
    "from heapq import heappop, heappush\n",
    "\n",
    "with open('model.readable') as file:\n",
    "    counter = 0\n",
    "    label_regular = re.compile(r'\\[\\d\\]')\n",
    "    feature_regular = re.compile(r'^(.+):\\d+:')\n",
    "    weight_regular = re.compile(r':\\d+:(.+)$')\n",
    "    heaps = {i: [] for i in STATUS_DICT.values()}\n",
    "    heap_size = 10\n",
    "    for line in file:\n",
    "        if counter > 10:\n",
    "            label = label_regular.findall(line)\n",
    "            if len(label) != 0:\n",
    "                label = int(label[0][1:-1])\n",
    "            else:\n",
    "                label = None\n",
    "            feature = feature_regular.findall(line)[0]\n",
    "            if feature[-1] == ']':\n",
    "                feature = feature[:-3]\n",
    "            weight = abs(float(weight_regular.findall(line)[0]))\n",
    "\n",
    "            if label not in heaps:\n",
    "                continue\n",
    "            if label is not None:\n",
    "                if ((weight, feature) not in heaps[label]):\n",
    "                    heappush(heaps[label], (weight, feature))\n",
    "                    if len(heaps[label]) > heap_size:\n",
    "                        heappop(heaps[label])\n",
    "                else:\n",
    "                    print('!!!')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на кучи для некоторых статусов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.976418, 'a^global-asax'),\n",
       " (0.976418, 'd^nID,'),\n",
       " (0.988981, 'b^2g'),\n",
       " (0.988981, 'c^m/D'),\n",
       " (0.976418, 't^create'),\n",
       " (0.988981, 't^in'),\n",
       " (1.40876, 'd^l-Sh'),\n",
       " (1.40876, 'Constant'),\n",
       " (1.40876, 'd^imel'),\n",
       " (1.40876, 'd^way/')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heaps[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.07207, 't^prompt'),\n",
       " (1.1132, 'c^hda'),\n",
       " (1.1132, 't^possible'),\n",
       " (1.35952, 't^using'),\n",
       " (1.1132, 't^castleactiverecord'),\n",
       " (1.60224, 'd^imel'),\n",
       " (1.35952, 'c^XX.'),\n",
       " (1.60224, 'Constant'),\n",
       " (1.60224, 'd^l-Sh'),\n",
       " (1.60224, 'd^way/')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heaps[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.82407, 'd^BMS?'),\n",
       " (0.82407, 't^registertypelib'),\n",
       " (0.830748, 'c^m/D'),\n",
       " (0.830748, 'b^2g'),\n",
       " (0.829659, 't^a'),\n",
       " (2.2639, 'd^way/'),\n",
       " (0.830748, 't^in'),\n",
       " (2.2639, 'Constant'),\n",
       " (2.2639, 'd^l-Sh'),\n",
       " (2.2639, 'd^imel')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heaps[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что кое-где суффиксы являются сильно значимыми признаками. Таким образом и следует выбирать, какие фичи добавлять."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Добавим признаки, извлеченные из текста поста (поле `BodyMarkdown`). В этом поле находится более подробная информация о вопросе, и часто туда помещают код, формулы и т.д. При удалении пунктуации мы потеряем много полезной информации, однако модель \"мешка слов\" на сырых данных может сильно раздуть признаковое пространство. В таких случаях работают с n-граммами на символах. <br>\n",
    "Будьте осторожны: символы \"`:`\" и \"`|`\" нельзя использовать в названиях признаков, поскольку они являются служебными для `vw`-формата. Замените эти символы на два других редко встречающихся в выборке (или вообще не встречающихся). Также не забудьте про \"`\\n`\". <br>\n",
    "Поскольку для каждого документа одна n-грамма может встретиться далеко не один раз, то будет экономнее записывать признаки в формате `[n-грамма]:[число вхождений]`.\n",
    "\n",
    "Также добавьте тэги (поля вид `TagN`). Приветствуется добавление информации о пользователе из других полей. Только не используйте `PostClosedDate` – в нем содержится информация о таргете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_ngram_body(row, ngram=3):\n",
    "    # YOUR CODE HERE\n",
    "    body_text = re.sub('\\|', 'ы', row['BodyMarkdown'])\n",
    "    body_text = re.sub('\\:', 'я', body_text)\n",
    "    body_text = re.sub('\\n+', '. ', body_text)\n",
    "    def ngram_from_word(counter, word, ngram=2):\n",
    "        for index in range(1, len(word) - ngram + 1):\n",
    "            counter[word[index:(index + ngram)]] += 1\n",
    "    ngrams_dict = Counter()\n",
    "    for word in body_text.split(' '):\n",
    "        ngram_from_word(ngrams_dict, word, ngram)\n",
    "    return ' '.join([key + ':' + str(ngrams_dict[key]) for key in ngrams_dict])\n",
    "\n",
    "\n",
    "def extract_tags(row):\n",
    "    # YOUR CODE HERE\n",
    "    return ' '.join(row['Tag' + str(i)] for i in range(1, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединим все вместе. Реализуйте экстрактор признаков, который выделяет каждую подгруппу в отдельный namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractors_list = [\n",
    "    ('t', extract_title),\n",
    "    ('b', extract_ngram_body),\n",
    "    ('a', extract_tags)\n",
    "] # (namespace, extractor)\n",
    "\n",
    "\n",
    "def make_feature_extractor(extractors_list):\n",
    "    def feature_extractor(row):\n",
    "        # YOUR CODE HERE\n",
    "        return ' '.join(['|' + name + ' ' + extractor(row) for name, extractor in extractors_list])\n",
    "    return feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2vw(make_feature_extractor(extractors_list))\n",
    "! head -n 1 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэкспериментируйте с другими параметрами модели. Добавьте квадратичные взаимодействия между различными блоками признаков, измените параметры оптимизатора, добавьте регуляризацию и т.д. Совсем необязательно перебирать все параметры по сетке и добиваться оптимального качества. Для нас важнее то, насколько хорошо вы разобрались с возможностями библиотеки и продемонстрировали это.\n",
    "\n",
    "Выберите не менее трех параметров. Для каждого из них объясните, почему по вашему мнению его изменение может улучшить качество модели, подберите оптимальное значение. Можете перебрать несколько значений \"руками\", а можете воспользоваться [vw-hypersearch](https://github.com/JohnLangford/vowpal_wabbit/wiki/Using-vw-hypersearch) или [vw-hyperopt](https://github.com/JohnLangford/vowpal_wabbit/blob/master/utl/vw-hyperopt.py) ([статья на хабре](https://habrahabr.ru/company/dca/blog/272697/)). Какие параметры повлияли на улучшение качества сильнее всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в фичи n-граммы разных длин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим n-граммы разной длины\n",
    "extractors_list = [\n",
    "    ('t', extract_title),\n",
    "    ('b', lambda row: extract_ngram_body(row, 2)),\n",
    "    ('c', lambda row: extract_ngram_body(row, 3)),\n",
    "    ('d', lambda row: extract_ngram_body(row, 4)),\n",
    "    ('a', extract_tags)\n",
    "] # (namespace, extractor)\n",
    "\n",
    "data2vw(make_feature_extractor(extractors_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавлене таких фичей существенно качество не улучшило. Но небольшой прирост все же дало."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Попробуем l1 и l2 регуляризацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l2 0.000001\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l1 0.000001\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, l2 регуляризация дала значителное улучшение, а l1 оказалась бесполезной. Лучше брать l2 регуляризацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь попробуем улучшить качество, поменяв различный параметры оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --sgd --quiet --passes 1 --cache_file cache_file\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --sgd --quiet --passes 5 --cache_file cache_file\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --sgd --quiet --passes 10 --cache_file cache_file\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что для sgd увеличение числа проходов все же положительно складывается на качестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --adaptive --quiet\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в целом изменение режима оптимизации приводит к значительно худшим результатам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем уменьшаять learning rate между проходами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l2 0.000001 --passes 3 --cache_file cache_file --decay_learning_rate 0.05\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прироста достигнуть не получилось. Попробуем добавить нелинейные признаки несколькими способами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 1.60944\n",
      "accuracy = 0.00904\n"
     ]
    }
   ],
   "source": [
    "# Квадратичные признаки по body объекта\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l1 0.000001 -q bb\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.13167\n",
      "accuracy = 0.97927\n"
     ]
    }
   ],
   "source": [
    "# Перемножаем признаки из body и title\n",
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l1 0.000001 -q tb\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавление квадратичных признаков привобит к очень плохой обучаемости. А пот скрестное перемножение сказывается на качестве неплохо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Займемся добавлением своих фичей. Добавим даты создания поста и дату регистрации пользователя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_dates(row):\n",
    "    import datetime\n",
    "    def get_date_time(string):\n",
    "        date = [int(x) for x in string.split()[0].split('/')]\n",
    "        time = [int(x) for x in string.split()[1].split(':')]\n",
    "        date = datetime.datetime(date[2], date[0], date[1])\n",
    "        time = datetime.datetime(1970, 1, 1, time[0], time[1], time[2])\n",
    "        date = str((date - datetime.datetime(1970, 1, 1)).total_seconds())\n",
    "        time = str((time - datetime.datetime(1970, 1, 1)).total_seconds())\n",
    "        return date, time\n",
    "\n",
    "    result = ''\n",
    "    try:\n",
    "        owner_creation_date_time = get_date_time(row['OwnerCreationDate'])\n",
    "        result += owner_creation_date_time[0] + ' ' + owner_creation_date_time[1]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    try:\n",
    "        post_creation_date_time = get_date_time(row['PostCreationDate'])\n",
    "        result += post_creation_date_time[0] + ' ' + post_creation_date_time[1]\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extractors_list = [\n",
    "    ('t', extract_title),\n",
    "    ('b', extract_ngram_body),\n",
    "    ('a', extract_tags),\n",
    "    ('d', extract_dates)\n",
    "] # (namespace, extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2vw(make_feature_extractor(extractors_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss  = 0.14416\n",
      "accuracy = 0.97927\n"
     ]
    }
   ],
   "source": [
    "! vw -d train --loss_function logistic --oaa 5 -f model --quiet --l1 0.000001\n",
    "! vw -i model -t test -r pred --quiet\n",
    "print('logloss  = %.5f\\naccuracy = %.5f' % get_scores())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Новые фичи прироста в качестве не дали. Но при этом оно сильно не упало. Это означает, что при некоторых других параметрах (например других параметрах оптимизатора), такие фичи могут хорошо повлиять на качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом все ясно, самая главная команда: vw -h"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
