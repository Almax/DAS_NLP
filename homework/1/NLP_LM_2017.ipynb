{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Тема: Языковое моделирование и определение языка.\n",
    "\n",
    "\n",
    "**Выдана**:   14 сентября 2017\n",
    "\n",
    "**Дедлайн**:   <font color='red'>9:00 утра 28 сентября 2017</font>\n",
    "\n",
    "**Среда выполнения**: Jupyter Notebook (Python 3)\n",
    "\n",
    "#### Правила:\n",
    "\n",
    "Результат выполнения задания $-$ отчет в формате Jupyter Notebook с кодом и выводами. В ходе выполнения задания требуется реализовать все необходимые алгоритмы, провести эксперименты и ответить на поставленные вопросы. Дополнительные выводы приветствуются. Чем меньше кода и больше комментариев $-$ тем лучше.\n",
    "\n",
    "Все ячейки должны быть \"выполненными\", при этом результат должен воспроизвдиться при проверке (на Python 3). Если какой-то код не был запущен или отрабатывает с ошибками, то пункт не засчитывается. Задание, сданное после дедлайна, _не принимается_. Совсем.\n",
    "\n",
    "\n",
    "Задание выполняется самостоятельно. Вы можете обсуждать идеи, объяснять друг другу материал, но не можете обмениваться частями своего кода. Если какие-то студенты будут уличены в списывании, все они автоматически получат за эту работу 0 баллов, а также предвзято негативное отношение семинаристов в будущем. Если вы нашли в Интернете какой-то код, который собираетесь заимствовать, обязательно укажите это в задании: вполне вероятно, что вы не единственный, кто найдёт и использует эту информацию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи:\n",
    "\n",
    "В данной лабораторной работе Вам предстоит реализовать n-грамную языковую модель с несколькими видами сглаживания:\n",
    "- Add-one smoothing\n",
    "- Stupid backoff\n",
    "- Interpolation smoothing\n",
    "- Kneser-Ney smoothing\n",
    "\n",
    "Вы обучите ее на готовых корпусах, оцените качество и проведете ряд экспериментов. Во второй части задания Вы примените реализованную модель (но с буквенными n-граммами) к задаче распознавания языка. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Языковые модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Цель языкового моделирования заключается в том, чтобы присвоить некоторые вероятности предложениям. Задача состоит в подсчете вероятности $P(W) = P(w_1, \\dots, w_n)$ или $P(w_n \\mid w_1, \\dots, w_{n-1})$. Модель, умеющая вычислять хотя бы одну из этих двух вероятностей, называется **языковой моделью** (LM от Language Model).\n",
    "\n",
    "Согласно **цепному правилу** (chain rule):\n",
    "\n",
    "$$P(X_1, \\dots, X_n) = P(X_1)P(X_2 \\mid X_1)\\dots P(X_n \\mid X_1, \\dots, X_{n-1}).$$ \n",
    "\n",
    "Также мы знаем, что\n",
    "\n",
    "$$\n",
    "    P(X_n \\mid X_1, \\dots, X_{n-1}) = \\frac{P(X_1, \\dots, X_n)}{P(X_1, \\dots, X_{n-1})},\n",
    "$$\n",
    "\n",
    "следовательно, для того чтобы оценить $P(X_n \\mid X_1, \\dots, X_{n-1})$ нужно посчитать $P(X_1, \\dots, X_n)$ и $P(X_1, \\dots, X_{n-1})$. Но эти вероятности будут чрезвычайно малы, если мы возьмем большое $n$, так множество предложений из $n$ слов растет экспоненциально. Для упрощения применим **марковское предположение**: \n",
    "\n",
    "$$P(X_n \\mid X_1, \\dots, X_{n-1}) = P(X_n \\mid X_{n - k + 1}, \\dots, X_{n-1})$$\n",
    "\n",
    "для некоторого фиксированного (небольшого) $k$. Это предположение говорит о том, что $X_{n}$ не зависит от $X_{1}, \\dots, X_{n - k}$, то есть на следующее слово влияет лишь контекст из предыдущих $k - 1$ слова. Таким образом, мы получаем финальную вероятность:\n",
    "\n",
    "$$\n",
    "    P(w_1, \\dots, w_n) = \\prod_i P(w_i \\mid w_{i-k+1}, \\dots, w_{i - 1}).\n",
    "$$\n",
    "\n",
    "Далее для краткости будем обозначать $w_{i-k}^i := w_{i-k}, \\dots, w_{i}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Хранилище n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала выполним вспомогательную работу. Следуйте комментариям, чтобы написать NGramStorage с удобным интерфейсом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NGramStorage:\n",
    "    \"\"\"Storage for ngrams' frequencies.\n",
    "\n",
    "    Args:\n",
    "        sents (list[list[str]]): List of sentences from which ngram\n",
    "            frequencies are extracted.\n",
    "        max_n (int): Upper bound of the length of ngrams.\n",
    "            For instance if max_n = 2, then storage will store\n",
    "            0, 1, 2-grams.\n",
    "\n",
    "    Attributes:\n",
    "        max_n (Readonly(int)): Upper bound of the length of ngrams.\n",
    "    \"\"\"\n",
    "\n",
    "    def __make_lower(self, n_gram):\n",
    "        return tuple([word.lower() for word in n_gram])\n",
    "\n",
    "    def __init__(self, sents=[], max_n=0):\n",
    "        self.__max_n = max_n\n",
    "        self.__ngrams = {i: Counter() for i in range(self.__max_n + 1)}\n",
    "        # self._ngrams[K] should have the following interface:\n",
    "        # self._ngrams[K][(w_1, ..., w_K)] = number of times w_1, ..., w_K occured in words\n",
    "        # self._ngrams[0][()] = number of all words\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        def handle_sentence(sentence):\n",
    "            for length in range(1, max_n + 1):\n",
    "                for i in range(len(sentence)):\n",
    "                    new_n_gram = tuple(sentence[i:(i + length)])\n",
    "                    if len(new_n_gram) == length:\n",
    "                        self.__ngrams[length][new_n_gram] += 1\n",
    "                        if length == 1:\n",
    "                            self.__ngrams[0][tuple()] += 1\n",
    "        for sentence in sents:\n",
    "            handle_sentence(self.__make_lower(sentence))\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "    def add_unk_token(self):\n",
    "        \"\"\"Add UNK token to 1-grams.\"\"\"\n",
    "        # In order to avoid zero probabilites \n",
    "        if self.__max_n == 0 or 'UNK' in self.__ngrams[1]:\n",
    "            return\n",
    "        self.__ngrams[0][()] += 1\n",
    "        self.__ngrams[1][('UNK', )] = 1\n",
    "        \n",
    "    @property\n",
    "    def max_n(self):\n",
    "        \"\"\"Get max_n\"\"\"\n",
    "        return self.__max_n\n",
    "        \n",
    "    def __getitem__(self, k):\n",
    "        \"\"\"Get dictionary of k-gram frequencies.\n",
    "        \n",
    "        Args:\n",
    "            k (int): length of returning ngrams' frequencies.\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary (in fact Counter) of k-gram frequencies.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(k, int):\n",
    "            raise TypeError('k (length of ngrams) must be an integer!')\n",
    "        if k > self.__max_n:\n",
    "            raise ValueError('k (length of ngrams) must be less or equal to the maximal length!')\n",
    "        return self.__ngrams[k]\n",
    "    \n",
    "    def __call__(self, ngram):\n",
    "        \"\"\"Return frequency of a given ngram.\n",
    "        \n",
    "        Args:\n",
    "            ngram (tuple): ngram for which frequency should be computed.\n",
    "            \n",
    "        Returns:\n",
    "            Frequency (int) of a given ngram.\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(ngram, tuple):\n",
    "            raise TypeError('ngram must be a tuple!')\n",
    "        if len(ngram) > self.__max_n:\n",
    "            raise ValueError('length of ngram must be less or equal to the maximal length!')\n",
    "        if len(ngram) == 1 and ngram not in self.__ngrams[1]:\n",
    "            return self.__ngrams[1][('UNK', )]\n",
    "        return self.__ngrams[len(ngram)][self.__make_lower(ngram)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте brown корпус, обучите модель и протестируйте на нескольких примерах последовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment next row and download brown corpus\n",
    "# nltk.download()\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all sentences = 57340\n",
      "Number of train sentences = 45872\n",
      "Number of test sentences = 11468\n"
     ]
    }
   ],
   "source": [
    "all_sents = list(brown.sents())\n",
    "random.shuffle(all_sents)\n",
    "print('Number of all sentences = {}'.format(len(all_sents)))\n",
    "train_sents = all_sents[:int(0.8 * len(all_sents))]\n",
    "test_sents = all_sents[int(0.8 * len(all_sents)):]\n",
    "print('Number of train sentences = {}'.format(len(train_sents)))\n",
    "print('Number of test sentences = {}'.format(len(test_sents)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create storage of 0, 1, 2, 3-grams\n",
    "storage = NGramStorage(train_sents, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1368\n",
      "3350\n",
      "25\n",
      "0\n",
      "930726\n"
     ]
    }
   ],
   "source": [
    "# It's time to test your code\n",
    "print(storage(('to', 'be')))\n",
    "print(storage(('or',)))\n",
    "print(storage(('not', 'to', 'be')))\n",
    "print(storage(('somethingweird',)))\n",
    "print(storage(()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для численного измерения качества языковой модели определим **перплексию**:\n",
    "\n",
    "$$\n",
    "    {\\mathbb{P}}(w_1, \\dots, w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_i P(w_i \\mid w_{i - k}, \\dots, w_{i - 1})\\right)^{-\\frac1N},\n",
    "$$\n",
    "\n",
    "Вижно, что минимизация перплексии эквивалентна максимизации правдоподобия модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте функцию по подсчету перплексии. Обратите внимание, что перплексия по корпусу равна произведению вероятностей **всех** предложений в степени $-\\frac1N$, где $N -$ суммарная длина всех предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perplexity(estimator, sents):\n",
    "    '''Estimate perplexity of the sequence of words using prob_estimator.'''\n",
    "    ### YOUR CODE HERE\n",
    "    # Avoid log(0) by replacing zero by 10 ** (-50).\n",
    "    log_perp = 0\n",
    "    N = 0\n",
    "    for sentence in sents:\n",
    "        log_perp += np.log(max(estimator.prob(sentence), 10 ** (-50)))\n",
    "        N += len(sentence)\n",
    "    perp = np.exp(-log_perp / N)\n",
    "    ### END YOUR CODE\n",
    "    \n",
    "    return perp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Оценка вероятностей n-грам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый и простейший способ оценки вероятностей N-грам следующий:\n",
    "\n",
    "$$\n",
    "    \\hat P_{S}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N)}{c(w_1^{N-1})}.\n",
    "$$\n",
    "\n",
    "где $c(w_1^N)$ — это число последовательностей $w_1, \\dots, w_N$ в корпусе, $S$ символизирует Straightforward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StraightforwardProbabilityEstimator:\n",
    "    \"\"\"Class for simplest probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = c(context + word) / c(context), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage):\n",
    "        self.__storage = storage\n",
    "        # Adding UNK token to avoid zero probabilities\n",
    "        self.__storage.add_unk_token()\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if self.__storage.max_n == 1:\n",
    "            return ()\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            return context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('word must be a string!')\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "        # Avoiding 0 / 0.\n",
    "        if context_counts == 0:\n",
    "            return 0.\n",
    "        return 1. * phrase_counts / context_counts\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 258.3768898133552\n",
      "0.0014698187545864685\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "simple_estimator = StraightforwardProbabilityEstimator(storage)\n",
    "\n",
    "# Estimating perplexity\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(simple_estimator, test_sents)))\n",
    "print(simple_estimator.prob('To be'.split()))\n",
    "print(simple_estimator.prob('To be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем перплексию униграмной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 122.50351008086275\n"
     ]
    }
   ],
   "source": [
    "uni_storage = NGramStorage(train_sents, 1)\n",
    "uni_simple_estimator = StraightforwardProbabilityEstimator(uni_storage)\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(uni_simple_estimator, test_sents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Какие выводы можно сделать? Почему $P(\\text{To be or not to be}) = 0$, хотя мы и добавили UNK токен?  \n",
    "**A:** Вывод: казалось бы, более умная, учитывающая больше признаков модель, а работает хуже. Это из-за дырок, которые описаны в следующем ответе. В триграммной модели они проявляются гораздо чаще, чем в униграммной, т.к. число различных приграмм в языке сильно превышает число различных униграмм.\n",
    "\n",
    "**Q:** Почему перплексия униграмной модели меньше, чем триграмной?  \n",
    "**A:** В триграмной модели появляются дырки, т.е. не присутствующие в словаре последовательности токенов, частота которых 0. Из-за этого резко уменьшается перплексия.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add-one smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Простейший вид сглаживания — **сглаживание Лапласа**. Чтобы избавиться от нулевых вероятностей $P(w_{N} \\mid w_1^{N - 1})$, будем использовать формулу:\n",
    "\n",
    "$$\n",
    "    \\hat P_{AOS}(w_{N} \\mid w_1^{N - 1}) = \\frac{c(w_1^N) + \\delta}{c(w_1^{N-1}) + \\delta V},\n",
    "$$\n",
    "\n",
    "где $V$ — это размер словаря, а $\\delta$ — некоторая фиксированная константа."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс, осуществляющий сглаживание Лапласа. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LaplaceProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = (c(context + word) + delta) / (c(context) + delta * V), where\n",
    "    c(sequence) - number of occurances of the sequence in the corpus,\n",
    "    delta - some constant,\n",
    "    V - number of different words in corpus.\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): Smoothing parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            return context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('context must be a tuple!')\n",
    "            \n",
    "        ### YOUR CODE HERE\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_counts = self.__storage(context)\n",
    "        # Avoiding 0 / 0.\n",
    "        if context_counts == 0:\n",
    "            return 0.\n",
    "        prob = (phrase_counts + self.__delta) / (context_counts + self.__delta * len(self.__storage[1]))\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберите наилучший параметр $\\delta$ для данного корпуса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace estimator perplexity = 215.78121471825537\n",
      "0.000379971097201\n"
     ]
    }
   ],
   "source": [
    "# Try to find out best delta parameter. We will not provide you any strater code.\n",
    "### YOUR CODE HERE\n",
    "def get_perplexity(delta):\n",
    "    return perplexity(LaplaceProbabilityEstimator(storage, delta), test_sents)\n",
    "\n",
    "deltas = np.linspace(0.00005, 0.0001, 100)\n",
    "perplexities = np.array([get_perplexity(delta) for delta in deltas])\n",
    "best_delta = deltas[np.argmin(perplexities)]\n",
    "### END YOUR CODE\n",
    "\n",
    "# Initialize estimator\n",
    "laplace_estimator = LaplaceProbabilityEstimator(storage, best_delta)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Laplace estimator perplexity = {}'.format(perplexity(laplace_estimator, test_sents)))\n",
    "print(laplace_estimator.prob('To be'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f52eaf945c0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZoAAAEKCAYAAAArYJMgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FdX5x/HPQ8K+yRL2JeyrrAERVJQuKmpx3xCxLoj2\np6LWaq211vbXxZ+12lYLKNYNFBTXKlJqcZclgbCGHQQkmAACYUnI8vz+uEMbachCcnNvcr/v1ysv\nZ+aemXkOiXly5pw5x9wdERGRcKkR6QBERKR6U6IREZGwUqIREZGwUqIREZGwUqIREZGwUqIREZGw\nUqIREZGwUqIREZGwUqIREZGwio90AJHUvHlzT0xMjHQYIiJVSkpKyi53Tyht+ZhONImJiSQnJ0c6\nDBGRKsXMvixLeT06ExGRsFKiERGRsFKiERGRsFKiERGRsFKiERGRsFKiERGRsFKiERGRsFKiERGJ\nMc9/voVP1++qtPsp0YiIxJBl2/by8N9X81rKtkq7pxKNiEiMOHwknztnpdKiYW1+OaZvpd03pqeg\nERGJJb+bk8amzINMv/EUGtetWWn3VYtGRCQGfLwuk+e/+JLrR3RiRNfmlXpvJRoRkWpu76Ej3PPa\nMrq2aMBPzulR6fdXohERqcbcnZ+9sZLdB47w+BUDqFMzrtJjUKIREanG3lj6Fe+uSOfO73Wnb9vG\nEYlBiUZEpJra/s0hfvHWKoYkNmHiyC4Ri0OJRkSkGsovcO6atQwHHrt8AHE1LGKxKNGIiFRDT3+y\niUWb9/CLC3rTvmm9iMaiRCMiUs2s/Goff/jHWkaf3IpLB7eLdDhKNCIi1cnhI/nc8cpSmtavxf9e\neDJmkXtkdpRmBhARqUZ+NyeNjZkHefGGoTSpXyvS4QBq0YiIVBvz12bw/Bdf8sMRiZzeLSHS4fyb\nEo2ISDWw60AO97y6nB4tG3LvOT0jHc63hC3RmFl7M5tvZmlmtsrM7giOXxbsF5hZUqHyiWZ22MxS\ng6/Jx7nuADNbEJRJNrOhx3w+xMzyzezScNVNRCSauDv3vrac/dm5PHFVZN7+L044+2jygLvdfYmZ\nNQRSzGwesBK4GJhSxDkb3X1ACdd9BPilu88xs9HB/pkAZhYH/B6YW0F1EBGJetMXbuWDNRn8/Pze\n9GzVKNLh/JewJRp3TwfSg+0sM0sD2rr7PKA8IyEcOPov2RjYUeiz24DZwJATvbiISFWyIeMAv353\nNad3a84PhydGOpwiVcqoMzNLBAYCC0so2snMlgL7gQfc/ZMiykwC5prZo4Qe/Q0P7tEWuAgYhRKN\niMSAnLx8bn95KXVrxvHoZf2pEcG3/4sT9sEAZtaAUCtjkrvvL6ZoOtDB3QcCdwEzzKyoNuAtwJ3u\n3h64E5gWHH8cuNfd80uIZ0LQt5OcmZlZ1uqIiESNx/6xjtXp+3nk0v60bFQn0uEcV1gTjZnVJJRk\nprv768WVdfccd98dbKcAG4HuRRQdDxy91qvA0cEAScArZrYFuBR4yswuLOI+U909yd2TEhKiZ/if\niEhZfLZhF1M+3sTYUzrwvd4tIx1OscL26MxCnTDTgDR3f6wU5ROAPe6eb2adgW7ApiKK7gBGAh8S\neky2HsDdOxW61nPA3939zXJWQ0Qk6nxz8Ah3zUqlS0J9Hjivd6TDKVE4+2hGAOOAFWaWGhy7H6gN\n/BlIAN41s1R3Pxs4A3jYzPKAfGCiu+8BMLNngMnungzcBDxhZvFANjAhjHUQEYkq7s69s5ez5+AR\npo0fQt1a0TWUuSjhHHX2KXC8nqk3iig/m9BjtqKudeMx1x1cwr2vK3WgIiJVyIxFW/nH6q/52ehe\nEVvIrKw0M4CISBWx/ussfvX30FDmG07rVPIJUUKJRkSkCsjJy+f2V1KpVyueP0TxUOaiaPZmEZEq\n4Hdz1pCWvp9p45NoEcVDmYuiFo2ISJSbvyaDv322heuGJ/KdXtE9lLkoSjQiIlEsY382P351GT1b\nNeS+c6NrVubS0qMzEZEoVVDg3P3qMg4eyeOVq4ZF3azMpaUWjYhIlHr6k018sn4XD57fh24tG0Y6\nnBOmRCMiEoWWbdvL/81dy7l9W3HV0PaRDqdclGhERKJMVnYut728lJaN6vC7i/uVZ1mVqKA+GhGR\nKOLuPPDmSr7ae5iZE4bRuF7NSIdUbmrRiIhEkddStvNW6g4mfacbSYlNIx1OhVCiERGJEhsyDvDg\nW6sY1rkpt57VNdLhVBglGhGRKJCdm8//zFhC3VpxPHHlQOKq0BQzJVEfjYhIFPjNe2ms2ZnF364b\nEtWrZZ4ItWhERCLs/ZU7eeGLL7np9E6c1bNFpMOpcEo0IiIRtG3PIX7y2jL6tWvMPWdXzSlmSqJE\nIyISIbn5Bdz28lLc4S9XDaJWfPX8law+GhGRCHl07lpSt+3lL1cPpEOzepEOJ2yqZ/oUEYly89dm\nMOXjTYw9pQPn92sT6XDCSolGRKSSpe87zN2zQlP///z83pEOJ+yUaEREKlFefgG3v7yU7Nx8nhw7\nqMpO/V8W6qMREalEf/znOhZv+YbHrxhAl4QGkQ6nUoStRWNm7c1svpmlmdkqM7sjOH5ZsF9gZkmF\nyiea2WEzSw2+Jh/nugPMbEFQJtnMhgbHx5jZ8kLHTwtX3URETsTH6zJ56sONXJHUngsHto10OJUm\nnC2aPOBud19iZg2BFDObB6wELgamFHHORncfUMJ1HwF+6e5zzGx0sH8m8AHwtru7mfUDZgHVc1C6\niFQ5O/dlM2lmKt1bNOShH/SJdDiVKmyJxt3TgfRgO8vM0oC27j4PKM/6Cg40CrYbAzuCexwoVKZ+\nUE5EJOKO7ZepW6v698sUVil9NGaWCAwEFpZQtJOZLQX2Aw+4+ydFlJkEzDWzRwk9+hte6D4XAb8F\nWgDnHSeWCcAEgA4dOpSpHiIiJ+KxeetYtGUPj18xgK4tYqNfprCwjzozswbAbGCSu+8vpmg60MHd\nBwJ3ATPMrFER5W4B7nT39sCdwLSjH7j7G+7eE7gQ+FVRN3H3qe6e5O5JCQkJJ1YpEZFSmr82g6c+\n3MiVQ2KrX6awsCYaM6tJKMlMd/fXiyvr7jnuvjvYTgE2At2LKDoeOHqtV4GhRVzrY6CLmTUvR/gi\nIuWyY+9h7pqZSs9WsdcvU1g4R50ZodZGmrs/VoryCWYWF2x3BroBm4oougMYGWyPAtYH53QN7omZ\nDQJqAbvLWw8RkRNxJK+AH81YQm6+81SMvC9zPOHsoxkBjANWmFlqcOx+oDbwZyABeNfMUt39bOAM\n4GEzywPygYnuvgfAzJ4BJrt7MnAT8ISZxQPZBP0twCXAtWaWCxwGrnB3DQgQkYj4/ftrWLp1L09e\nPYjOMfK+zPFYLP8uTkpK8uTk5EiHISLVzPsrdzLxpRSuG55YLR+ZmVmKuyeVXDJEU9CIiFSgLbsO\ncs+ry+jfrjE/Ha1X+UCJRkSkwmTn5nPL9CXUqGE8OXYQteNjt1+mMM11JiJSQR58ayVp6fv523VD\naNek+q4vU1Zq0YiIVIBZyduYlbyd20Z15ayeLSIdTlRRohERKadVO/bx8zdXMrxLMyZ9t6jX/2Kb\nEo2ISDnsO5zLLS8t4aR6NfnTVQOJq3HC8zhWW+qjERE5QQUFzt2zUtmx9zAzbx5G8wa1Ix1SVFKL\nRkTkBE3+eCP/TMvggfN6Mbhj00iHE7WUaERETsCn63fx6Ny1XNC/DeOHJ0Y6nKimRCMiUkZf7T3M\n7a8spUtCA3538cnlWV8rJijRiIiUQU5ePre+lMKRvAImjxtM/drq6i6J/oVERMrgl++sZtn2fUy+\nZjBdYnyyzNJSi0ZEpJRmLd7GjIVbuXlkZ87p2yrS4VQZSjQiIqWwfPteHnhrJSO6NuOe7/eIdDhV\nihKNiEgJdh/IYeKLKSQ0qM2frhxIfJx+dZaF+mhERIqRl1/A7a8sZdfBI8yeOJxmeimzzJSWRUSK\n8X9z1/LZht38+sK+nNyucaTDqZKUaEREjuOdZTuY8vEmxg3ryOVJ7SMdTpWlRCMiUoS09P385LXl\nJHVsws/P7x3pcKo0JRoRkWPsPXSEm19MoVHdeJ66ZhC14vWrsjw0GEBEpJC8/AJue3kpO/dl88rN\nw2jRsE6kQ6rywpamzay9mc03szQzW2VmdwTHLwv2C8wsqVD5RDM7bGapwdfk41x3gJktCMokm9nQ\n4PhYM1sefH1uZv3DVTcRqb7+b+5aPlm/i4fH9GFQhyaRDqdaCGeLJg+4292XmFlDIMXM5gErgYuB\nKUWcs9HdB5Rw3UeAX7r7HDMbHeyfCWwGRrr7N2Z2LjAVOKWC6iIiMeCt1K/+3fl/5dAOkQ6n2ghb\nonH3dCA92M4yszSgrbvPA8oz26kDjYLtxsCO4B6fFyqzAGh3ojcQkdiz8qt93Dt7OUMTm6rzv4KV\nKtGYWVN333OiNzGzRGAgsLCEop3MbCmwH3jA3T8poswkYK6ZPUro0d/wIsrcAMw50XhFJLbsOpDD\nhBeSaVKvFk+OVed/RSvtv+ZCM3vVzEZbGZsiZtYAmA1Mcvf9xRRNBzq4+0DgLmCGmTUqotwtwJ3u\n3h64E5h2zP3OIpRo7j1OPBOCvp3kzMzMslRFRKqhI3kF3PJSCrsPHuHpa5NIaKg3/ytaaRNNd0J9\nHuOADWb2GzPrXtJJZlaTUJKZ7u6vF1fW3XPcfXewnQJsDO57rPHA0Wu9CgwtdL9+wDPAmKPXKuI+\nU909yd2TEhISSqqCiFRzD72zisVbvuGRS/vRt63e/A+HUiUaD5nn7lcBNxL6Zb/IzD4ys1OLOido\n+UwD0tz9sZLuYWYJZhYXbHcGugGbiii6AxgZbI8C1gfndCCUgMa5+7rS1EtEYtuLC75kxsKtTBzZ\nhTED2kY6nGqrtH00zYBrCLVovgZuA94GBhBqVXQq4rQRQfkVZpYaHLsfqA38GUgA3jWzVHc/GzgD\neNjM8oB8YOLRfiEzewaY7O7JwE3AE2YWD2QDE4JrPwg0A54Knu7lufu/h0+LiBT2+cZdPPT2Ks7q\nkcA9Z2va/3Aydy+5kNk64EXgb+6+/ZjP7nX334cpvrBKSkry5OTkSIchIpXsy90HGfPkZzRvUJs3\nbh1Owzo1Ix1SlWJmKWX5Q760w5v7u/vhY27U3N13VdUkIyKxKSs7lxufT8Ydnrk2SUmmEpRl1Nmw\noztmdgnweTHlRUSiTn6Bc8crqWzadZCnxg4isXn9SIcUE0rbohkLPGtmHwJtCPWFjApXUCIi4fDI\n+2v415oMfjWmDyO6No90ODGjVInG3VeY2f8S6qfJAs44tq9GRCSavZq87d/Ty4w7NTHS4cSU0o46\nmwZ0AfoRerflHTP7i7s/Gc7gREQqQvKWPfzsjZWc1rU5D16g6WUqW2n7aFYCZ7n7ZnefCwwDBoUv\nLBGRirF19yEmvJhCuyZ1efLqQdSM0/Qyla20L2z+EahjZj2C/X3ufkNYIxMRKaf92bnc8Pxi8guc\nadcNoXE9jTCLhFIlGjO7AEgF3g/2B5jZ2+EMTESkPPLyC7htxlI27zrIX68ZRCeNMIuY0rYhHyI0\np9heAHdPpejZAEREosKv303jo3WZ/OrCvgzvohFmkVTaRJPn7vuOOVbylAIiIhHw3Gebee7zLdx4\nWieu0gJmEVfa92hWmtnVQJyZdQNuRy9sikgU+tear3n476v5Xu+W/HR0r0iHI5S+RXMb0AfIAV4m\ntDDZpHAFJSJyIlbv2M9tM5bSu00jnrhyAHE1TnglX6lApX1h8xDws+BLRCTq7NyXzfXPLaZhnZpM\nGz+EerXCtlK9lFGx3wkze4di+mLc/QcVHpGISBkdyMnj+ucWk5Wdy6sTh9OyUZ1IhySFlJTyH62U\nKERETlBoGPMS1n6dxTPjk+jdpqgV4CWSik007v7R0W0zqwX0JNTCWevuR8Icm4hIsdydX76zmvlr\nM/n1hX05q0eLSIckRSjtXGfnAZOBjYABnczsZnefE87gRESK8/Qnm3hxwZdMOKMz1wzrGOlw5DhK\n21v2B0JznW0AMLMuwLuAEo2IRMTfl+/gN++t4bx+rbnvnJ6RDkeKUdrhzRlHk0xgE5ARhnhEREq0\neMse7pq5jCGJTfjDZf2poWHMUa20LZpVZvYeMItQH81lwGIzuxjA3V8PU3wiIt+yIeMANz6fTLsm\ndZk6Lok6NeMiHZKUoLSJpg7wNTAy2M8EmgIXEEo8SjQiEnYZ+7MZ/+wiasbV4Pnrh9Kkfq1IhySl\nUGKiMbM4YHmwVICISEQcyMnjh88t5ptDR5g54VTaN60X6ZCklErso3H3fKDML2aaWXszm29maWa2\nyszuCI5fFuwXmFlSofKJZnbYzFKDr8nHue4AM1sQlEk2s6HB8Z5m9oWZ5ZjZj8sar4hEryN5Bdzy\nUgprdmbx1NhBnNyucaRDkjIo7aOzz83sL8BM4ODRg+6+pJhz8oC73X2JmTUEUsxsHqHVOi8GphRx\nzkZ3H1BCLI8Av3T3OWY2Otg/E9hDaLLPC0tZJxGpAgoKnHtnL+eT9bt45NJ+nKl3Zaqc0iaa4cF/\nHy50zIFRxzvB3dOB9GA7y8zSgLbuPg/A7IRHiThw9NXfxsCO4B4ZQEbwzo+IVBO/n7uGN5Z+xT1n\n9+DypPaRDkdOQGkn1TyrPDcxs0RgILCwhKKdzGwpodmhH3D3T4ooMwmYa2aPEnr0N7yIMsXFMgGY\nANChg9apEIlm0z7dzJSPNnHtqR259cwukQ5HTlBpl3JuaWbTzGxOsN/bzG4o5bkNgNnAJHffX0zR\ndKCDuw8E7gJmmFlRkxbdAtzp7u2BO4FppYnjKHef6u5J7p6UkJBQllNFpBK9lfoVv/r7as7t24pf\nXNCnPE9BJMJK+8Lmc8BcoE2wv45SrEdjZjUJJZnpJb1r4+457r472E4hNN1N9yKKjuc/w6lfJbTE\ntIhUIx+uzeDuWcsY1rkpf7xC68pUdaVNNM3dfRZQAODueUB+cSdY6M+PaUCauz9W0g3MLCEYSo2Z\ndQa6EZqB4Fg7+M/7PKOA9aWsg4hUAUu3fsMtLy2he8uGPH2tXsisDko7GOCgmTUjWJvGzIYB+0o4\nZwQwDlhhZqnBsfuB2sCfgQTgXTNLdfezgTOAh83saBKb6O57gvs9A0x292TgJuAJM4sHsgn6W8ys\nFZBMaKBAgZlNAnqX8LhORKLIhowsrn9uMQkNa/Pc9UNoWKdmpEOSCmDux13X7D+FzAYRSg59gFWE\nksSl7r48vOGFV1JSkicnJ0c6DBEBtn9ziEv/+gX57rw28VQ6Nqsf6ZDkOMwsxd2TSi4ZUtoWzWrg\nDeAQkAW8SaifRkSk3HYdyGHctEUcOpLHzJuVZKqb0vbRvEBo0bPfEGrZdANeDFdQIhI79mfnMv7Z\nRaTvO8yz1w2hV2utkFndlLZF08Pd+xfan29my8IRkIjEjsNH8rnhucWs3ZnF0+OTSEpsGumQJAxK\n26JZGgwAAMDMTgE+C09IIhILjuQVMPGlFFK+/IbHrxygZZirsdK2aE4BrjWzrcF+ByDNzFYA7u79\nwhKdiFRL+QXOpJlL+WhdJr+/5GTO79em5JOkyiptojknrFGISMw4Oknmeyt28sB5vbhiiKaCqu5K\nO9fZl+EORESqP3fnoXdW8VrKdiZ9txs3nt450iFJJShtH42ISLm4O797fw0vfPElN5/RmTu+0y3S\nIUklUaIRkUrxxAfrmfLRJq4Z1oH7zu2pSTJjiBKNiITdXz/cyOP/XM+lg9vx8A/6KsnEGCUaEQmr\nZz/dzO/fX8MP+rfh95f0o4ZmYo45SjQiEjYvLviSh4M1ZR67vL+m+49RSjQiEhYzFm7l52+u5Lu9\nWvDElQOJj9Ovm1il77yIVLiZi7dy/xsrGNWzBU+OHUSteP2qiWX67otIhZqVvI37Xl/ByO4JPDV2\nELXjtXBZrCvtzAAiIiWatXgb976+nNO6NmfKuMFaHVMAtWhEpILMXLyVn8xezundErQEs3yLEo2I\nlNvLi7Zy7+zQ47KpasnIMfToTETK5cUvtvDzt1ZxZo8EJl+jJCP/TYlGRE7YtE8386u/r+a7vVry\n5NiB6viXIinRiMgJmfzRRn43Zw3n9m3FE1cO1BBmOa6w/WSYWXszm29maWa2yszuCI5fFuwXmFlS\nofKJZnbYzFKDr8nHue4AM1sQlEk2s6HBcTOzP5nZBjNbbmaDwlU3kVjm7jw2bx2/m7OGC/q34U9X\nKclI8cLZoskD7nb3JWbWEEgxs3nASuBiYEoR52x09wElXPcR4JfuPsfMRgf7ZwLnAt2Cr1OAvwb/\nFZEK4u78ds4apn68icuT2vHbi/tpWhkpUdgSjbunA+nBdpaZpQFt3X0eUJ7ZWx1oFGw3BnYE22OA\nF9zdgQVmdpKZtQ7iEJFyKihwHnx7JS8t2Mq1p3bkoQv6aIJMKZVK6aMxs0RgILCwhKKdzGwpsB94\nwN0/KaLMJGCumT1K6NHf8OB4W2BboXLbg2NKNCLllJtfwD2vLuPN1B3cPLIz952j9WSk9ML+YNXM\nGgCzgUnuvr+YoulAB3cfCNwFzDCzRkWUuwW4093bA3cC047eqoiyXkQ8E4K+neTMzMyyVOXbF/b/\nurRItZSdm8+t05fwZuoO7jm7Bz89t5eSjJRJWBONmdUklGSmu/vrxZV19xx33x1spwAbge5FFB0P\nHL3Wq8DQYHs70L5QuXb857Fa4ftMdfckd09KSEgoS3X+bUNGFpdO/oKtuw+d0PkiVcWBnDyuf24x\n81Z/zcNj+vCjs7pGOiSpgsI56swItTbS3P2xUpRPMLO4YLszoU79TUUU3QGMDLZHAeuD7beBa4PR\nZ8OAfeHqn6lXK551O7P48avLyC9Qy0aqp90Hcrj66QUs3LyHxy7vz7WnJkY6JKmiwtmiGQGMA0YV\nGrI82swuMrPtwKnAu2Y2Nyh/BrDczJYBrwET3X0PgJk9U2go9E3AH4JyvwEmBMffI5SYNgBPA7eG\nq2JtTqrLL37Qh0Vb9vC3zzaH6zYiEfPV3sNcNuUL1u7MYuq4wVw8qF2kQ5IqzGK5ryEpKcmTk5NP\n6Fx3Z8KLKXy0LpN3bzuNbi0bVnB0IpGx7ussrp22iINH8pg2fghDOzWNdEgSZcwsxd2TSi4Zores\nTpCZ8duLT6ZB7XjumrWM3PyCSIckUm6Lt+zh0r9+ToE7s24+VUlGKoQSTTk0b1Cb31zUlxVf7eNP\nH6wv+QSRKDZ31U6ueWYhzRvW5vVbh9OrdVGDPkXKTommnM7p25rLBrfjyfkbWLhpd6TDETkhL3yx\nhVteSqFX60a8NnE47ZrUi3RIUo0o0VSAh37Qh47N6nPnzFT2HcqNdDgipVZQ4Px2ThoPvrWKUT1b\nMOOmU2hav1akw5JqRommAtSvHc8TVw4gIyuHn76xXC9zSpWQnZvPpJmpTPloE9cM68DkawZTr5Ym\ndJeKp0RTQfq1O4kfn92D91bs5OVF20o+QSSC9hw8wrhpC3l72Q5+ck4PfjWmL/Fx+nUg4aE/XyrQ\nhNM789mGXTz0zir6t29MnzaNIx2SyH/ZvOsgP/zbInbsy+bPVw3kgv5tIh2SVHP6E6YC1ahhPH7F\nAJrWq8Wt05ewP1v9NRJdvti4m4ue+oz92Xm8fNMpSjJSKZRoKlizBrX5y9UD2f7NYX7yqvprJHrM\nXLyVcdMW0qx+Ld64dTiDO+odGakcSjRhkJTYlPvO6cn7q3Yy7VNNUSORlV/g/Oa9NO6dvYJTuzTj\n9VtH0LFZ/UiHJTFEfTRhcuPpnUj58ht+O2cNvVo3YkTX5pEOSWLQ/uxc7nh5KfPXZnLtqR158Pze\n6vSXSqefuDAxMx69vD9dEurzoxlL2LZHSwpI5dqUeYALn/yMT9bv4n8v6svDGlkmEaKfujBqUDue\nqeOSKChwbnohmUNH8iIdksSI+WsyGPPkZ+w9lMv0G09h7CkdIx2SxDAlmjBLbF6fP189iHVfZ3H3\nrGUUaP0aCaOCAucv/1rP9c8vpn2Terz1oxGc0rlZpMOSGKdEUwlGdk/g/tG9mLNyJ4/MXRvpcKSa\nysrO5ZbpKTz6j3WM6d+G2bcMp31TzVkmkafBAJXkhtM6sXnXQSZ/tJFOzetxxZAOkQ5JqpG1O7O4\n5aUUvtxziAfO68UNp3UitMitSOQp0VQSM+OhH/Rh655D/OyNlbRrUk8j0aRCvJX6FffNXkGDOvHM\nuPEUPSqTqKNHZ5WoZlwNnhw7iM4J9Zn4YgqrduyLdEhShWXn5vPAmyu445VUTm7bmHdvO01JRqKS\nEk0la1SnJs9fP5SGdeIZ/+xitu7WsGcpu827DnLxU5/z0oKt3HxGZ6bfdAotGtWJdFgiRVKiiYDW\njevywg1DySsoYNyzC8nMyol0SFKFvJX6FRf8+VN27DvMs9cl8dPRvaip92MkiumnM0K6tmjIs9cN\n4ev92Yx/dpEWTJMSHczJ48evLuOOV1Lp0aoh795+OqN6tox0WCIlUqKJoEEdmjBlXBIbMg5w7d8W\nkaXZnuU4Vn61jwv+/Cmzl2zn9lFdmTlhGG1PqhvpsERKJWyJxszam9l8M0szs1Vmdkdw/LJgv8DM\nkgqVTzSzw2aWGnxNPs51ZxYqs8XMUoPjtczsb2a2wsyWmdmZ4apbRRrZPYG/XD2QVV/t4/rnFmv2\nAPmW/ALnqQ83cOGTn3HwSB4zbhzGXd/voalkpEoJ5/DmPOBud19iZg2BFDObB6wELgamFHHORncf\nUNxF3f2Ko9tm9gfg6NCtm4LPTzazFsAcMxvi7gUVUJew+n6fVjx+5QBuf3kpNzyXzLTrkrSkrrD9\nm0PcNWsZizbvYfTJrfjNRSdzUr1akQ5LpMzC9tvM3dOB9GA7y8zSgLbuPg8o98tkFrrA5cCo4FBv\n4IPgfhlmthdIAhaV60aV5Px+bcjNL+DuWcsY/+winr1uCA3r1Ix0WBIB7s5bqTv4+ZsrKXDn0cv6\nc8mgtnoBU6qsSml/m1kiMBBYWELRTma21Mw+MrPTSyh7OvC1u68P9pcBY8ws3sw6AYOB9kXEMsHM\nks0sOTMC06lRAAAQXklEQVQzs0z1CLeLBrbjiSsHsmTrXsZNW8S+w+qziTX7DuVy+yupTJoZ6vCf\nc8cZXDq4nZKMVGlhfz5jZg2A2cAkd99fTNF0oIO77zazwcCbZtanmHOuAl4utP8s0AtIBr4EPif0\n+O5b3H0qMBUgKSkp6ma4vKB/G2rG1eC2l5dw9dMLeO6HQ0loWDvSYUkl+GhdJve+tpxdB3K45+we\nTBzZhbgaSjBS9YW1RWNmNQklmenu/npxZd09x913B9spwEag+3GuG0+on2dmofPz3P1Odx/g7mOA\nk4D1RZ0f7c7p24qp1yaxMfMAl03+XC91VnMHc/K4/40VjH92EQ3rxPPGrSP40VldlWSk2gjnqDMD\npgFp7v5YKconmFlcsN0Z6AZsOk7x7wJr3H17ofPrmVn9YPt7QJ67ry5nNSLmrB4tmHHTMPYezuXi\nv36u6Wqqqc827OLsxz/m5UVbmXBGZ9657TRObtc40mGJVKhwtmhGAOOAUYWGI482s4vMbDtwKvCu\nmc0Nyp8BLDezZcBrwER33wNgZs8UHgoNXMm3H5sBtACWBIMO7g3uXaUN6tCE1yaeSq0444opC5i/\nJiPSIUkF2Z+dy09fX8HYZxZSM64Gs24+lftH96JOzbhIhyZS4cw96ropKk1SUpInJydHOowSpe87\nzA3PJbNm534ePL83143oFOmQpBzeX7mTX7y9ksysHG46vTN3fq+7EoxUKWaW4u5JJZcM0csaVUDr\nxnV5deKp3PFKKg+9s5qNmQd58ILemt+qiknfd5hfvLWKf6z+ml6tGzFlXBID2p8U6bBEwk6Jpoqo\nXzueKeMG8/v31zD1402s2bmfJ68epBl7q4Dc/AKe+2wLj/9zHfnu3HduT244rZP+UJCYoURThcTV\nMO4f3Ys+bRpx3+wVnPfnT/nr2EEkJTaNdGhyHAs37ebnb61k3dcHGNWzBQ9d0IcOzbS8ssQW/UlV\nBY0Z0JY3fjSc+rXiuHLqAp76cAMFBbHb1xaNtn9ziB/NWMIVUxdwMCefqeMGM218kpKMxCS1aKqo\nnq0a8db/nMb9r6/gkffX8tmGXfzx8gF6lBZhB3PymPLRRqZ8vAkzmPTdbtx8Rhfq1lJnv8QujTqr\nAqPOiuPuzErexkNvr6ZurTh+fWFfRp/cOtJhxZy8/AJmJW/nsXnr2HUghwv6t+G+c3tqKn+pljTq\nLMaYGVcM6cDgjk25c2Yqt05fwnn9WvOrMX1pWl8z/YabuzN31U4e/cc6NmQcYEhiE56+djADOzSJ\ndGgiUUOJppro2qIBr986nCkfbeSJD9azYONufn5+b8YMaKMJGcPA3flk/S4e/cdalm/fR5eE+ky+\nZjBn92mpf2+RY+jRWRV/dFaUtPT93Dd7Ocu272N4l2Y8PKYvXVs0iHRY1YK789G6TP70wXqWbN1L\n25Pqcuf3unPhgDZajExiRlkfnSnRVMNEA6GVGWcs2soj768hOzefH47oxI/O6krjulrj5kQUFDjz\n0r7mqQ83smzbXto0rsOtZ3XlsqR21I5XR7/EFiWaMqjOieaozKwcHnl/Da8t2U7jujW54zvdGHtK\nR2rF66/v0sjJy+etpTuY8vFGNmYepF2Tutx6ZlcuHdxO/4YSs5RoyiAWEs1Rq3bs4zfvpfHZht20\nPakut43qyiWD2+nt9OPIyMpm+oKtTF/4JbsOHKFX60ZMHNmZ805urUdkEvOUaMoglhINhPoXPl6/\ni8fmrWPZtr20b1qXiSO7cMmgdprUkdC/z6LNe5i+cCtzVqaTm++M6tmCH45I5LSuzdXJLxJQoimD\nWEs0R7k789dm8MQ/17Ns+z6a1a/FtacmMnZYB5o3iL3VPDOysnlr6Q5mJm9jQ8YBGtWJ5+JB7bj2\n1I50TtAgCpFjKdGUQawmmqPcnYWb9/D0x5v4YE0GNeOM7/dpxdihHRjWuRk1qvEKj4eO5PHPtAze\nXPoVH63LJL/AGdjhJK4e2oHz+7XRm/wixdALm1JqZsawzs0Y1rkZGzIOMGPhVmYv2c67y9Np16Qu\nYwa04cIBbenWsmGkQ60QB3Ly+GhtJu+tTOdfaRkczs2nZaPaTDijM5cMaqch4CJhohZNDLdoipKd\nm8+clem8vuQrPtuwiwKHHi0b8v0+Lfl+71b0bduoyvRVuDtf7j7Ex+sz+SAtgy827uZIfgHN6tfi\n3JNbcUG/NgxJbFqtW24i4aBHZ2WgRFO8jKxs3l2ezvsrd7J4yx4KHFo2qs0Z3RIY2SOBEV2a0yTK\nprnZsfcwCzfvZtHmPXy6YRfb9hwGoGOzenyvV0u+36cVgzs2IU7JReSEKdGUgRJN6e05eIQP0r7m\nw7WZfLI+k/3ZeQB0a9GApMQmDOrQhD5tGtO1RYNKeb/E3cnMymHt11ms+Gofy7ftY/n2vezYlw1A\nwzrxnNKpKWd0T+D0bgkkNqtXZVpiItFOiaYMlGhOTF5+Acu272PBpt0kb9lD8pffkBUknlpxNejS\nogGdmtcjsVl9OjarR6vGdWnZqDYtGtahUZ34Ur2HkptfQFZ2HrsO5JCxP4eMrGy27TnMl3sOsnX3\nITZkHmDvodx/l09sVo9+7U5iYIeTGNqpKT1bNVKrRSRMNBhAwi4+rgaDOzZhcMfQDMUFBc6mXQdZ\nnb6f1Tv2s3bnftLSs/jHqq/JK2JBtnq14mhQO56acTWoGWfE1TDyC5zcfOdIfgEHsvM4nJtf5L1b\nN65D+6b1OLdva3q0bECPVo3o1bohJ9WLrkd4IvIfYUs0ZtYeeAFoBRQAU939CTO7DHgI6AUMdffk\noHwikAasDS6xwN0nFnHdmUCPYPckYK+7DzCzmsAzwCBC9XrB3X8bntpJYTVqGF1bNKBriwb8oH+b\nfx/PzS8gfW82GVnZ7NyfTWZWDlnZeew/nMvBI3kcyXNy8wvIL3Diahg142pQK96oXyueRnVr0rBO\nPM0b1KZFw9q0aFSH1o3r6MVSkSoonC2aPOBud19iZg2BFDObB6wELgamFHHORncfUNxF3f2Ko9tm\n9gdgX7B7GVDb3U82s3rAajN72d23VEBd5ATUjKtBh2b1tHyxSIwLW6Jx93QgPdjOMrM0oK27zwPK\n3TFroQtcDow6ekugvpnFA3WBI8D+ct1ERETKrVJmBwweiw0EFpZQtJOZLTWzj8zs9BLKng587e7r\ng/3XgIOEkttW4FF333PiUYuISEUI+2AAM2sAzAYmuXtxLYx0oIO77zazwcCbZtanmHOuAl4utD8U\nyAfaAE2AT8zsn+6+6Zh4JgATADp06HBCdRIRkdILa4sm6KCfDUx399eLK+vuOe6+O9hOATYC3Y9z\n3XhC/TwzCx2+Gnjf3XPdPQP4DPiv4XfuPtXdk9w9KSEh4USqJSIiZRC2RBP0oUwD0tz9sVKUTzCz\nuGC7M9AN2HSc4t8F1rj79kLHtgKjLKQ+MAxYU546iIhI+YWzRTMCGEfol39q8DXazC4ys+3AqcC7\nZjY3KH8GsNzMlhHqb5l4tI/FzJ4xs8Ktkyv59mMzgCeBBoRGtS0G/ubuy8NWOxERKRXNDKCZAURE\nyqSsMwNoTVoREQmrmG7RmFkm8GU5LtEc2FVB4VQFsVZfUJ1jhepcNh3dvdSjqWI60ZSXmSWXpflY\n1cVafUF1jhWqc3jp0ZmIiISVEo2IiISVEk35TI10AJUs1uoLqnOsUJ3DSH00IiISVmrRiIhIWMVc\nojGzc8xsrZltMLP7ivi8tpnNDD5fGMw8ffSznwbH15rZ2SVd08w6BddYH1yzVnD8OjPLLDRjwo3V\nvc7BZ5eb2WozW2VmM6pzfc3sj4W+v+vMbG+46htFde5gZvMtNAP7cjMbHQN17mhmHwT1/dDM2lWj\nOv9PcMzNrHmh42Zmfwo+W25mg0oM3N1j5guIIzRZZ2egFrAM6H1MmVuBycH2lcDMYLt3UL420Cm4\nTlxx1wRmAVcG25OBW4Lt64C/xFiduwFLgSbBfovqXN9j7ncb8GwMfI+nFtruDWyJgTq/CowPtkcB\nL1ajOg8EEoEtQPNC9xgNzAGM0JySC0uKPdZaNEOBDe6+yd2PAK8AY44pMwZ4Pth+DfiOmVlw/BUP\nzTK9GdgQXK/IawbnjAquQXDNC8NYt+OJljrfBDzp7t8AeGiG7XCIlvoWduySFhUtWursQKNguzGw\no4LrWVi01Lk38EGwPb+IGCpSpdUZwN2XetErFI8BXvCQBcBJZta6uMBjLdG0BbYV2t8eHCuyjLvn\nEVoqulkx5x7veDNgb3CNou51SdDsfM3M2penUiWIljp3B7qb2WdmtsDMzilnvY4nWuoLhB6tEPoL\n8l8nXKOSRUudHwKusdCkue8RasmFS7TUeRlwSbB9EdDQzJqdcK2KV5l1Lm8c3xJriaao9aOPHXZ3\nvDIVdRzgHSDR3fsB/+Q/f4GEQ7TUOZ7Q47MzCf2F/4yZnVRE+fKKlvoedSXwmrvnF1G2okRLna8C\nnnP3doQer7xoZuH6HRMtdf4xMNLMlgIjga+AvCLKV4TKrHN54/iWWEs024HCrYd2/Hfz/t9lLLTA\nWmNgTzHnHu/4LkJNyvhjjuPuu909Jzj+NDC4XLUqXlTUOTjnLQ8tTLcZWEso8VS0aKnvUUUtaVHR\noqXONxDqy8DdvwDqEJpPKxyios7uvsPdL3b3gcDPgmP7ylu546jMOpc3jm8LV8dVNH4R+qt6E6FH\nGUc7vvocU+ZHfLszbVaw3Ydvd6ZtItSRdtxrEuooLNyBeGuw3brQ/S4CFsRAnc8Bng+2mxNqejer\nrvUN9nsQ6ki1GPm5ngNcF2z3IvTLJyx1j6I6NwdqBNv/CzxcXb7Pha65hW8PBjiPbw8GWFRi7OH8\nHyAavwg16dcRGmnxs+DYw8APgu06wQ/VBmAR0LnQuT8LzlsLnFvcNYPjnYNrbAiuWTs4/ltgVfBN\nnQ/0jIE6G/AYsBpYcfR/2upa3+Czh4DfxdDPdW9CS6gvA1KB78dAnS8F1gfnPFP4+18N6nw7odZL\nHqE/Gp4JjhuhhSY3Evp/OamkuDUzgIiIhFWs9dGIiEglU6IREZGwUqIREZGwUqIREZGwUqIREZGw\nUqIRiRAze8jMflyazy0043ebyotOpOIo0YhUDdcBSjRSJSnRiFQiM/tZsPbHPwnNHICZdTGz980s\nxcw+MbOex5xzKZAETLfQ+jZ1zexBM1tsZivNbGowQ69IVFKiEakkZjaY0LQgA4GLgSHBR1OB29x9\nMKFJGp8qfJ67vwYkA2PdfYC7Hya0ntEQd+8L1AXOr6RqiJRZfMlFRKSCnA684e6HAMzsbUJThgwH\nXi3UKKldimudZWY/AeoBTQlNafROhUcsUgGUaEQq17FzPtUgtNbJgNJewMzqEGr1JLn7NjN7iFDC\nEolKenQmUnk+Bi4K+lgaAhcAh4DNZnYZ/Hs99v5FnJsFNAy2jyaVXWbWgNDEjiJRS4lGpJK4+xJg\nJqGZjWcDnwQfjQVuMLNlhB6BFbUc8HPAZDNLBXIIrWO0AngTWBzeyEXKR7M3i4hIWKlFIyIiYaVE\nIyIiYaVEIyIiYaVEIyIiYaVEIyIiYaVEIyIiYaVEIyIiYaVEIyIiYfX/6BeBb9cpo3UAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f52ed96eb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plot\n",
    "%matplotlib inline\n",
    "\n",
    "# Рисуем, чтобы удостовериться, что выбран правильный интервал поиска дельты\n",
    "# Этот интервал искался руками.\n",
    "axis = plot.gca()\n",
    "plot.plot(deltas, perplexities)\n",
    "axis.set_xlabel('delta')\n",
    "axis.set_ylabel('perplexy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stupid backoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея **простого отката** довольно понятна. Если у нас есть достаточно информцаии для подсчета вероятности $k$-грам, то будем использовать $k$-грамы. Иначе будем использовать вероятности $(k-1)$-грам с некоторым множителем, например, $0.4$, и так далее. К сожалению, в данном случае мы получим не вероятностное распределение, но в большинстве задач это не имеет принципиального значения. Если это все же важно, то необходимо подобрать множитель соответствующим образом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс, симулирующий сглаживание простым откатом. Он должен иметь аналогичный интерфейс, как и StraightforwardProbabilityEstimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StupidBackoffProbabilityEstimator:\n",
    "    \"\"\"Class for stupid backoff probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        P'(word | context),                  if  P'(word | context) > 0;\n",
    "        P'(word | context[1:]) * multiplier, if  P'(word | context) == 0\n",
    "                                             and P'(word | context[1:]) > 0;\n",
    "        ...\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        multiplier (float): Multiplier which is used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, multiplier=0.1):\n",
    "        self.__base_estimator = base_estimator\n",
    "        self.__mult = multiplier\n",
    "\n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) by one word.\n",
    "        \"\"\"\n",
    "        if len(context) != 1:\n",
    "            return context[1:]\n",
    "        else:\n",
    "            return tuple()\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        counter = 0\n",
    "        while self.__base_estimator(word, context) == 0:\n",
    "            context = self.cut_context(context)\n",
    "            counter += 1\n",
    "        prob = (self.__mult ** counter) * self.__base_estimator(word, context)\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stupid backoff estimator perplexity = 121.98634637596338\n",
      "0.000379971097201\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "sbackoff_estimator = StupidBackoffProbabilityEstimator(simple_estimator, .4)\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Stupid backoff estimator perplexity = {}'.format(perplexity(sbackoff_estimator, test_sents)))\n",
    "print(laplace_estimator.prob('To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответьте на следующие вопросы (внутри ipython ноутбука):\n",
    "\n",
    "**Q:** Почему бессмысленно измерять перплексию в случае **Stupid backoff**?  \n",
    "**A:** Из-за тупого отнятия вероятности распределение перестает быть вероятностным (сумма всех вероятностей не единица). Перплексия, как вероятностная величина теряет значение.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае идея сглаживания посредством **интерполяции** также крайне проста. Пусть у нас есть $N$-грамная модель. Заведем вектор $\\bar\\lambda = (\\lambda_1, \\dots, \\lambda_N)$, такой, что $\\sum_i\\lambda_i = 1$ и $\\lambda_i \\geq 0$. Тогда\n",
    "\n",
    "$$\n",
    "    \\hat P_{IS}(w_{N} \\mid w_1^{N-1}) = \\sum_{i=1}^N \\lambda_i \\hat P_{S}(w_N \\mid w_{N-i+1}^{N-1}).\n",
    "$$\n",
    "\n",
    "Придумайте, как обойтись одним вектором $\\bar\\lambda$, т.е. пользоваться им как в случае контекста длины $N$, так и при контексте меньшей длины (например, в начале предложения). Если мы просто обрубим сумму, то у нас уже не будет вероятностное распределение, что, конечно же, плохо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InterpolationProbabilityEstimator:\n",
    "    \"\"\"Class for interpolation probability estimations.\n",
    "    \n",
    "    P(word | context) =\n",
    "        lambda_N * P'(word | context) +\n",
    "        lambda_{N-1} * P'(word | context[1:]) +\n",
    "        ... +\n",
    "        lambda_1 * P'(word)\n",
    "    P'(word | context) - probability of a word provided context of a base estimator.\n",
    "    \n",
    "    Args:\n",
    "        base_estimator(BaseProbabilityEstimator): Object of BaseProbabilityEstimator\n",
    "            or some other class which can estimate conditional probabilities.\n",
    "        lambdas (np.array[float]): Lambdas which are used for probability estimations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_estimator, lambdas):\n",
    "        self.lambdas = lambdas\n",
    "        self.__base_estimator = base_estimator\n",
    "        \n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        def normalized(lambdas):\n",
    "            lambdas_sum = sum(lambdas)\n",
    "            return np.array([one_lambda / lambdas_sum for one_lambda in lambdas])\n",
    "        # Обрезаем лямбды в начале. Делаем так, чтобы их было на 1 больше, чем длина контекста.\n",
    "        current_lambdas = normalized(self.lambdas[(len(self.lambdas) - len(context) - 1):])\n",
    "        prob = np.sum([\n",
    "            one_lambda * self.__base_estimator(word, context[i:])\n",
    "            for i, one_lambda in enumerate(reversed(current_lambdas))\n",
    "        ])\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolation estimator perplexity = 235.5084232953787\n",
      "0.000379971097201\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize estimator\n",
    "interpol_estimator = InterpolationProbabilityEstimator(simple_estimator, np.array([0.2, 0.2, 0.6]))\n",
    "\n",
    "# Let's make some estimations\n",
    "print('Interpolation estimator perplexity = {}'.format(perplexity(interpol_estimator, test_sents)))\n",
    "print(laplace_estimator.prob('To be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучить значения параметров $\\lambda$ можно с помощью EM-алгоритма, но мы не будем этого здесь делать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея данного сглаживания заключается в том, что словам, которые участвуют в большом количестве контекстов, присваиваются большие вероятности, а те, которые используются в паре-тройке контекстов, получают маленькие вероятности. Формулы приведены на слайде 37 лекции.\n",
    "Реализуйте данный подход."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KneserNeyProbabilityEstimator:\n",
    "    \"\"\"Class for probability estimations of type P(word | context).\n",
    "    \n",
    "    P(word | context) = ...\n",
    "    \n",
    "    Args:\n",
    "        storage(NGramStorage): Object of NGramStorage class which will\n",
    "            be used to extract frequencies of ngrams.\n",
    "        delta(float): KneserNey parameter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, storage, delta=1.):\n",
    "        self.__storage = storage\n",
    "        self.__delta = delta\n",
    "        \n",
    "        self._unique_continuations_number = Counter()\n",
    "        for length in range(1, self.__storage.max_n):\n",
    "            for ngramm in self.__storage[length]:\n",
    "                self._unique_continuations_number[ngramm[:-1]] += 1\n",
    "        \n",
    "        self._continuations_number = Counter()\n",
    "        for length in range(1, self.__storage.max_n):\n",
    "            for ngramm in self.__storage[length]:\n",
    "                self._continuations_number[ngramm[:-1]] += self.__storage(ngramm)\n",
    "        \n",
    "        self._bigramms_beginigs_number = Counter()\n",
    "        for bigramm in self.__storage[2]:\n",
    "            self._bigramms_beginigs_number[bigramm[1]] += self.__storage(bigramm)\n",
    "        \n",
    "        counter = 0\n",
    "        for sentence in self.__storage[2]:\n",
    "            counter += self.__storage[2][sentence]\n",
    "        self._bigramms_number = counter\n",
    "    \n",
    "    def cut_context(self, context):\n",
    "        \"\"\"Cut context if it is too large.\n",
    "        \n",
    "        Args:\n",
    "            context (tuple[str]): Some sequence of words.\n",
    "        \n",
    "        Returns:\n",
    "            Cutted context (tuple[str]) up to the length of max_n.\n",
    "        \"\"\"\n",
    "        if len(context) + 1 > self.__storage.max_n:\n",
    "            context = context[-self.__storage.max_n + 1:]\n",
    "        return context\n",
    "\n",
    "    def __call__(self, word, context):\n",
    "        \"\"\"Estimate conditional probability P(word | context).\n",
    "        \n",
    "        Args:\n",
    "            word (str): Current word.\n",
    "            context (tuple[str]): Context of a word.\n",
    "            \n",
    "        Returns:\n",
    "            Conditional probability (float) P(word | context).\n",
    "        \"\"\"\n",
    "        # Cheking the input\n",
    "        if not isinstance(word, str):\n",
    "            raise TypeError('word must be a string!')\n",
    "        if not isinstance(context, tuple):\n",
    "            raise TypeError('word must be a string!')\n",
    "        # If context is too large, let's cut it.\n",
    "        context = self.cut_context(context)\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "        phrase_counts = self.__storage(context + (word, ))\n",
    "        context_continuations = self._continuations_number[context]\n",
    "        if context_continuations == 0:\n",
    "            prob = self(word, context[1:])\n",
    "        elif len(context) == 0:\n",
    "            prob = self._bigramms_beginigs_number[word] / self._bigramms_number\n",
    "        else:\n",
    "            prob = (\n",
    "                max(phrase_counts - self.__delta, 0) / context_continuations\n",
    "                + self.__delta * self._unique_continuations_number[context]\n",
    "                * self(word, context[1:]) / context_continuations\n",
    "            )\n",
    "        ### END YOUR CODE\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    def prob(self, sent):\n",
    "        \"\"\"Estimate probability of a sentence using Markov rule.\n",
    "        \n",
    "        Args:\n",
    "            sentence (list[str]): Sentence for probability estimation.\n",
    "            \n",
    "        Returns:\n",
    "            Probability (float) P(sentence).\n",
    "        \"\"\"\n",
    "        prob = 1.\n",
    "        for i in range(len(sent)):\n",
    "            prob *= self(sent[i], tuple(sent[:i]))\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple estimator perplexity = 248.85089007351334\n",
      "0.0014698187545864685\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize estimator\n",
    "kn_estimator = KneserNeyProbabilityEstimator(storage)\n",
    "\n",
    "# Estimating perplexity\n",
    "print('Simple estimator perplexity = {}'.format(perplexity(kn_estimator, test_sents)))\n",
    "print(simple_estimator.prob('To be'.split()))\n",
    "print(simple_estimator.prob('To be or not to be'.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение языка документа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Постановка задачи:**  \n",
    "Одна из задач, которая может быть решена при помощи языковых моделей $-$ **определение языка документа**. Реализуйте два классификатора для определения языка документа:\n",
    "1. Наивный классификатор, который будет учитывать частоты символов и выбирать язык текста по признаку: распределение частот символов \"наиболее похоже\" на распределение частот символов в выбранном языке.\n",
    "2. Классификатор на основе языковых моделей. Сами придумайте, как он должен работать.  \n",
    "_Подсказка_: лучше считать n-грамы не по словам, а по символам.\n",
    "\n",
    "---\n",
    "\n",
    "**Как представлены данные:**  \n",
    "Во всех текстовых файлах на каждой строчке записано отдельное предложение.\n",
    "1. В папке _data_ находятся две папки: _full_ и _plain_. В _full_ находятся тексты в той форме, что они были взяты из сети, в _plain_ находятся те же самые тексты, но с них сначала была снята диакритика, а затем русский и греческий тексты были транслитерованы в английский.\n",
    "2. В каждой из папок _full_ и _plain_ находятся папки _train_ и _test_.\n",
    "3. В _train_ находятся файлы с текстами с говорящими именами, например, _ru.txt_, _en.txt_.\n",
    "4. В _test_ находятся файлы _1.txt_, _2.txt_, $\\dots$ в которых хранятся тексты, язык которых нужно определить. В этой же папке находится файл _ans.csv_, в котором вы можете найти правильные ответы и проверить, насколько хорошо сработали Ваши алгоритмы.\n",
    "\n",
    "---\n",
    "\n",
    "**Что нужно сделать:**  \n",
    "Напишите два своих классификатора (которые описаны в постановке задачи) и получите максимально возможное accuracy на test-сете. Разрешается использовать только _train_ для обучения.\n",
    "\n",
    "---\n",
    "\n",
    "**В данном задании мы не предоставляем стартового кода!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write the code and estimate accuracy of your method.\n",
    "# Create your own classifiers.\n",
    "\n",
    "### YOUR CODE HERE\n",
    "\n",
    "### END YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_plain_test_sentencies():\n",
    "    result = {}\n",
    "    for i in range(1, 240):\n",
    "        sentencies = []\n",
    "        with open('language_detection/plain/test/' + str(i) + '.txt') as file:\n",
    "            for line in file:\n",
    "                sentencies.append(line.strip()[:-1].lower().split(' '))\n",
    "        result[i] = sentencies\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_test_sents = get_plain_test_sentencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def get_plain_train_sentencies():\n",
    "    result = {}\n",
    "    plain_train_path = 'language_detection/plain/train/'\n",
    "    train_files = [file for file in listdir(plain_train_path) if file.endswith('.txt')]\n",
    "    for train_file in train_files:\n",
    "        sentencies = []\n",
    "        with open(plain_train_path + train_file) as file:\n",
    "            for line in file:\n",
    "                sentencies.append(line.strip()[:-1].lower().split(' '))\n",
    "        result[train_file[:-4]] = sentencies\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "plain_train_sentencies = get_plain_train_sentencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_any_key(dictionary):\n",
    "    for key in dictionary:\n",
    "        return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def storagies_difference(storage_1, storage_2):\n",
    "    difference = 0\n",
    "    for length in range(max(storage_1.max_n, storage_2.max_n)):\n",
    "        n_gramms = {key for key in storage_1[length].keys()}\n",
    "        n_gramms.update({key for key in storage_2[length].keys()})\n",
    "        for n_gramm in n_gramms:\n",
    "            difference += abs(storage_1(n_gramm) - storage_2(n_gramm))\n",
    "    return difference\n",
    "\n",
    "class NaiveClassifier:\n",
    "    def __init__(self):\n",
    "        self.storagies = {}\n",
    "\n",
    "    def fit(self, language_name, sentencies):\n",
    "        self.storagies[language_name] = NGramStorage(sentencies)\n",
    "        \n",
    "    def predict(self, sentencies):\n",
    "        temp_storage = NGramStorage(sentencies)\n",
    "        least_difference = storagies_difference(temp_storage, self.storagies[get_any_key(self.storagies)])\n",
    "        result_language = get_any_key(self.storagies)\n",
    "        for language in self.storagies:\n",
    "            new_difference = storagies_difference(temp_storage, self.storagies[language])\n",
    "            if new_difference < least_difference:\n",
    "                least_difference = new_difference\n",
    "                result_language = language\n",
    "        return result_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LaplaceClassifier:\n",
    "    def __init__(self):\n",
    "        self.storagies = {}\n",
    "\n",
    "    def fit(self, language_name, sentencies):\n",
    "        self.storagies[language_name] = LaplaceProbabilityEstimator(NGramStorage(sentencies))\n",
    "        \n",
    "    def predict(self, sentencies):\n",
    "        result_language = get_any_key(self.storagies)\n",
    "        biggest_probability = self.storagies[result_language].prob(sentencies)\n",
    "        for language in self.storagies:\n",
    "            new_probability = self.storagies[language].prob(sentencies)\n",
    "            if new_probability < biggest_probability:\n",
    "                biggest_probability = new_probability\n",
    "                result_language = language\n",
    "        return result_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_classifier = NaiveClassifier()\n",
    "for language in plain_train_sentencies:\n",
    "    naive_classifier.fit(language, plain_train_sentencies[language])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "laplace_classifier = LaplaceClassifier()\n",
    "for language in plain_train_sentencies:\n",
    "    laplace_classifier.fit(language, plain_train_sentencies[language])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['so', 'verdarb', 'ihn', 'emma', 'noch', 'aus', 'ihrem', 'grabe', 'heraus'],\n",
       " ['denn',\n",
       "  'alle',\n",
       "  'reisenden',\n",
       "  'stimmen',\n",
       "  'in',\n",
       "  'dem',\n",
       "  'punkte',\n",
       "  'miteinander',\n",
       "  'uberein,',\n",
       "  'daß',\n",
       "  'die',\n",
       "  'australier',\n",
       "  'sich',\n",
       "  'geradezu',\n",
       "  'scheuen,',\n",
       "  'blut',\n",
       "  'zu',\n",
       "  'vergießen,',\n",
       "  'und',\n",
       "  'oftmals',\n",
       "  'schon',\n",
       "  'haben',\n",
       "  'jene',\n",
       "  'in',\n",
       "  'ihnen',\n",
       "  'treue',\n",
       "  'verbundete',\n",
       "  'gefunden,',\n",
       "  'um',\n",
       "  'den',\n",
       "  'angriff',\n",
       "  'von',\n",
       "  'ganz',\n",
       "  'anders',\n",
       "  'grausamen',\n",
       "  'rauberbanden',\n",
       "  'zuruckzuweisen'],\n",
       " ['und',\n",
       "  'man',\n",
       "  'wurde',\n",
       "  'ihn',\n",
       "  'fur',\n",
       "  'die',\n",
       "  'folgen',\n",
       "  'verantwortlich',\n",
       "  'machen',\n",
       "  '--',\n",
       "  'warum',\n",
       "  'auch',\n",
       "  'nicht'],\n",
       " ['ost',\n",
       "  'conserviren',\n",
       "  'die',\n",
       "  'maoris',\n",
       "  'den',\n",
       "  'kopf',\n",
       "  'ihrer',\n",
       "  'eigenen',\n",
       "  'chefs;',\n",
       "  'aber',\n",
       "  'in',\n",
       "  'diesem',\n",
       "  'falle',\n",
       "  'bleibt',\n",
       "  'das',\n",
       "  'auge',\n",
       "  'in',\n",
       "  'seiner',\n",
       "  'hohlung',\n",
       "  'offen'],\n",
       " ['lange',\n",
       "  'vor',\n",
       "  'ankunft',\n",
       "  'der',\n",
       "  'europaer',\n",
       "  'befriedigten',\n",
       "  'die',\n",
       "  'seelander',\n",
       "  'ihre',\n",
       "  'gefraßigkeit',\n",
       "  'durch',\n",
       "  'den',\n",
       "  'mord'],\n",
       " ['dieser',\n",
       "  'souveran,',\n",
       "  'der',\n",
       "  'ubrigens',\n",
       "  'von',\n",
       "  'den',\n",
       "  'großmachten',\n",
       "  'europas',\n",
       "  'noch',\n",
       "  'nicht',\n",
       "  'anerkannt',\n",
       "  'ist,',\n",
       "  'bezieht',\n",
       "  'von',\n",
       "  'dort',\n",
       "  'eine',\n",
       "  'civilliste',\n",
       "  'von',\n",
       "  '75,000',\n",
       "  'bis',\n",
       "  '80,000',\n",
       "  'francs,',\n",
       "  'durch',\n",
       "  'fischen,',\n",
       "  'einsalzen',\n",
       "  'und',\n",
       "  'versenden',\n",
       "  'eines',\n",
       "  '»cheilodactylus«,',\n",
       "  'der',\n",
       "  'unter',\n",
       "  'dem',\n",
       "  'namen',\n",
       "  'kabeljau',\n",
       "  'wohl',\n",
       "  'allgemeiner',\n",
       "  'bekannt',\n",
       "  'ist'],\n",
       " ['sie',\n",
       "  'kamen',\n",
       "  'ohne',\n",
       "  'muhe',\n",
       "  'uber',\n",
       "  'die',\n",
       "  'ufer',\n",
       "  'des',\n",
       "  'murray',\n",
       "  'und',\n",
       "  'darling',\n",
       "  'und',\n",
       "  'erreichten',\n",
       "  'die',\n",
       "  'station',\n",
       "  'menindie',\n",
       "  'an',\n",
       "  'der',\n",
       "  'grenze',\n",
       "  'der',\n",
       "  'colonien'],\n",
       " ['ljewin',\n",
       "  'sah,',\n",
       "  'daß',\n",
       "  'es',\n",
       "  'ihm',\n",
       "  'auf',\n",
       "  'diese',\n",
       "  'weise',\n",
       "  'nicht',\n",
       "  'gelingen',\n",
       "  'werde,',\n",
       "  'den',\n",
       "  'inneren',\n",
       "  'zusammenhang',\n",
       "  'zwischen',\n",
       "  'dem',\n",
       "  'praktischen',\n",
       "  'leben',\n",
       "  'dieses',\n",
       "  'mannes',\n",
       "  'und',\n",
       "  'seiner',\n",
       "  'gedankenwelt',\n",
       "  'zu',\n",
       "  'finden'],\n",
       " ['zweifellos',\n",
       "  'ist',\n",
       "  'ihnen',\n",
       "  'nicht',\n",
       "  'unbekannt,',\n",
       "  'daß',\n",
       "  'nepeta',\n",
       "  'cataria,',\n",
       "  'vulgar',\n",
       "  'katzenminze,',\n",
       "  'sonderbarerweise',\n",
       "  'auf',\n",
       "  'das',\n",
       "  'gesamte',\n",
       "  'katzengeschlecht',\n",
       "  'als',\n",
       "  'aphrodisiakum',\n",
       "  'wirkt'],\n",
       " ['deshalb', 'schwieg', 'k.', 'ein', 'weilchen'],\n",
       " ['das',\n",
       "  'da',\n",
       "  'war',\n",
       "  'nicht',\n",
       "  'ein',\n",
       "  'einfaches',\n",
       "  'madchen,',\n",
       "  'das',\n",
       "  'aus',\n",
       "  'einem',\n",
       "  'theilchen',\n",
       "  'unserer',\n",
       "  'erde',\n",
       "  'gebildet',\n",
       "  'und',\n",
       "  'durch',\n",
       "  'den',\n",
       "  'flackernden',\n",
       "  'strahl',\n",
       "  'einer',\n",
       "  'frauenseele',\n",
       "  'armlich',\n",
       "  'im',\n",
       "  'innern',\n",
       "  'erleuchtet',\n",
       "  'wurde:',\n",
       "  'es',\n",
       "  'war',\n",
       "  'ein',\n",
       "  'engel!',\n",
       "  'aber',\n",
       "  'der',\n",
       "  'finsternis,',\n",
       "  'der',\n",
       "  'flamme',\n",
       "  'und',\n",
       "  'nicht',\n",
       "  'dem',\n",
       "  'lichte',\n",
       "  'entstammend'],\n",
       " ['alle', 'hatten', 'die', 'kopfe', 'gesenkt'],\n",
       " ['als',\n",
       "  'schon',\n",
       "  'die',\n",
       "  'halfte',\n",
       "  'der',\n",
       "  'kinder',\n",
       "  'wieder',\n",
       "  'angekleidet',\n",
       "  'war,',\n",
       "  'kamen',\n",
       "  'einige',\n",
       "  'bauernweiber',\n",
       "  'in',\n",
       "  'ihrem',\n",
       "  'sonntagsstaat,',\n",
       "  'die',\n",
       "  'ausgegangen',\n",
       "  'waren,',\n",
       "  'um',\n",
       "  'barenklau',\n",
       "  'und',\n",
       "  'bibernell',\n",
       "  'zu',\n",
       "  'suchen,',\n",
       "  'zu',\n",
       "  'dem',\n",
       "  'badehauschen',\n",
       "  'und',\n",
       "  'blieben',\n",
       "  'schuchtern',\n",
       "  'an',\n",
       "  'der',\n",
       "  'tur',\n",
       "  'stehen'],\n",
       " ['–',\n",
       "  'welche,',\n",
       "  'mein',\n",
       "  'herr?',\n",
       "  'antwortete',\n",
       "  'das',\n",
       "  'kind,',\n",
       "  'das',\n",
       "  'nicht',\n",
       "  'die',\n",
       "  'fassung',\n",
       "  'verlor'],\n",
       " ['es',\n",
       "  'schien',\n",
       "  'ihr',\n",
       "  'in',\n",
       "  'diesem',\n",
       "  'augenblick,',\n",
       "  'als',\n",
       "  'habe',\n",
       "  'sie',\n",
       "  'schon',\n",
       "  'alles',\n",
       "  'gesagt'],\n",
       " ['4', 'die', 'freundin', 'des', 'fraulein', 'burstne'],\n",
       " ['niemals',\n",
       "  'habe',\n",
       "  'er,',\n",
       "  'so',\n",
       "  'lange',\n",
       "  'er',\n",
       "  'schon',\n",
       "  'fuhrer',\n",
       "  'gewesen,',\n",
       "  'einen',\n",
       "  'so',\n",
       "  'durchweichten',\n",
       "  'boden',\n",
       "  'betreten'],\n",
       " ['und',\n",
       "  'er',\n",
       "  'that',\n",
       "  'ein',\n",
       "  'weiteres,',\n",
       "  'ja',\n",
       "  'des',\n",
       "  'guten',\n",
       "  'zu',\n",
       "  'viel;',\n",
       "  'doch',\n",
       "  'schadete',\n",
       "  'es',\n",
       "  'ihm',\n",
       "  'nichts,',\n",
       "  'dank',\n",
       "  'dem',\n",
       "  'klaren',\n",
       "  'guaminiwasser,',\n",
       "  'welches',\n",
       "  'ganz',\n",
       "  'besonders',\n",
       "  'der',\n",
       "  'verdauung',\n",
       "  'forderlich',\n",
       "  'zu',\n",
       "  'sein',\n",
       "  'schien'],\n",
       " ['das', 'licht', 'war', 'verschwunden'],\n",
       " ['bauern,',\n",
       "  'mantel',\n",
       "  'um',\n",
       "  'die',\n",
       "  'schultern,',\n",
       "  'sangen',\n",
       "  'im',\n",
       "  'chor',\n",
       "  'ein',\n",
       "  'lied'],\n",
       " ['diese,',\n",
       "  'schon',\n",
       "  'durch',\n",
       "  'die',\n",
       "  'uns',\n",
       "  'von',\n",
       "  'ayrton',\n",
       "  'gegebenen',\n",
       "  'details',\n",
       "  'bewiesenen',\n",
       "  'thatsachen',\n",
       "  'werden',\n",
       "  'noch',\n",
       "  'durch',\n",
       "  'die',\n",
       "  'worte',\n",
       "  'der',\n",
       "  'straflinge,',\n",
       "  'welche',\n",
       "  'ich',\n",
       "  'euch',\n",
       "  'mitgetheilt',\n",
       "  'habe,',\n",
       "  'verstarkt'],\n",
       " ['er', 'ware', 'ein', 'verlassener,', 'freundloser', 'junge', 'dachte', 'er'],\n",
       " ['aber',\n",
       "  'mit',\n",
       "  'erstaunen',\n",
       "  'und',\n",
       "  'bedauern',\n",
       "  'erfullte',\n",
       "  'ihn',\n",
       "  'die',\n",
       "  'gereizte,',\n",
       "  'erregte',\n",
       "  'stimmung,',\n",
       "  'in',\n",
       "  'die',\n",
       "  'golenischtschew',\n",
       "  'geriet,',\n",
       "  'wahrend',\n",
       "  'er',\n",
       "  'uber',\n",
       "  'den',\n",
       "  'gegenstand,',\n",
       "  'der',\n",
       "  'ihn',\n",
       "  'beschaftigte,',\n",
       "  'diese',\n",
       "  'mitteilungen',\n",
       "  'machte'],\n",
       " ['»es',\n",
       "  'ist',\n",
       "  'alles',\n",
       "  'zu',\n",
       "  'ende;',\n",
       "  'weiter',\n",
       "  'kann',\n",
       "  'ich',\n",
       "  'nichts',\n",
       "  'sagen«,',\n",
       "  'antwortete',\n",
       "  'dolly.',\n",
       "  '»und,',\n",
       "  'weißt',\n",
       "  'du,',\n",
       "  'das',\n",
       "  'allerschlimmste',\n",
       "  'ist,',\n",
       "  'daß',\n",
       "  'ich',\n",
       "  'ihn',\n",
       "  'nicht',\n",
       "  'verlassen',\n",
       "  'kann,',\n",
       "  'der',\n",
       "  'kinder',\n",
       "  'wegen;',\n",
       "  'ich',\n",
       "  'bin',\n",
       "  'gebunden'],\n",
       " ['»der?«',\n",
       "  'erwiderte',\n",
       "  'sie',\n",
       "  'hohnisch.',\n",
       "  '»der',\n",
       "  'ist',\n",
       "  'vollstandig',\n",
       "  'zufrieden.'],\n",
       " ['ach,',\n",
       "  'wenn',\n",
       "  'mein',\n",
       "  'dasein',\n",
       "  'einen',\n",
       "  'zweck',\n",
       "  'gehabt',\n",
       "  'hatte,',\n",
       "  'wenn',\n",
       "  'ich',\n",
       "  'einer',\n",
       "  'großen',\n",
       "  'leidenschaft',\n",
       "  'begegnet',\n",
       "  'ware,',\n",
       "  'wenn',\n",
       "  'ich',\n",
       "  'ein',\n",
       "  'herz',\n",
       "  'gefunden',\n",
       "  'hatte',\n",
       "  '..'],\n",
       " ['»ja,',\n",
       "  'ja,',\n",
       "  'ich',\n",
       "  'bete',\n",
       "  'miß',\n",
       "  'georgiana',\n",
       "  'an!«',\n",
       "  'rief',\n",
       "  'die',\n",
       "  'begeisterte',\n",
       "  'abbot.',\n",
       "  '»der',\n",
       "  'kleine',\n",
       "  'suße',\n",
       "  'liebling!',\n",
       "  '–',\n",
       "  'mit',\n",
       "  'ihren',\n",
       "  'langen',\n",
       "  'locken',\n",
       "  'und',\n",
       "  'blauen',\n",
       "  'augen,',\n",
       "  'und',\n",
       "  'den',\n",
       "  'sußen,',\n",
       "  'lieblichen',\n",
       "  'farben,',\n",
       "  'gerade',\n",
       "  'als',\n",
       "  'ob',\n",
       "  'sie',\n",
       "  'angemalt',\n",
       "  'ware!',\n",
       "  '–',\n",
       "  'bessie,',\n",
       "  'ich',\n",
       "  'hatte',\n",
       "  'wahrhaftig',\n",
       "  'appetit',\n",
       "  'auf',\n",
       "  'einen',\n",
       "  'gerosteten',\n",
       "  'kase',\n",
       "  'zum',\n",
       "  'abendbrot.'],\n",
       " ['die',\n",
       "  'beiden',\n",
       "  'waren',\n",
       "  'viel',\n",
       "  'zu',\n",
       "  'sehr',\n",
       "  'in',\n",
       "  'ihren',\n",
       "  'streit',\n",
       "  'vertieft',\n",
       "  'gewesen,',\n",
       "  'um',\n",
       "  'die',\n",
       "  'plotzliche',\n",
       "  'stille',\n",
       "  'zu',\n",
       "  'bemerken,',\n",
       "  'die',\n",
       "  'sich',\n",
       "  'uber',\n",
       "  'die',\n",
       "  'klasse',\n",
       "  'gelagert',\n",
       "  'hatte,',\n",
       "  'wahrend',\n",
       "  'der',\n",
       "  'lehrer',\n",
       "  'auf',\n",
       "  'den',\n",
       "  'zehen',\n",
       "  'von',\n",
       "  'seinem',\n",
       "  'pult',\n",
       "  'heruntergeschlichen',\n",
       "  'kam'],\n",
       " ['doch',\n",
       "  'man',\n",
       "  'hatte',\n",
       "  'keine',\n",
       "  'wahl,',\n",
       "  'und',\n",
       "  'fur',\n",
       "  'eine',\n",
       "  'ueberfahrt',\n",
       "  'von',\n",
       "  'funf',\n",
       "  'bis',\n",
       "  'sechs',\n",
       "  'tagen',\n",
       "  'brauchte',\n",
       "  'man',\n",
       "  'ihn',\n",
       "  'nicht',\n",
       "  'so',\n",
       "  'genau',\n",
       "  'anzusehen'],\n",
       " ['nichts',\n",
       "  'erwirbt',\n",
       "  'einem',\n",
       "  'fursten',\n",
       "  'so',\n",
       "  'viel',\n",
       "  'achtung,',\n",
       "  'als',\n",
       "  'große',\n",
       "  'unternehmungen',\n",
       "  'und',\n",
       "  'glanzende',\n",
       "  'handlungen'],\n",
       " ['»sie',\n",
       "  'haben',\n",
       "  'schone',\n",
       "  'dunkle',\n",
       "  'augen«,',\n",
       "  'sagte',\n",
       "  'sie,',\n",
       "  'nachdem',\n",
       "  'sie',\n",
       "  'sich',\n",
       "  'gesetzt',\n",
       "  'hatten,',\n",
       "  'und',\n",
       "  'sah',\n",
       "  'k.',\n",
       "  'von',\n",
       "  'unten',\n",
       "  'ins',\n",
       "  'gesicht,',\n",
       "  '»man',\n",
       "  'sagt',\n",
       "  'mir,',\n",
       "  'ich',\n",
       "  'hatte',\n",
       "  'auch',\n",
       "  'schone',\n",
       "  'augen,',\n",
       "  'aber',\n",
       "  'ihre',\n",
       "  'sind',\n",
       "  'viel',\n",
       "  'schoner'],\n",
       " ['zieht', 'mir', 'nur', 'noch', 'die', 'beine', 'ein', 'wenig', 'gerade'],\n",
       " ['plotzlich',\n",
       "  'horte',\n",
       "  'sie',\n",
       "  'ein',\n",
       "  'gleichmaßiges',\n",
       "  'ruhiges',\n",
       "  'pfeifen',\n",
       "  'durch',\n",
       "  'die',\n",
       "  'nase'],\n",
       " ['ihr',\n",
       "  'begehr',\n",
       "  'muß',\n",
       "  'erfullt',\n",
       "  'werden,',\n",
       "  'oder',\n",
       "  'sie',\n",
       "  'nimmt',\n",
       "  'furchtbare',\n",
       "  'rache',\n",
       "  'an',\n",
       "  'ihrer',\n",
       "  'irdischen',\n",
       "  'hulle.'],\n",
       " ['bei',\n",
       "  'diesem',\n",
       "  'namen,',\n",
       "  'der',\n",
       "  'an',\n",
       "  'ihre',\n",
       "  'ehebruche',\n",
       "  'und',\n",
       "  'all',\n",
       "  'ihr',\n",
       "  'mißgeschick',\n",
       "  'erinnerte,',\n",
       "  'wandte',\n",
       "  'sich',\n",
       "  'frau',\n",
       "  'bovary',\n",
       "  'ab,',\n",
       "  'als',\n",
       "  'fuhle',\n",
       "  'sie',\n",
       "  'den',\n",
       "  'ekelhaften',\n",
       "  'geschmack',\n",
       "  'eines',\n",
       "  'noch',\n",
       "  'viel',\n",
       "  'starkeren',\n",
       "  'giftes',\n",
       "  'auf',\n",
       "  'der',\n",
       "  'zunge'],\n",
       " ['lord',\n",
       "  'glenarvan',\n",
       "  'kehrte',\n",
       "  'in',\n",
       "  'raschester',\n",
       "  'fahrt',\n",
       "  'nach',\n",
       "  'malcolm-castle',\n",
       "  'zuruck'],\n",
       " ['jetzt',\n",
       "  'hingegen,',\n",
       "  'wenn',\n",
       "  'er',\n",
       "  'seine',\n",
       "  'verteidigung',\n",
       "  'selbst',\n",
       "  'fuhren',\n",
       "  'wurde,',\n",
       "  'mußte',\n",
       "  'er',\n",
       "  'sich',\n",
       "  '–',\n",
       "  'wenigstens',\n",
       "  'fur',\n",
       "  'den',\n",
       "  'augenblick',\n",
       "  '–',\n",
       "  'ganz',\n",
       "  'und',\n",
       "  'gar',\n",
       "  'dem',\n",
       "  'gericht',\n",
       "  'aussetzen,',\n",
       "  'der',\n",
       "  'erfolg',\n",
       "  'dessen',\n",
       "  'sollte',\n",
       "  'ja',\n",
       "  'fur',\n",
       "  'spater',\n",
       "  'seine',\n",
       "  'vollstandige',\n",
       "  'und',\n",
       "  'endgultige',\n",
       "  'befreiung',\n",
       "  'sein,',\n",
       "  'aber',\n",
       "  'um',\n",
       "  'diese',\n",
       "  'zu',\n",
       "  'erreichen,',\n",
       "  'mußte',\n",
       "  'er',\n",
       "  'sich',\n",
       "  'vorlaufig',\n",
       "  'jedenfalls',\n",
       "  'in',\n",
       "  'viel',\n",
       "  'großere',\n",
       "  'gefahr',\n",
       "  'begeben',\n",
       "  'als',\n",
       "  'bisher'],\n",
       " ['aber',\n",
       "  'seitdem',\n",
       "  'achtete',\n",
       "  'er',\n",
       "  'sich',\n",
       "  'ihrer',\n",
       "  'noch',\n",
       "  'weniger',\n",
       "  'fur',\n",
       "  'wurdig,',\n",
       "  'beugte',\n",
       "  'sich',\n",
       "  'moralisch',\n",
       "  'noch',\n",
       "  'tiefer',\n",
       "  'vor',\n",
       "  'ihr',\n",
       "  'und',\n",
       "  'schatzte',\n",
       "  'sein',\n",
       "  'unverdientes',\n",
       "  'gluck',\n",
       "  'noch',\n",
       "  'hoher'],\n",
       " ['der',\n",
       "  'hauptmann',\n",
       "  'der',\n",
       "  'bastille',\n",
       "  'ging',\n",
       "  'an',\n",
       "  'der',\n",
       "  'spitze',\n",
       "  'und',\n",
       "  'ließ',\n",
       "  'die',\n",
       "  'thuren',\n",
       "  'vor',\n",
       "  'dem',\n",
       "  'alten',\n",
       "  'kranken',\n",
       "  'und',\n",
       "  'gebuckt',\n",
       "  'hinschreitenden',\n",
       "  'konige',\n",
       "  'offnen,',\n",
       "  'der',\n",
       "  'beim',\n",
       "  'gehen',\n",
       "  'hustete'],\n",
       " ['die',\n",
       "  'nordstadt',\n",
       "  'hatte',\n",
       "  'gleichfalls',\n",
       "  'sechs',\n",
       "  'von',\n",
       "  'karl',\n",
       "  'dem',\n",
       "  'funften',\n",
       "  'erbaute',\n",
       "  'thore,',\n",
       "  'namlich',\n",
       "  'vom',\n",
       "  'billy-thurme',\n",
       "  'begonnen:',\n",
       "  'das',\n",
       "  'thor',\n",
       "  'saint-antoine,',\n",
       "  'das',\n",
       "  'templerthor,',\n",
       "  'das',\n",
       "  'thor',\n",
       "  'saint-merlin,',\n",
       "  'das',\n",
       "  'thor',\n",
       "  'saint-denis,',\n",
       "  'das',\n",
       "  'monmartrethor',\n",
       "  'und',\n",
       "  'das',\n",
       "  'thor',\n",
       "  'saint-honore'],\n",
       " ['»ich',\n",
       "  'mochte,',\n",
       "  'daß',\n",
       "  'sie',\n",
       "  'das',\n",
       "  'deutsche',\n",
       "  'aufgeben',\n",
       "  'und',\n",
       "  'hindostanisch',\n",
       "  'lernten.'],\n",
       " ['bald', 'kam', 'der', 'lehrer', 'und', 'die', 'schule', 'begann'],\n",
       " ['wie', 'schnell', 'ich', 'ging'],\n",
       " ['»ich', 'meinte', 'es', 'niemals', 'anders«,', 'sagte', 'dieser'],\n",
       " ['»ja,', 'gott', 'sei', 'dank,', 'es', 'ist', 'zu', 'ende'],\n",
       " ['ich',\n",
       "  'mochte',\n",
       "  'sie',\n",
       "  'noch',\n",
       "  'einmal',\n",
       "  'sehen',\n",
       "  '...',\n",
       "  'einmal',\n",
       "  '...',\n",
       "  'ein',\n",
       "  'einziges',\n",
       "  '...'],\n",
       " ['als',\n",
       "  'johann',\n",
       "  'sah,',\n",
       "  'daß',\n",
       "  'es',\n",
       "  'nur',\n",
       "  'eine',\n",
       "  'solche',\n",
       "  'personlichkeit',\n",
       "  'war,',\n",
       "  'd.h.',\n",
       "  'zweifelsohne',\n",
       "  'ein',\n",
       "  'arzt',\n",
       "  'oder',\n",
       "  'ein',\n",
       "  'gerichtsbeamter,',\n",
       "  'und',\n",
       "  'daß',\n",
       "  'dieser',\n",
       "  'mensch',\n",
       "  'eine',\n",
       "  'vom',\n",
       "  'munde',\n",
       "  'weit',\n",
       "  'entfernt',\n",
       "  'stehende',\n",
       "  'nase',\n",
       "  'im',\n",
       "  'gesichte',\n",
       "  'hatte',\n",
       "  '–',\n",
       "  'das',\n",
       "  'zeichen',\n",
       "  'der',\n",
       "  'dummheit',\n",
       "  '–,',\n",
       "  'so',\n",
       "  'zog',\n",
       "  'er',\n",
       "  'sich',\n",
       "  'in',\n",
       "  'den',\n",
       "  'winkel',\n",
       "  'seines',\n",
       "  'loches',\n",
       "  'mit',\n",
       "  'dem',\n",
       "  'hoffnungslosen',\n",
       "  'gefuhle',\n",
       "  'zuruck,',\n",
       "  'daß',\n",
       "  'er',\n",
       "  'eine',\n",
       "  'unbegrenzte',\n",
       "  'zeit',\n",
       "  'in',\n",
       "  'so',\n",
       "  'unbequemer',\n",
       "  'lage',\n",
       "  'und',\n",
       "  'in',\n",
       "  'so',\n",
       "  'schlechter',\n",
       "  'gesellschaft',\n",
       "  'zuzubringen',\n",
       "  'haben',\n",
       "  'wurde'],\n",
       " ['man',\n",
       "  'darf',\n",
       "  'nicht',\n",
       "  'sterben',\n",
       "  'wollen,',\n",
       "  'weil',\n",
       "  'andere',\n",
       "  'gestorben',\n",
       "  'sind'],\n",
       " ['der', 'unbekannte', 'faßte', 'es', 'anders', 'an'],\n",
       " ['liegst', 'du', 'im', 'dammerschein'],\n",
       " ['alle',\n",
       "  'diese',\n",
       "  'von',\n",
       "  'eigenem',\n",
       "  'interesse',\n",
       "  'gereizten',\n",
       "  'leute',\n",
       "  'hatten',\n",
       "  'nur',\n",
       "  'ihre',\n",
       "  'angelegenheiten',\n",
       "  'im',\n",
       "  'kopfe,',\n",
       "  'und',\n",
       "  'die',\n",
       "  'fremden',\n",
       "  'gingen',\n",
       "  'ganz',\n",
       "  'unbeachtet',\n",
       "  'mitten',\n",
       "  'durch',\n",
       "  'diese',\n",
       "  'geschaftige',\n",
       "  'bevolkerung'],\n",
       " ['es',\n",
       "  'war',\n",
       "  'die',\n",
       "  'stunde,',\n",
       "  'da',\n",
       "  'man',\n",
       "  'in',\n",
       "  'den',\n",
       "  'gutshofen',\n",
       "  'zu',\n",
       "  'mittag',\n",
       "  'ißt'],\n",
       " ['24'],\n",
       " ['zuweilen',\n",
       "  'schauten',\n",
       "  'sie',\n",
       "  'plotzlich',\n",
       "  'von',\n",
       "  'bergeshoh',\n",
       "  'auf',\n",
       "  'irgendwelche',\n",
       "  'machtige',\n",
       "  'stadt',\n",
       "  'hinab,',\n",
       "  'mit',\n",
       "  'ihrem',\n",
       "  'dom,',\n",
       "  'ihren',\n",
       "  'brucken,',\n",
       "  'schiffen,',\n",
       "  'limonenhainen',\n",
       "  'und',\n",
       "  'weißen',\n",
       "  'marmorkirchen',\n",
       "  'mit',\n",
       "  'spitzen',\n",
       "  'turmen'],\n",
       " ['der',\n",
       "  'alte',\n",
       "  'seemann',\n",
       "  'wußte',\n",
       "  'nicht,',\n",
       "  'auf',\n",
       "  'wen',\n",
       "  'er',\n",
       "  'horen',\n",
       "  'sollte'],\n",
       " ['zwei',\n",
       "  'schritte',\n",
       "  'vor',\n",
       "  'der',\n",
       "  'hutte',\n",
       "  'lauschte',\n",
       "  'er',\n",
       "  'mit',\n",
       "  'vorgeneigtem',\n",
       "  'kopfe'],\n",
       " ['der',\n",
       "  'kranke',\n",
       "  'verspurte',\n",
       "  'dabei',\n",
       "  'erstaunlicherweise',\n",
       "  '--',\n",
       "  'wie',\n",
       "  'der',\n",
       "  'berichterstatter',\n",
       "  'als',\n",
       "  'augenzeuge',\n",
       "  'versichern',\n",
       "  'darf',\n",
       "  '--',\n",
       "  'nicht',\n",
       "  'den',\n",
       "  'geringsten',\n",
       "  'schmerz,',\n",
       "  'und',\n",
       "  'sein',\n",
       "  'zustand',\n",
       "  'laßt',\n",
       "  'bis',\n",
       "  'jetzt',\n",
       "  'nichts',\n",
       "  'zu',\n",
       "  'wunschen',\n",
       "  'ubrig'],\n",
       " ['mascha,',\n",
       "  'laß',\n",
       "  'uns',\n",
       "  'doch',\n",
       "  'saure',\n",
       "  'milch',\n",
       "  'bringen',\n",
       "  'oder',\n",
       "  'auch',\n",
       "  'himbeeren«,',\n",
       "  'wandte',\n",
       "  'er',\n",
       "  'sich',\n",
       "  'an',\n",
       "  'seine',\n",
       "  'frau.',\n",
       "  '»die',\n",
       "  'himbeeren',\n",
       "  'halten',\n",
       "  'sich',\n",
       "  'in',\n",
       "  'diesem',\n",
       "  'jahre',\n",
       "  'merkwurdig',\n",
       "  'lange.«',\n",
       "  'damit',\n",
       "  'stand',\n",
       "  'swijaschski',\n",
       "  'in',\n",
       "  'der',\n",
       "  'vergnugtesten',\n",
       "  'stimmung',\n",
       "  'auf',\n",
       "  'und',\n",
       "  'trat',\n",
       "  'von',\n",
       "  'ljewin',\n",
       "  'weg;',\n",
       "  'er',\n",
       "  'war',\n",
       "  'offenbar',\n",
       "  'der',\n",
       "  'meinung,',\n",
       "  'daß',\n",
       "  'das',\n",
       "  'gesprach',\n",
       "  'an',\n",
       "  'diesem',\n",
       "  'punkte',\n",
       "  'beendet',\n",
       "  'sei,',\n",
       "  'wahrend',\n",
       "  'es',\n",
       "  'nach',\n",
       "  'ljewins',\n",
       "  'ansicht',\n",
       "  'gerade',\n",
       "  'hier',\n",
       "  'erst',\n",
       "  'anfing'],\n",
       " ['»wenn',\n",
       "  'ich',\n",
       "  'mich',\n",
       "  'jemals',\n",
       "  'verheirate,«',\n",
       "  'fuhr',\n",
       "  'sie',\n",
       "  'fort',\n",
       "  'nach',\n",
       "  'einer',\n",
       "  'pause,',\n",
       "  'die',\n",
       "  'niemand',\n",
       "  'unterbrach,',\n",
       "  '»so',\n",
       "  'bin',\n",
       "  'ich',\n",
       "  'entschlossen,',\n",
       "  'daß',\n",
       "  'mein',\n",
       "  'gemahl',\n",
       "  'nicht',\n",
       "  'mein',\n",
       "  'rival,',\n",
       "  'sondern',\n",
       "  'meine',\n",
       "  'folie',\n",
       "  'sein',\n",
       "  'soll'],\n",
       " ['waren', 'wir', 'nicht', 'unserer', 'vier'],\n",
       " ['»und', 'er', 'billigte', 'deinen', 'lehrplan,', 'jane'],\n",
       " ['aber',\n",
       "  'vor',\n",
       "  'dem',\n",
       "  'hindernis,',\n",
       "  'dem',\n",
       "  'sie',\n",
       "  'sich',\n",
       "  'jetzt',\n",
       "  'naherten,',\n",
       "  'begann',\n",
       "  'wronski,',\n",
       "  'um',\n",
       "  'nicht',\n",
       "  'einen',\n",
       "  'großen',\n",
       "  'kreis',\n",
       "  'beschreiben',\n",
       "  'zu',\n",
       "  'mussen,',\n",
       "  'mit',\n",
       "  'den',\n",
       "  'zugeln',\n",
       "  'zu',\n",
       "  'arbeiten',\n",
       "  'und',\n",
       "  'uberholte',\n",
       "  'machotin',\n",
       "  'schnell',\n",
       "  'gerade',\n",
       "  'auf',\n",
       "  'dem',\n",
       "  'doppelabhang'],\n",
       " ['»paganel'],\n",
       " ['wenn',\n",
       "  'sich',\n",
       "  'namlich',\n",
       "  'den',\n",
       "  'großeren,',\n",
       "  'heißhungrigen',\n",
       "  'madchen',\n",
       "  'eine',\n",
       "  'gelegenheit',\n",
       "  'dazu',\n",
       "  'bot,',\n",
       "  'so',\n",
       "  'brachten',\n",
       "  'sie',\n",
       "  'die',\n",
       "  'kleinen',\n",
       "  'durch',\n",
       "  'schmeicheleien',\n",
       "  'oder',\n",
       "  'drohungen',\n",
       "  'dahin,',\n",
       "  'ihnen',\n",
       "  'ihren',\n",
       "  'anteil',\n",
       "  'abzutreten'],\n",
       " ['und',\n",
       "  'nun',\n",
       "  'erzahlen',\n",
       "  'sie',\n",
       "  'mir,',\n",
       "  'was',\n",
       "  'sie',\n",
       "  'in',\n",
       "  'lowood',\n",
       "  'gelernt',\n",
       "  'haben'],\n",
       " ['(sie',\n",
       "  'war',\n",
       "  'so',\n",
       "  'uberrascht,',\n",
       "  'daß',\n",
       "  'sie',\n",
       "  'im',\n",
       "  'augenblick',\n",
       "  'ihre',\n",
       "  'eigene',\n",
       "  'sprache',\n",
       "  'ganz',\n",
       "  'vergaß)',\n",
       "  '»jetzt',\n",
       "  'werde',\n",
       "  'ich',\n",
       "  'auseinander',\n",
       "  'geschoben',\n",
       "  'wie',\n",
       "  'das',\n",
       "  'langste',\n",
       "  'teleskop',\n",
       "  'das',\n",
       "  'es',\n",
       "  'je',\n",
       "  'gab'],\n",
       " ['»ich',\n",
       "  'will',\n",
       "  'ja',\n",
       "  'auch',\n",
       "  'ubermorgen',\n",
       "  'abreisen,',\n",
       "  'agafja',\n",
       "  'michailowna'],\n",
       " ['wartete',\n",
       "  'sie',\n",
       "  'seit',\n",
       "  'ein',\n",
       "  'paar',\n",
       "  'minuten',\n",
       "  'oder',\n",
       "  'seit',\n",
       "  'einem',\n",
       "  'jahrhundert'],\n",
       " ['–',\n",
       "  'das',\n",
       "  'ist',\n",
       "  'ein',\n",
       "  'rechter',\n",
       "  'grund!',\n",
       "  'erwiderte',\n",
       "  'lady',\n",
       "  'helena'],\n",
       " ['»eine',\n",
       "  'furchterliche',\n",
       "  'katastrophe!«',\n",
       "  'rief',\n",
       "  'der',\n",
       "  'apotheker',\n",
       "  'aus,',\n",
       "  'der',\n",
       "  'fur',\n",
       "  'alle',\n",
       "  'moglichen',\n",
       "  'ereignisse',\n",
       "  'immer',\n",
       "  'das',\n",
       "  'passende',\n",
       "  'begleitwort',\n",
       "  'zur',\n",
       "  'hand',\n",
       "  'hatte'],\n",
       " ['»warum', 'denn', 'nicht'],\n",
       " ['»ah', 'so'],\n",
       " ['da',\n",
       "  'der',\n",
       "  'furst',\n",
       "  'also',\n",
       "  'nicht',\n",
       "  'auf',\n",
       "  'solche',\n",
       "  'art',\n",
       "  'freigebig',\n",
       "  'sein',\n",
       "  'darf,',\n",
       "  'daß',\n",
       "  'es',\n",
       "  'in',\n",
       "  'die',\n",
       "  'augen',\n",
       "  'falle',\n",
       "  'und',\n",
       "  'bekannt',\n",
       "  'werde,',\n",
       "  'so',\n",
       "  'muß',\n",
       "  'er',\n",
       "  'den',\n",
       "  'ruf',\n",
       "  'des',\n",
       "  'geizes',\n",
       "  'nicht',\n",
       "  'furchten'],\n",
       " ['sie',\n",
       "  'wird',\n",
       "  'notwendigerweise',\n",
       "  'unglucklich',\n",
       "  'sein;',\n",
       "  'aber',\n",
       "  'ich',\n",
       "  'habe',\n",
       "  'keine',\n",
       "  'schuld,',\n",
       "  'und',\n",
       "  'daher',\n",
       "  'kann',\n",
       "  'ich',\n",
       "  'nicht',\n",
       "  'unglucklich',\n",
       "  'sein.'],\n",
       " ['so',\n",
       "  'hatte',\n",
       "  'er',\n",
       "  'denn',\n",
       "  'die',\n",
       "  'arbeit',\n",
       "  'nur',\n",
       "  'verrichtet',\n",
       "  'um',\n",
       "  'etwas',\n",
       "  'zu',\n",
       "  'tun,',\n",
       "  'um',\n",
       "  'die',\n",
       "  'furchterliche',\n",
       "  'zeit',\n",
       "  'totzuschlagen,',\n",
       "  'um',\n",
       "  'seinen',\n",
       "  'geist',\n",
       "  'abzulenken'],\n",
       " ['aber',\n",
       "  'dennoch',\n",
       "  'uberlegte',\n",
       "  'sie,',\n",
       "  'daß',\n",
       "  'ihre',\n",
       "  'schwagerin',\n",
       "  'anna',\n",
       "  'die',\n",
       "  'frau',\n",
       "  'eines',\n",
       "  'der',\n",
       "  'einflußreichsten',\n",
       "  'manner',\n",
       "  'in',\n",
       "  'petersburg',\n",
       "  'und',\n",
       "  'selbst',\n",
       "  'eine',\n",
       "  'petersburger',\n",
       "  'grande',\n",
       "  'dame',\n",
       "  'sei'],\n",
       " ['es',\n",
       "  'war',\n",
       "  'der',\n",
       "  '»ombu«,',\n",
       "  'den',\n",
       "  'man',\n",
       "  'vereinzelt',\n",
       "  'auf',\n",
       "  'den',\n",
       "  'argentinischen',\n",
       "  'ebenen',\n",
       "  'antrifft'],\n",
       " ['wieder', 'eine', 'ihrer', 'ewigen', 'zerstreutheiten'],\n",
       " ['was', 'soll', 'ich', 'ihm', 'denn', 'nur', 'sagen'],\n",
       " ['–',\n",
       "  'nun,',\n",
       "  'gehen',\n",
       "  'sie',\n",
       "  'darauf',\n",
       "  'ein?',\n",
       "  'fragte',\n",
       "  'john',\n",
       "  'mangles,',\n",
       "  'den',\n",
       "  'die',\n",
       "  'manieren',\n",
       "  'des',\n",
       "  'kapitans',\n",
       "  'ganz',\n",
       "  'und',\n",
       "  'gar',\n",
       "  'nicht',\n",
       "  'in',\n",
       "  'verlegenheit',\n",
       "  'brachten'],\n",
       " ['der', 'junge', 'mann', 'stammelte', 'etwas', 'unverstandliches'],\n",
       " ['–',\n",
       "  'o,',\n",
       "  'das',\n",
       "  'ist',\n",
       "  'schon',\n",
       "  'gesprochen,',\n",
       "  'kapitan',\n",
       "  'grant,',\n",
       "  'fiel',\n",
       "  'lady',\n",
       "  'helena',\n",
       "  'ein'],\n",
       " ['man',\n",
       "  'hatte',\n",
       "  'uns',\n",
       "  'uberall,',\n",
       "  'wohin',\n",
       "  'wir',\n",
       "  'gekommen',\n",
       "  'waren,',\n",
       "  'schwierigkeiten',\n",
       "  'bereitet'],\n",
       " ['am',\n",
       "  'folgenden',\n",
       "  'morgen',\n",
       "  'erkannte',\n",
       "  'jacques',\n",
       "  'paganel',\n",
       "  'vermittelst',\n",
       "  'seiner',\n",
       "  'karte',\n",
       "  'auf',\n",
       "  'dem',\n",
       "  'rechten',\n",
       "  'ufer',\n",
       "  'den',\n",
       "  'berg',\n",
       "  'tanbara,',\n",
       "  'welcher',\n",
       "  '3000',\n",
       "  'fuß',\n",
       "  'hoch',\n",
       "  'ist'],\n",
       " ['um',\n",
       "  'vier',\n",
       "  'uhr',\n",
       "  'flog',\n",
       "  'das',\n",
       "  'boot,',\n",
       "  'von',\n",
       "  'der',\n",
       "  'sichern',\n",
       "  'hand',\n",
       "  'des',\n",
       "  'hauptlings',\n",
       "  'geleitet,',\n",
       "  'ohne',\n",
       "  'jeden',\n",
       "  'aufenthalt',\n",
       "  'durch',\n",
       "  'ein',\n",
       "  'enges',\n",
       "  'thal',\n",
       "  'dahin'],\n",
       " ['und',\n",
       "  'der',\n",
       "  'wirklich',\n",
       "  'gegen',\n",
       "  'sich',\n",
       "  'selbst',\n",
       "  'aufgebrachte,',\n",
       "  'wurdige',\n",
       "  'geograph',\n",
       "  'schlug',\n",
       "  'sich',\n",
       "  'heftig',\n",
       "  'vor',\n",
       "  'die',\n",
       "  'stirn'],\n",
       " ['er',\n",
       "  'wollte',\n",
       "  'durchaus,',\n",
       "  'daß',\n",
       "  'das',\n",
       "  'baby',\n",
       "  'geholt',\n",
       "  'werde,',\n",
       "  'obgleich',\n",
       "  'ich',\n",
       "  'ihn',\n",
       "  'anflehte,',\n",
       "  'das',\n",
       "  'kind',\n",
       "  'lieber',\n",
       "  'in',\n",
       "  'die',\n",
       "  'kost',\n",
       "  'zu',\n",
       "  'geben',\n",
       "  'und',\n",
       "  'fur',\n",
       "  'seine',\n",
       "  'erhaltung',\n",
       "  'zu',\n",
       "  'bezahlen'],\n",
       " ['gewohnlich',\n",
       "  'gelang',\n",
       "  'es',\n",
       "  'mir,',\n",
       "  'die',\n",
       "  'halfte',\n",
       "  'dieses',\n",
       "  'lukullischen',\n",
       "  'mahls',\n",
       "  'fur',\n",
       "  'mich',\n",
       "  'zu',\n",
       "  'behalten,',\n",
       "  'die',\n",
       "  'andere',\n",
       "  'halfte',\n",
       "  'mußte',\n",
       "  'ich',\n",
       "  'unabanderlich',\n",
       "  'jedesmal',\n",
       "  'verschenken'],\n",
       " ['»ist',\n",
       "  'es',\n",
       "  'denn',\n",
       "  'ein',\n",
       "  'freudenfeuer,',\n",
       "  'das',\n",
       "  'soeben',\n",
       "  'erst',\n",
       "  'angezundet',\n",
       "  'ist?«',\n",
       "  'fragte',\n",
       "  'ich',\n",
       "  'weiter'],\n",
       " ['newjedowski',\n",
       "  'und',\n",
       "  'swijaschski',\n",
       "  'kamen',\n",
       "  'beide',\n",
       "  'als',\n",
       "  'kandidaten',\n",
       "  'in',\n",
       "  'betracht'],\n",
       " ['»ich', 'weiß', 'es', 'wirklich', 'nicht.'],\n",
       " ['die', 'abreise', 'wurde', 'auf', 'acht', 'uhr', 'morgens', 'festgesetzt'],\n",
       " ['er',\n",
       "  'hielt',\n",
       "  'es',\n",
       "  'namlich',\n",
       "  'fur',\n",
       "  'hochst',\n",
       "  'provinzlerhaft,',\n",
       "  'in',\n",
       "  'einem',\n",
       "  'offentlichen',\n",
       "  'lokal',\n",
       "  'den',\n",
       "  'hut',\n",
       "  'abzunehmen'],\n",
       " ['die',\n",
       "  'hauserinsel',\n",
       "  'der',\n",
       "  'altstadt',\n",
       "  'ist,',\n",
       "  'wie',\n",
       "  'sauvel',\n",
       "  'sagt,',\n",
       "  'der',\n",
       "  'bei',\n",
       "  'seinem',\n",
       "  'sonst',\n",
       "  'schwulstigen',\n",
       "  'stile',\n",
       "  'zeitweilig',\n",
       "  'recht',\n",
       "  'glucklich',\n",
       "  'in',\n",
       "  'der',\n",
       "  'darstellungsweise',\n",
       "  'ist,',\n",
       "  '–',\n",
       "  '»die',\n",
       "  'hauserinsel',\n",
       "  'der',\n",
       "  'altstadt',\n",
       "  'ist',\n",
       "  'wie',\n",
       "  'ein',\n",
       "  'großes',\n",
       "  'schiff',\n",
       "  'geformt,',\n",
       "  'das',\n",
       "  'im',\n",
       "  'schlamme',\n",
       "  'aufgefahren',\n",
       "  'ist',\n",
       "  'und',\n",
       "  'im',\n",
       "  'stromlauf',\n",
       "  'der',\n",
       "  'seine',\n",
       "  'festsitzt«'],\n",
       " ['das', 'ist', 'ein', 'schwerer', 'schlag', 'fur', 'sie!'],\n",
       " ['sie',\n",
       "  'hatte',\n",
       "  'seine',\n",
       "  'forderung',\n",
       "  'nicht',\n",
       "  'erfullt,',\n",
       "  'und',\n",
       "  'er',\n",
       "  'mußte',\n",
       "  'sie',\n",
       "  'daher',\n",
       "  'jetzt',\n",
       "  'bestrafen',\n",
       "  'und',\n",
       "  'seine',\n",
       "  'drohung',\n",
       "  'zur',\n",
       "  'ausfuhrung',\n",
       "  'bringen,',\n",
       "  'das',\n",
       "  'heißt,',\n",
       "  'er',\n",
       "  'mußte',\n",
       "  'die',\n",
       "  'scheidung',\n",
       "  'verlangen',\n",
       "  'und',\n",
       "  'ihr',\n",
       "  'den',\n",
       "  'sohn',\n",
       "  'wegnehmen'],\n",
       " ['wurde',\n",
       "  'man',\n",
       "  'ihm',\n",
       "  'nicht',\n",
       "  'glauben,',\n",
       "  'was',\n",
       "  'in',\n",
       "  'diesem',\n",
       "  'fall',\n",
       "  'begreiflich',\n",
       "  'war,',\n",
       "  'so',\n",
       "  'konnte',\n",
       "  'er',\n",
       "  'frau',\n",
       "  'grubach',\n",
       "  'als',\n",
       "  'zeugin',\n",
       "  'fuhren',\n",
       "  'oder',\n",
       "  'auch',\n",
       "  'die',\n",
       "  'beiden',\n",
       "  'alten',\n",
       "  'von',\n",
       "  'druben,',\n",
       "  'die',\n",
       "  'wohl',\n",
       "  'jetzt',\n",
       "  'auf',\n",
       "  'dem',\n",
       "  'marsch',\n",
       "  'zum',\n",
       "  'gegenuberliegenden',\n",
       "  'fenster',\n",
       "  'waren'],\n",
       " ['sie',\n",
       "  'hatten',\n",
       "  'aber',\n",
       "  'keine',\n",
       "  'lust,',\n",
       "  'diese',\n",
       "  'stolze',\n",
       "  'errungenschaft',\n",
       "  'aus',\n",
       "  'mangel',\n",
       "  'an',\n",
       "  'ubung',\n",
       "  'wieder',\n",
       "  'zu',\n",
       "  'verlieren:',\n",
       "  'o',\n",
       "  'nein,',\n",
       "  'sie',\n",
       "  'ubten',\n",
       "  'sie',\n",
       "  'nach',\n",
       "  'dem',\n",
       "  'essen',\n",
       "  'mit',\n",
       "  'recht',\n",
       "  'schonem',\n",
       "  'erfolg,',\n",
       "  'und',\n",
       "  'so',\n",
       "  'verbrachten',\n",
       "  'sie',\n",
       "  'einen',\n",
       "  'herrlichen',\n",
       "  'abend'],\n",
       " ['»du',\n",
       "  'hast',\n",
       "  'wohl',\n",
       "  'nicht',\n",
       "  'erwartet,',\n",
       "  'mich',\n",
       "  'so',\n",
       "  'zu',\n",
       "  'finden«,',\n",
       "  'brachte',\n",
       "  'er',\n",
       "  'mit',\n",
       "  'anstrengung',\n",
       "  'hervor'],\n",
       " ['»und',\n",
       "  'weißt',\n",
       "  'du,',\n",
       "  'gisquette,',\n",
       "  'als',\n",
       "  'der',\n",
       "  'legat',\n",
       "  'voruberkam,',\n",
       "  'spielte',\n",
       "  'man',\n",
       "  'die',\n",
       "  'ersturmung',\n",
       "  'und',\n",
       "  'allen',\n",
       "  'englandern',\n",
       "  'kostete',\n",
       "  'es',\n",
       "  'die',\n",
       "  'kopfe.'],\n",
       " ['jane,',\n",
       "  'hast',\n",
       "  'du',\n",
       "  'jemals',\n",
       "  'gehort',\n",
       "  'oder',\n",
       "  'weißt',\n",
       "  'du,',\n",
       "  'daß',\n",
       "  'ich',\n",
       "  'nicht',\n",
       "  'der',\n",
       "  'alteste',\n",
       "  'sohn',\n",
       "  'meines',\n",
       "  'hauses',\n",
       "  'war'],\n",
       " ['lauter',\n",
       "  'gold',\n",
       "  'und',\n",
       "  'diamanten,\"',\n",
       "  'sagte',\n",
       "  'joe',\n",
       "  'wieder',\n",
       "  'mit',\n",
       "  'begeisterung'],\n",
       " ['dieser',\n",
       "  'hatte',\n",
       "  'keinen',\n",
       "  'schlechtern',\n",
       "  'entschluß',\n",
       "  'fassen',\n",
       "  'konnen,',\n",
       "  'als',\n",
       "  'sich',\n",
       "  'einem',\n",
       "  'fremden',\n",
       "  'in',\n",
       "  'die',\n",
       "  'arme',\n",
       "  'zu',\n",
       "  'werfen,',\n",
       "  'um',\n",
       "  'ferrara',\n",
       "  'zu',\n",
       "  'erlangen'],\n",
       " ['»nein,',\n",
       "  'in',\n",
       "  'der',\n",
       "  'tat',\n",
       "  'nicht,«',\n",
       "  'sagte',\n",
       "  'alice,',\n",
       "  '»was',\n",
       "  'fur',\n",
       "  'eine',\n",
       "  'art',\n",
       "  'tanz',\n",
       "  'ist',\n",
       "  'es?'],\n",
       " ['aber',\n",
       "  'nun',\n",
       "  'nicht',\n",
       "  'mehr',\n",
       "  'sprechen!',\n",
       "  '–',\n",
       "  'horch,',\n",
       "  'da',\n",
       "  'kommt',\n",
       "  'eine',\n",
       "  'geflogen!«',\n",
       "  'schrie',\n",
       "  'ihn',\n",
       "  'ljewin',\n",
       "  'beinahe',\n",
       "  'an',\n",
       "  'und',\n",
       "  'zog',\n",
       "  'die',\n",
       "  'hahne',\n",
       "  'auf'],\n",
       " [\"war'\",\n",
       "  'die',\n",
       "  'treppe',\n",
       "  'nicht',\n",
       "  'gebrochen,',\n",
       "  'hattest',\n",
       "  'du',\n",
       "  'was',\n",
       "  'von',\n",
       "  \"'nem\",\n",
       "  'traum',\n",
       "  'erleben',\n",
       "  'konnen'],\n",
       " ['als',\n",
       "  'er',\n",
       "  'neben',\n",
       "  'mir',\n",
       "  'stand,',\n",
       "  'fragte',\n",
       "  'ich',\n",
       "  'strenge:',\n",
       "  '»nun,',\n",
       "  'wen',\n",
       "  'werden',\n",
       "  'sie',\n",
       "  'denn',\n",
       "  'jetzt',\n",
       "  'heiraten?'],\n",
       " ['»das',\n",
       "  'mag',\n",
       "  'beweisen',\n",
       "  '–',\n",
       "  'wenn',\n",
       "  'es',\n",
       "  'ubrigens',\n",
       "  'ein',\n",
       "  'echtes',\n",
       "  'dokument',\n",
       "  'ist,',\n",
       "  'daß',\n",
       "  'ich',\n",
       "  'einmal',\n",
       "  'verheiratet',\n",
       "  'war,',\n",
       "  'aber',\n",
       "  'es',\n",
       "  'beweist',\n",
       "  'nicht,',\n",
       "  'daß',\n",
       "  'jenes',\n",
       "  'weib,',\n",
       "  'welches',\n",
       "  'darin',\n",
       "  'als',\n",
       "  'meine',\n",
       "  'gattin',\n",
       "  'bezeichnet',\n",
       "  'wird,',\n",
       "  'noch',\n",
       "  'am',\n",
       "  'leben',\n",
       "  'ist.'],\n",
       " ['und',\n",
       "  'in',\n",
       "  'der',\n",
       "  'tat,',\n",
       "  'eine',\n",
       "  'menge',\n",
       "  'geld',\n",
       "  'war',\n",
       "  'fur',\n",
       "  'diese',\n",
       "  'sache',\n",
       "  'bereits',\n",
       "  'aufgewandt',\n",
       "  'worden',\n",
       "  'und',\n",
       "  'wurde',\n",
       "  'noch',\n",
       "  'fortdauernd',\n",
       "  'dafur',\n",
       "  'aufgewandt,',\n",
       "  'und',\n",
       "  'zwar',\n",
       "  'vollig',\n",
       "  'ertraglos;',\n",
       "  'es',\n",
       "  'war',\n",
       "  'klar,',\n",
       "  'daß',\n",
       "  'die',\n",
       "  'ganze',\n",
       "  'sache',\n",
       "  'zu',\n",
       "  'nichts',\n",
       "  'fuhren',\n",
       "  'konnte'],\n",
       " ['»gestatte',\n",
       "  'mir,',\n",
       "  'das',\n",
       "  'zu',\n",
       "  'bezweifeln«,',\n",
       "  'erwiderte',\n",
       "  'stepan',\n",
       "  'arkadjewitsch',\n",
       "  'mit',\n",
       "  'sanfter',\n",
       "  'stimme.',\n",
       "  '»ihre',\n",
       "  'lage',\n",
       "  'ist',\n",
       "  'fur',\n",
       "  'sie',\n",
       "  'qualvoll',\n",
       "  'und',\n",
       "  'bringt',\n",
       "  'dabei',\n",
       "  'keinem',\n",
       "  'anderen',\n",
       "  'den',\n",
       "  'geringsten',\n",
       "  'vorteil'],\n",
       " ['woher', 'kennen', 'sie', 'sie', 'uberhaupt?'],\n",
       " ['»ich', 'habe', 'gelesen.'],\n",
       " ['wir',\n",
       "  'hatten',\n",
       "  'dich',\n",
       "  'schon',\n",
       "  'in',\n",
       "  'unserer',\n",
       "  'gewalt,',\n",
       "  'als',\n",
       "  'dieser',\n",
       "  'elende',\n",
       "  'offizier',\n",
       "  'dazukam'],\n",
       " ['wohlan,',\n",
       "  'mylord,',\n",
       "  'wer',\n",
       "  'von',\n",
       "  'uns',\n",
       "  'den',\n",
       "  'andern',\n",
       "  'uberlebt,',\n",
       "  'der',\n",
       "  'wird',\n",
       "  'das',\n",
       "  'gelubde',\n",
       "  'gegen',\n",
       "  'lady',\n",
       "  'helena',\n",
       "  'und',\n",
       "  'mary',\n",
       "  'grant',\n",
       "  'erfullen.'],\n",
       " ['und',\n",
       "  'der',\n",
       "  'apotheker,',\n",
       "  'der',\n",
       "  'seinen',\n",
       "  'platz',\n",
       "  'etwas',\n",
       "  'weiter',\n",
       "  'weg',\n",
       "  'hatte,',\n",
       "  'hielt',\n",
       "  'sich',\n",
       "  'eine',\n",
       "  'hand',\n",
       "  'ans',\n",
       "  'ohr,',\n",
       "  'um',\n",
       "  'silbe',\n",
       "  'fur',\n",
       "  'silbe',\n",
       "  'ordentlich',\n",
       "  'zu',\n",
       "  'verstehen'],\n",
       " ['»gott',\n",
       "  'segne',\n",
       "  'sie,',\n",
       "  'mein',\n",
       "  'teurer',\n",
       "  'herr!«',\n",
       "  'sagte',\n",
       "  'ich.',\n",
       "  '»gott',\n",
       "  'halte',\n",
       "  'sie',\n",
       "  'von',\n",
       "  'unrecht',\n",
       "  'und',\n",
       "  'sunde',\n",
       "  'zuruck'],\n",
       " ['und',\n",
       "  'das',\n",
       "  'sagt',\n",
       "  'mir',\n",
       "  'meine',\n",
       "  'schwester',\n",
       "  'und',\n",
       "  'glaubt',\n",
       "  'dabei,',\n",
       "  'daß',\n",
       "  '...',\n",
       "  'daß',\n",
       "  '...',\n",
       "  'daß',\n",
       "  'sie',\n",
       "  'mir',\n",
       "  'ihre',\n",
       "  'teilnahme',\n",
       "  'ausdruckt'],\n",
       " ['die',\n",
       "  'klausnerin',\n",
       "  'antwortete',\n",
       "  'nicht;',\n",
       "  'sie',\n",
       "  'begann',\n",
       "  'in',\n",
       "  'einem',\n",
       "  'singenden,',\n",
       "  'erregten',\n",
       "  'und',\n",
       "  'spottischen',\n",
       "  'tone',\n",
       "  'zu',\n",
       "  'murmeln:',\n",
       "  '»tochter',\n",
       "  'aegyptens'],\n",
       " ['schlag',\n",
       "  'ihn',\n",
       "  'doch',\n",
       "  'runter,',\n",
       "  'wenn',\n",
       "  'du',\n",
       "  'ein',\n",
       "  'paar',\n",
       "  'ohrfeigen',\n",
       "  'haben',\n",
       "  'willst!'],\n",
       " ['»warum',\n",
       "  'nicht,',\n",
       "  'wenn',\n",
       "  'das',\n",
       "  'angenehmer',\n",
       "  'ist?«',\n",
       "  'sagte',\n",
       "  'lwow',\n",
       "  'mit',\n",
       "  'seinem',\n",
       "  'hubschen',\n",
       "  'lacheln',\n",
       "  'und',\n",
       "  'beruhrte',\n",
       "  'leise',\n",
       "  'ihre',\n",
       "  'hand.',\n",
       "  '»wer',\n",
       "  'dich',\n",
       "  'nicht',\n",
       "  'kennt,',\n",
       "  'mußte',\n",
       "  'denken,',\n",
       "  'daß',\n",
       "  'du',\n",
       "  'keine',\n",
       "  'mutter,',\n",
       "  'sondern',\n",
       "  'eine',\n",
       "  'stiefmutter',\n",
       "  'warest.'],\n",
       " ['immer', 'zu'],\n",
       " [\",,ist's\", 'das'],\n",
       " ['die',\n",
       "  'franzosischen',\n",
       "  'heere',\n",
       "  'sind',\n",
       "  'also',\n",
       "  'vermischt,',\n",
       "  'halb',\n",
       "  'gedungene,',\n",
       "  'halb',\n",
       "  'eigne',\n",
       "  'mannschaft'],\n",
       " ['man', 'wahnt', 'sie', 'vor', 'augen', 'zu', 'haben'],\n",
       " ['»das',\n",
       "  'kommt',\n",
       "  'von',\n",
       "  'deinen',\n",
       "  'spaßen!«',\n",
       "  'schalt',\n",
       "  'die',\n",
       "  'furstin',\n",
       "  'ihren',\n",
       "  'mann',\n",
       "  'argerlich.',\n",
       "  '»und',\n",
       "  'so',\n",
       "  'machst',\n",
       "  'du',\n",
       "  'es',\n",
       "  'immer.«',\n",
       "  'und',\n",
       "  'nun',\n",
       "  'folgte',\n",
       "  'eine',\n",
       "  'reihe',\n",
       "  'von',\n",
       "  'vorwurfen'],\n",
       " ['es',\n",
       "  'tut',\n",
       "  'mir',\n",
       "  'nur',\n",
       "  'leid,',\n",
       "  'daß',\n",
       "  'ich',\n",
       "  'uberhaupt',\n",
       "  'hergekommen',\n",
       "  'bin!'],\n",
       " ['sonst',\n",
       "  'kame',\n",
       "  'die',\n",
       "  'ganze',\n",
       "  'geschichte',\n",
       "  'und',\n",
       "  'auch',\n",
       "  'die',\n",
       "  'veraußerung',\n",
       "  'des',\n",
       "  'grundstucks',\n",
       "  'heraus'],\n",
       " ['ueberdies',\n",
       "  'brauchte',\n",
       "  'ich',\n",
       "  'nur',\n",
       "  'ein',\n",
       "  'buch',\n",
       "  'zu',\n",
       "  'offnen,',\n",
       "  'und',\n",
       "  'alle',\n",
       "  'unreinen',\n",
       "  'dunste',\n",
       "  'meines',\n",
       "  'gehirnes',\n",
       "  'flohen',\n",
       "  'vor',\n",
       "  'dem',\n",
       "  'glanze',\n",
       "  'der',\n",
       "  'wissenschaft'],\n",
       " ['er',\n",
       "  'ahnte,',\n",
       "  'daß',\n",
       "  'es',\n",
       "  'auch',\n",
       "  'mit',\n",
       "  'seinem',\n",
       "  'bruder',\n",
       "  'so',\n",
       "  'kommen',\n",
       "  'werde'],\n",
       " ['es',\n",
       "  'blieb',\n",
       "  'nur',\n",
       "  'noch',\n",
       "  'ubrig,',\n",
       "  'die',\n",
       "  'karten',\n",
       "  'mit',\n",
       "  'den',\n",
       "  'adressen',\n",
       "  'festzunageln;',\n",
       "  'dort',\n",
       "  'lagen',\n",
       "  'sie,',\n",
       "  'vier',\n",
       "  'kleine,',\n",
       "  'weiße',\n",
       "  'vierecke,',\n",
       "  'auf',\n",
       "  'der',\n",
       "  'kommode'],\n",
       " ['wohin', 'mich', 'wenden'],\n",
       " ['»wie'],\n",
       " ['aber',\n",
       "  'laß',\n",
       "  'uns',\n",
       "  'robin',\n",
       "  'hood',\n",
       "  'spielen',\n",
       "  '--',\n",
       "  \"'s\",\n",
       "  'ist',\n",
       "  \"'n\",\n",
       "  'famoser',\n",
       "  'spaß'],\n",
       " ['wahrend',\n",
       "  'er',\n",
       "  'die',\n",
       "  'grafin',\n",
       "  'lydia',\n",
       "  'iwanowna',\n",
       "  'lesen',\n",
       "  'horte',\n",
       "  'und',\n",
       "  'landaus',\n",
       "  'schone,',\n",
       "  'einfaltige',\n",
       "  'oder',\n",
       "  'spitzbubische',\n",
       "  '(das',\n",
       "  'wußte',\n",
       "  'er',\n",
       "  'selbst',\n",
       "  'nicht)',\n",
       "  'augen',\n",
       "  'auf',\n",
       "  'sich',\n",
       "  'gerichtet',\n",
       "  'fuhlte,',\n",
       "  'begann',\n",
       "  'stepan',\n",
       "  'arkadjewitsch',\n",
       "  'eine',\n",
       "  'art',\n",
       "  'von',\n",
       "  'eigentumlicher',\n",
       "  'schwere',\n",
       "  'im',\n",
       "  'kopfe',\n",
       "  'zu',\n",
       "  'empfinden'],\n",
       " ['»das', 'ware', 'auch', 'das', 'beste!'],\n",
       " ['wenn',\n",
       "  'sie',\n",
       "  'da',\n",
       "  'oben',\n",
       "  'uber',\n",
       "  'die',\n",
       "  'hecke',\n",
       "  'gucken,',\n",
       "  'konnen',\n",
       "  'sie',\n",
       "  'das',\n",
       "  'ungesehen',\n",
       "  'beobachten!'],\n",
       " ['in', 'der', 'ferne', 'heulte', 'ein', 'hund'],\n",
       " ['ob',\n",
       "  'nun',\n",
       "  'mit',\n",
       "  'ihr',\n",
       "  'oder',\n",
       "  'mit',\n",
       "  'einer',\n",
       "  'anderen,',\n",
       "  'aber',\n",
       "  'geschehen',\n",
       "  'mußte',\n",
       "  'es'],\n",
       " ['alle',\n",
       "  'verbindung',\n",
       "  'zwischen',\n",
       "  'knotung',\n",
       "  'und',\n",
       "  'entwickelung',\n",
       "  'seines',\n",
       "  'stuckes',\n",
       "  'war',\n",
       "  'abgeschnitten'],\n",
       " ['»notar',\n",
       "  'guillaumin.«',\n",
       "  'und',\n",
       "  'mit',\n",
       "  'der',\n",
       "  'großten',\n",
       "  'kaltblutigkeit',\n",
       "  'fugte',\n",
       "  'sie',\n",
       "  'hinzu:',\n",
       "  '»ich',\n",
       "  'habe',\n",
       "  'nur',\n",
       "  'nicht',\n",
       "  'das',\n",
       "  'rechte',\n",
       "  'vertrauen',\n",
       "  'zur',\n",
       "  'sache'],\n",
       " ['am',\n",
       "  'folgenden',\n",
       "  'morgen,',\n",
       "  'wahrend',\n",
       "  'der',\n",
       "  'duncan',\n",
       "  'der',\n",
       "  'kuste',\n",
       "  'entlang',\n",
       "  'fuhr,',\n",
       "  'wurden',\n",
       "  'seine',\n",
       "  'boote',\n",
       "  \"an's\",\n",
       "  'land',\n",
       "  'geschickt,',\n",
       "  'um',\n",
       "  'die',\n",
       "  'beschaffenheit',\n",
       "  'des',\n",
       "  'ufers',\n",
       "  'zu',\n",
       "  'untersuchen'],\n",
       " ['»mochtest', 'du', 'irgend', 'etwas', 'anderes,', 'jane'],\n",
       " ['ich',\n",
       "  'ging',\n",
       "  'an',\n",
       "  'den',\n",
       "  'feldern',\n",
       "  'entlang,',\n",
       "  'an',\n",
       "  'hecken',\n",
       "  'und',\n",
       "  'gaßchen,',\n",
       "  'bis',\n",
       "  'die',\n",
       "  'sonne',\n",
       "  'aufgegangen',\n",
       "  'war'],\n",
       " ['bis',\n",
       "  'zum',\n",
       "  'essen',\n",
       "  'war',\n",
       "  'noch',\n",
       "  'viel',\n",
       "  'zeit,',\n",
       "  'das',\n",
       "  'wetter',\n",
       "  'war',\n",
       "  'prachtvoll,',\n",
       "  'und',\n",
       "  'daher',\n",
       "  'wurden',\n",
       "  'mehrere',\n",
       "  'mittel',\n",
       "  'verschiedener',\n",
       "  'art',\n",
       "  'in',\n",
       "  'vorschlag',\n",
       "  'gebracht,',\n",
       "  'um',\n",
       "  'die',\n",
       "  'noch',\n",
       "  'ubrigen',\n",
       "  'zwei',\n",
       "  'stunden',\n",
       "  'auszufullen'],\n",
       " ['alles,',\n",
       "  'was',\n",
       "  'ich',\n",
       "  'versichern',\n",
       "  'kann,',\n",
       "  'ist',\n",
       "  'das,',\n",
       "  'daß',\n",
       "  'der',\n",
       "  'kapitan',\n",
       "  'grant',\n",
       "  'entweder',\n",
       "  'gefangener',\n",
       "  'der',\n",
       "  'australier',\n",
       "  'ist,',\n",
       "  'oder',\n",
       "  '..'],\n",
       " ['»du',\n",
       "  'solltest',\n",
       "  'wronski',\n",
       "  'deswegen',\n",
       "  'kennen,',\n",
       "  'weil',\n",
       "  'er',\n",
       "  'einer',\n",
       "  'deiner',\n",
       "  'nebenbuhler',\n",
       "  'ist.'],\n",
       " ['man',\n",
       "  'musse',\n",
       "  'sich',\n",
       "  'ohne',\n",
       "  'murren',\n",
       "  'seinem',\n",
       "  'ratschluß',\n",
       "  'unterwerfen'],\n",
       " ['als',\n",
       "  'klagliche',\n",
       "  'bettlerin',\n",
       "  'vor',\n",
       "  'der',\n",
       "  'werkstatte',\n",
       "  'schleppt',\n",
       "  'sie',\n",
       "  'sich',\n",
       "  'von',\n",
       "  'nachbildung',\n",
       "  'zu',\n",
       "  'nachbildung'],\n",
       " ['das',\n",
       "  'war',\n",
       "  'eben',\n",
       "  'die',\n",
       "  'dame,',\n",
       "  'die',\n",
       "  'am',\n",
       "  'vormittag',\n",
       "  'zu',\n",
       "  'anna',\n",
       "  'gekommen',\n",
       "  'war',\n",
       "  'und',\n",
       "  'mit',\n",
       "  'der',\n",
       "  'sie',\n",
       "  'dann',\n",
       "  'ausgefahren',\n",
       "  'war,',\n",
       "  'um',\n",
       "  'einkaufe',\n",
       "  'zu',\n",
       "  'machen'],\n",
       " ['›wer',\n",
       "  'ist',\n",
       "  'das,',\n",
       "  'sergei',\n",
       "  'alexejewitsch?‹',\n",
       "  'wollte',\n",
       "  'stepan',\n",
       "  'arkadjewitsch',\n",
       "  'schon',\n",
       "  'fragen,',\n",
       "  'besann',\n",
       "  'sich',\n",
       "  'jedoch',\n",
       "  'noch',\n",
       "  'rechtzeitig'],\n",
       " ['er',\n",
       "  'war',\n",
       "  'selbst',\n",
       "  'auf',\n",
       "  'einmal',\n",
       "  'so',\n",
       "  'vergnugt',\n",
       "  'geworden',\n",
       "  'und',\n",
       "  'mochte',\n",
       "  'sich',\n",
       "  'gar',\n",
       "  'nicht',\n",
       "  'von',\n",
       "  'seinem',\n",
       "  'bruder',\n",
       "  'trennen.',\n",
       "  '»aber',\n",
       "  'wo',\n",
       "  'bist',\n",
       "  'du',\n",
       "  'denn',\n",
       "  'wahrend',\n",
       "  'des',\n",
       "  'regens',\n",
       "  'gewesen?'],\n",
       " ['ich',\n",
       "  'sprach',\n",
       "  'nicht',\n",
       "  'zu',\n",
       "  'ihm',\n",
       "  '–',\n",
       "  'es',\n",
       "  'sprach',\n",
       "  'nicht',\n",
       "  'zu',\n",
       "  'mir',\n",
       "  '–',\n",
       "  'in',\n",
       "  'worten;',\n",
       "  'aber',\n",
       "  'ich',\n",
       "  'las',\n",
       "  'in',\n",
       "  'seinen',\n",
       "  'augen',\n",
       "  'und',\n",
       "  'es',\n",
       "  'las',\n",
       "  'in',\n",
       "  'den',\n",
       "  'meinigen;',\n",
       "  'und',\n",
       "  'unser',\n",
       "  'stummes',\n",
       "  'gesprach',\n",
       "  'lautete',\n",
       "  'ungefahr',\n",
       "  'so'],\n",
       " ['deshalb',\n",
       "  'zog',\n",
       "  'er',\n",
       "  'die',\n",
       "  'sicherheit',\n",
       "  'der',\n",
       "  'losung',\n",
       "  'vor,',\n",
       "  'wie',\n",
       "  'sie',\n",
       "  'der',\n",
       "  'naturliche',\n",
       "  'verlauf',\n",
       "  'bringen',\n",
       "  'mußte,',\n",
       "  'und',\n",
       "  'ging',\n",
       "  'in',\n",
       "  'sein',\n",
       "  'zimmer',\n",
       "  'zuruck,',\n",
       "  'ohne',\n",
       "  'daß',\n",
       "  'von',\n",
       "  'seiner',\n",
       "  'seite',\n",
       "  'oder',\n",
       "  'von',\n",
       "  'seite',\n",
       "  'der',\n",
       "  'wachter',\n",
       "  'ein',\n",
       "  'weiteres',\n",
       "  'wort',\n",
       "  'gefallen',\n",
       "  'ware'],\n",
       " ['»das', 'ist', 'zu', 'eng.'],\n",
       " ['meiner',\n",
       "  'ansicht',\n",
       "  'nach',\n",
       "  'heißt',\n",
       "  'dieser',\n",
       "  'mann',\n",
       "  'wirklich',\n",
       "  'ayrton,',\n",
       "  'ben',\n",
       "  'joyce',\n",
       "  'ist',\n",
       "  'nur',\n",
       "  'sein',\n",
       "  'kriegsname'],\n",
       " ['–', 'immer', 'nach', 'osten'],\n",
       " ['kann',\n",
       "  'nicht',\n",
       "  'jeden',\n",
       "  'augenblick',\n",
       "  'ein',\n",
       "  'unerwartetes',\n",
       "  'ereignis',\n",
       "  'eintreten'],\n",
       " ['dann,',\n",
       "  'zu',\n",
       "  'lord',\n",
       "  'und',\n",
       "  'lady',\n",
       "  'glenarvan',\n",
       "  'gewendet,',\n",
       "  'sagte',\n",
       "  'er:',\n",
       "  'der',\n",
       "  'quartiermeister',\n",
       "  'bei',\n",
       "  'der',\n",
       "  'abfahrt',\n",
       "  'des',\n",
       "  'duncan'],\n",
       " ['alle',\n",
       "  'morgen,',\n",
       "  'ehe',\n",
       "  'er',\n",
       "  'seine',\n",
       "  'kranken',\n",
       "  'besuchte,',\n",
       "  'wurde',\n",
       "  'er',\n",
       "  'hinreiten',\n",
       "  'und',\n",
       "  'das',\n",
       "  'notige',\n",
       "  'anordnen'],\n",
       " ['er',\n",
       "  'neigte',\n",
       "  'den',\n",
       "  'kopf',\n",
       "  'leicht,',\n",
       "  'aber',\n",
       "  'immer',\n",
       "  'wandte',\n",
       "  'er',\n",
       "  'noch',\n",
       "  'keinen',\n",
       "  'blick',\n",
       "  'von',\n",
       "  'der',\n",
       "  'gruppe',\n",
       "  'des',\n",
       "  'hundes',\n",
       "  'mit',\n",
       "  'dem',\n",
       "  'kinde'],\n",
       " ['»mich', 'friert', 'sehr,«', 'antwortete', 'sie'],\n",
       " ['o!',\n",
       "  'diese',\n",
       "  'letzte',\n",
       "  'stunde,',\n",
       "  'die',\n",
       "  'mit',\n",
       "  'all',\n",
       "  'ihren',\n",
       "  'schrecken',\n",
       "  'nahte'],\n",
       " ['mr.',\n",
       "  'brocklehurst',\n",
       "  'kauft',\n",
       "  'alle',\n",
       "  'nahrungsmittel',\n",
       "  'und',\n",
       "  'alle',\n",
       "  'kleider',\n",
       "  'fur',\n",
       "  'uns.'],\n",
       " ['ihm',\n",
       "  'wenigstens',\n",
       "  'war',\n",
       "  'es,',\n",
       "  'als',\n",
       "  'lagen',\n",
       "  'tiefe',\n",
       "  'abgrunde',\n",
       "  'zwischen',\n",
       "  'ihr',\n",
       "  'und',\n",
       "  'ihm'],\n",
       " ['schnell!', 'schnell!'],\n",
       " ['»der',\n",
       "  'herr',\n",
       "  'ist',\n",
       "  'russe',\n",
       "  'und',\n",
       "  'hat',\n",
       "  'nach',\n",
       "  'ihnen',\n",
       "  'gefragt«,',\n",
       "  'berichtete',\n",
       "  'der',\n",
       "  'oberkellner'],\n",
       " ['die',\n",
       "  'schwester',\n",
       "  'eilte',\n",
       "  'zur',\n",
       "  'mutter',\n",
       "  'und',\n",
       "  'hielt',\n",
       "  'ihr',\n",
       "  'die',\n",
       "  'stirn'],\n",
       " ['die',\n",
       "  'feuerwehr',\n",
       "  'stutzte',\n",
       "  'sich',\n",
       "  'auf',\n",
       "  'ihre',\n",
       "  'gewehre,',\n",
       "  'und',\n",
       "  'binet',\n",
       "  'stand',\n",
       "  'immer',\n",
       "  'noch',\n",
       "  'stramm',\n",
       "  'da',\n",
       "  'im',\n",
       "  'stillgestanden',\n",
       "  'und',\n",
       "  'mit',\n",
       "  'vorschriftsmaßiger',\n",
       "  'sabelhaltung'],\n",
       " ['wendet',\n",
       "  'man',\n",
       "  'ein,',\n",
       "  'konig',\n",
       "  'ludwig',\n",
       "  'habe',\n",
       "  'dem',\n",
       "  'papst',\n",
       "  'alexander',\n",
       "  'die',\n",
       "  'romagna,',\n",
       "  'und',\n",
       "  'neapel',\n",
       "  'den',\n",
       "  'spaniern',\n",
       "  'zugestanden,',\n",
       "  'um',\n",
       "  'einen',\n",
       "  'krieg',\n",
       "  'zu',\n",
       "  'vermeiden,',\n",
       "  'so',\n",
       "  'antwortete',\n",
       "  'ich:',\n",
       "  'man',\n",
       "  'muß',\n",
       "  'aus',\n",
       "  'den',\n",
       "  'grunden,',\n",
       "  'die',\n",
       "  'oben',\n",
       "  'bereits',\n",
       "  'angegeben',\n",
       "  'wurden,',\n",
       "  'niemals',\n",
       "  'ein',\n",
       "  'ubles',\n",
       "  'verhaltniß',\n",
       "  'einreißen',\n",
       "  'lassen,',\n",
       "  'um',\n",
       "  'einen',\n",
       "  'krieg',\n",
       "  'zu',\n",
       "  'vermeiden;',\n",
       "  'denn',\n",
       "  'er',\n",
       "  'wird',\n",
       "  'gar',\n",
       "  'nicht',\n",
       "  'vermieden,',\n",
       "  'sondern',\n",
       "  'nur',\n",
       "  'zu',\n",
       "  'deinem',\n",
       "  'nachtheile',\n",
       "  'aufgeschoben'],\n",
       " ['darauf',\n",
       "  'folgte',\n",
       "  'eine',\n",
       "  'personliche',\n",
       "  'angelegenheit:',\n",
       "  'der',\n",
       "  'besuch',\n",
       "  'seines',\n",
       "  'arztes',\n",
       "  'und',\n",
       "  'der',\n",
       "  'seines',\n",
       "  'geschaftsfuhrers'],\n",
       " ['sie',\n",
       "  'kleidete',\n",
       "  'sich',\n",
       "  'aus',\n",
       "  'und',\n",
       "  'ging',\n",
       "  'in',\n",
       "  'das',\n",
       "  'schlafzimmer;',\n",
       "  'aber',\n",
       "  'von',\n",
       "  'jener',\n",
       "  'lebhaftigkeit,',\n",
       "  'die',\n",
       "  'wahrend',\n",
       "  'ihres',\n",
       "  'aufenthaltes',\n",
       "  'in',\n",
       "  'moskau',\n",
       "  'nur',\n",
       "  'so',\n",
       "  'aus',\n",
       "  'ihren',\n",
       "  'augen',\n",
       "  'gespruht,',\n",
       "  'aus',\n",
       "  'ihrem',\n",
       "  'lacheln',\n",
       "  'hervorgeleuchtet',\n",
       "  'hatte,',\n",
       "  'war',\n",
       "  'jetzt',\n",
       "  'auf',\n",
       "  'ihrem',\n",
       "  'gesichte',\n",
       "  'nichts',\n",
       "  'zu',\n",
       "  'entdecken;',\n",
       "  'vielmehr',\n",
       "  'schien',\n",
       "  'jetzt',\n",
       "  'jenes',\n",
       "  'feuer',\n",
       "  'in',\n",
       "  'ihrem',\n",
       "  'inneren',\n",
       "  'entweder',\n",
       "  'erloschen',\n",
       "  'zu',\n",
       "  'sein',\n",
       "  'oder',\n",
       "  'sich',\n",
       "  'irgendwo',\n",
       "  'tief',\n",
       "  'unten',\n",
       "  'versteckt',\n",
       "  'zu',\n",
       "  'haben'],\n",
       " ['die',\n",
       "  'beispiele',\n",
       "  'dieser',\n",
       "  'art',\n",
       "  'von',\n",
       "  'einschließung',\n",
       "  'waren,',\n",
       "  'obgleich',\n",
       "  'man',\n",
       "  'wenig',\n",
       "  'notiz',\n",
       "  'von',\n",
       "  'ihnen',\n",
       "  'nahm,',\n",
       "  'in',\n",
       "  'wahrheit,',\n",
       "  'und',\n",
       "  'wie',\n",
       "  'wir',\n",
       "  'eben',\n",
       "  'gesagt',\n",
       "  'haben,',\n",
       "  'doch',\n",
       "  'haufig',\n",
       "  'im',\n",
       "  'innern',\n",
       "  'der',\n",
       "  'stadte'],\n",
       " ['arme',\n",
       "  'jungen',\n",
       "  '--',\n",
       "  'sie',\n",
       "  'hatten,',\n",
       "  'wie',\n",
       "  'tom,',\n",
       "  'einen',\n",
       "  'ruckfall',\n",
       "  'zu',\n",
       "  'erdulden'],\n",
       " ['jetzt',\n",
       "  'waren',\n",
       "  'sie',\n",
       "  'nun',\n",
       "  'miteinander',\n",
       "  'allein;',\n",
       "  'aber',\n",
       "  'anna',\n",
       "  'wußte',\n",
       "  'nicht,',\n",
       "  'wovon',\n",
       "  'sie',\n",
       "  'reden',\n",
       "  'sollte'],\n",
       " ['noch',\n",
       "  'mit',\n",
       "  'den',\n",
       "  'zu',\n",
       "  'fausten',\n",
       "  'geballten',\n",
       "  'handen',\n",
       "  'lief',\n",
       "  'sie',\n",
       "  'dann',\n",
       "  'hinter',\n",
       "  'k.,',\n",
       "  'der',\n",
       "  'aber',\n",
       "  'einen',\n",
       "  'großen',\n",
       "  'vorsprung',\n",
       "  'hatte'],\n",
       " ['was',\n",
       "  'machen',\n",
       "  'wir',\n",
       "  'nur',\n",
       "  'mit',\n",
       "  'dem',\n",
       "  'bißchen',\n",
       "  'geld,',\n",
       "  'was',\n",
       "  'wir',\n",
       "  'noch',\n",
       "  'haben?'],\n",
       " ['warum',\n",
       "  'sie',\n",
       "  'das',\n",
       "  'sagte,',\n",
       "  'woran',\n",
       "  'sie',\n",
       "  'doch',\n",
       "  'eine',\n",
       "  'sekunde',\n",
       "  'vorher',\n",
       "  'noch',\n",
       "  'nicht',\n",
       "  'gedacht',\n",
       "  'gehabt',\n",
       "  'hatte,',\n",
       "  'das',\n",
       "  'hatte',\n",
       "  'sie',\n",
       "  'nicht',\n",
       "  'erklaren',\n",
       "  'konnen'],\n",
       " ['an',\n",
       "  'dieser',\n",
       "  'vertheilung',\n",
       "  'von',\n",
       "  'rechten',\n",
       "  'linien,',\n",
       "  'rechten',\n",
       "  'winkeln,',\n",
       "  'erkennt',\n",
       "  'man',\n",
       "  'das',\n",
       "  'werk',\n",
       "  'des',\n",
       "  'geometers',\n",
       "  'und',\n",
       "  'nicht',\n",
       "  'des',\n",
       "  'geographen'],\n",
       " ['der',\n",
       "  'taube',\n",
       "  'richter,',\n",
       "  'den',\n",
       "  'auch',\n",
       "  'niemand',\n",
       "  'auf',\n",
       "  'die',\n",
       "  'taubheit',\n",
       "  'des',\n",
       "  'angeklagten',\n",
       "  'aufmerksam',\n",
       "  'machte,',\n",
       "  'glaubte,',\n",
       "  'daß',\n",
       "  'dieser,',\n",
       "  'wie',\n",
       "  'alle',\n",
       "  'angeklagten',\n",
       "  'gewohnlich',\n",
       "  'thaten,',\n",
       "  'geantwortet',\n",
       "  'hatte,',\n",
       "  'und',\n",
       "  'fuhr',\n",
       "  'in',\n",
       "  'seiner',\n",
       "  'gedankenlosen',\n",
       "  'und',\n",
       "  'albernen',\n",
       "  'zuversicht',\n",
       "  'fort'],\n",
       " ['die',\n",
       "  'zeit',\n",
       "  'ist',\n",
       "  'der',\n",
       "  'baumeister,',\n",
       "  'ein',\n",
       "  'volk',\n",
       "  'macht',\n",
       "  'den',\n",
       "  'maurer'],\n",
       " ['–',\n",
       "  'ohne',\n",
       "  'in',\n",
       "  'anschlag',\n",
       "  'zu',\n",
       "  'bringen,',\n",
       "  'daß',\n",
       "  'die',\n",
       "  'bewohner',\n",
       "  'der',\n",
       "  'pampas',\n",
       "  'in',\n",
       "  'patagonien',\n",
       "  'ebenso',\n",
       "  'wohl',\n",
       "  'indier',\n",
       "  'sind,',\n",
       "  'als',\n",
       "  'die',\n",
       "  'eingeborenen',\n",
       "  'des',\n",
       "  'pendjab'],\n",
       " ['»verflucht!«', 'stohnte', 'der', 'hauptmann', 'und', 'sank', 'nie', 'der'],\n",
       " ['wenn',\n",
       "  'sie',\n",
       "  'menschenverstand',\n",
       "  'hatten,',\n",
       "  'wurden',\n",
       "  'sie',\n",
       "  'das',\n",
       "  'dach',\n",
       "  'abreißen.«',\n",
       "  'nach',\n",
       "  'einer',\n",
       "  'oder',\n",
       "  'zwei',\n",
       "  'minuten',\n",
       "  'fingen',\n",
       "  'sie',\n",
       "  'wieder',\n",
       "  'an',\n",
       "  'sich',\n",
       "  'zu',\n",
       "  'ruhren,',\n",
       "  'und',\n",
       "  'alice',\n",
       "  'horte',\n",
       "  'das',\n",
       "  'kaninchen',\n",
       "  'sagen:',\n",
       "  '»eine',\n",
       "  'karre',\n",
       "  'voll',\n",
       "  'ist',\n",
       "  'vor',\n",
       "  'der',\n",
       "  'hand',\n",
       "  'genug.'],\n",
       " ['der',\n",
       "  'schlaf',\n",
       "  'fuhrte',\n",
       "  'mich',\n",
       "  'wieder',\n",
       "  'zu',\n",
       "  'den',\n",
       "  'scenen',\n",
       "  'meiner',\n",
       "  'kindheit',\n",
       "  'zuruck'],\n",
       " [\"werd'\", 'wieder', 'mal', 'abrechnung', 'halten', 'mussen', 'mit', 'ihm.'],\n",
       " ['sie',\n",
       "  'naherte',\n",
       "  'sich,',\n",
       "  'ohne',\n",
       "  'ein',\n",
       "  'wort',\n",
       "  'zu',\n",
       "  'verlieren,',\n",
       "  'quasimodo,',\n",
       "  'der',\n",
       "  'sich',\n",
       "  'vergebens',\n",
       "  'hin-',\n",
       "  'und',\n",
       "  'herwand,',\n",
       "  'um',\n",
       "  'ihr',\n",
       "  'auszuweichen,',\n",
       "  'machte',\n",
       "  'eine',\n",
       "  'kurbisflasche',\n",
       "  'von',\n",
       "  'ihrem',\n",
       "  'gurtel',\n",
       "  'los',\n",
       "  'und',\n",
       "  'setzte',\n",
       "  'sie',\n",
       "  'sachte',\n",
       "  'an',\n",
       "  'die',\n",
       "  'trockenen',\n",
       "  'lippen',\n",
       "  'des',\n",
       "  'unglucklichen'],\n",
       " ['welche', 'thore', 'wurden', 'wol', 'ihm', 'verschlossen', 'werden']]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_test_sents[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "word must be a string!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-9566f6a1985d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlaplace_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplain_test_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-cea61bcb51a1>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentencies)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresult_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_any_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbiggest_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult_language\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mnew_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36049c45435e>\u001b[0m in \u001b[0;36mprob\u001b[0;34m(self, sent)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mprob\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36049c45435e>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Cheking the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word must be a string!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'context must be a tuple!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: word must be a string!"
     ]
    }
   ],
   "source": [
    "laplace_classifier.predict(plain_test_sents[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "word must be a string!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-88cecb20236c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnaive_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnaive_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplain_test_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlaplace_predictiona\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlaplace_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplain_test_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-112-88cecb20236c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnaive_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnaive_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplain_test_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlaplace_predictiona\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlaplace_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplain_test_sents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-cea61bcb51a1>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, sentencies)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mresult_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_any_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mbiggest_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult_language\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mnew_probability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoragies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36049c45435e>\u001b[0m in \u001b[0;36mprob\u001b[0;34m(self, sent)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0mprob\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-36049c45435e>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, word, context)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Cheking the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word must be a string!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'context must be a tuple!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: word must be a string!"
     ]
    }
   ],
   "source": [
    "naive_predictions = [naive_classifier.predict(plain_test_sents[i]) for i in range(1, 240)]\n",
    "laplace_predictiona = [laplace_classifier.predict(plain_test_sents[i]) for i in range(1, 240)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en',\n",
       " 'en']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
